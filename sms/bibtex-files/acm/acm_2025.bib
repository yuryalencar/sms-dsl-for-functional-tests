@inproceedings{10.1145/2915970.2916010,
author = {H\"{a}ser, Florian and Felderer, Michael and Breu, Ruth},
title = {An integrated tool environment for experimentation in domain specific language engineering},
year = {2016},
isbn = {9781450336918},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2915970.2916010},
doi = {10.1145/2915970.2916010},
abstract = {Domain specific languages (DSLs) are widely used in practice and investigated in software engineering research. But so far, language workbenches do not provide sufficient built-in decision support for language design and improvement. Controlled experiments have the potential to provide appropriate, data-driven decision support for language engineers and researchers to compare different language features with evidence-based feedback. This paper provides an integrated end-to-end tool environment to perform controlled experiments in DSL engineering. The experiment environment is built on the basis and integrated into the language workbench Meta Programming System (MPS). The environment not only supports language design but also all steps of experimentation, i.e., planning, operation, analysis &amp; interpretation, as well as presentation &amp; package. The tool environment is presented by means of a running example experiment comparing the time taken to create system acceptance tests for web applications in two different DSLs.},
booktitle = {Proceedings of the 20th International Conference on Evaluation and Assessment in Software Engineering},
articleno = {20},
numpages = {5},
keywords = {tool support, meta programming system (MPS), language engineering, experimentation, empirical evaluation, domain specific languages (DSLs), controlled experiment},
location = {Limerick, Ireland},
series = {EASE '16}
}

@inproceedings{10.1145/2072221.2072247,
author = {Solms, Fritz and Edwards, Craig and Paar, Alexander and Gruner, Stefan},
title = {A domain-specific language for URDAD based requirements elicitation},
year = {2011},
isbn = {9781450308786},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2072221.2072247},
doi = {10.1145/2072221.2072247},
abstract = {Use-Case Responsibility-Driven Analysis and Design (URDAD) is a service-oriented software analysis and design methodology. It is used by requirements engineers to develop technology-neutral, semi-formal platform-independent models (PIM) within the OMG's MDA. In the past, URDAD models were denoted in UML. However, that was tedious and error-prone. The resulting models were often of rather poor quality. In this paper we introduce and discuss a new Domain-Specific Language (DSL) for URDAD. Its meta model is consistent and satisfiable. We show that URDAD DSL specifications are simpler and allow for more complete service contract specifications than their corresponding UML expressions. They also enable traceability and test case generation.},
booktitle = {Proceedings of the South African Institute of Computer Scientists and Information Technologists Conference on Knowledge, Innovation and Leadership in a Diverse, Multidisciplinary Environment},
pages = {224–230},
numpages = {7},
keywords = {service orientation, requirements engineering, platform independent model, model driven development, meta model, domain specific language},
location = {Cape Town, South Africa},
series = {SAICSIT '11}
}

@inproceedings{10.1145/3510457.3513078,
author = {Elsner, Daniel and Wuersching, Roland and Schnappinger, Markus and Pretschner, Alexander and Graber, Maria and Dammer, Ren\'{e} and Reimer, Silke},
title = {Build system aware multi-language regression test selection in continuous integration},
year = {2022},
isbn = {9781450392266},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3510457.3513078},
doi = {10.1145/3510457.3513078},
abstract = {At IVU Traffic Technologies, continuous integration (CI) pipelines build, analyze, and test the code for inadvertent effects before pull requests are merged. However, compiling the entire code base and executing all regression tests for each pull request is infeasible due to prohibitively long feedback times. Regression test selection (RTS) aims to reduce the testing effort. Yet, existing safe RTS techniques are not suitable, as they largely rely on language-specific program analysis. The IVU code base consists of more than 13 million lines of code in Java or C/C++ and contains thousands of non-code artifacts. Regression tests commonly operate across languages, using cross-language links, or read from non-code artifacts. In this paper, we describe our build system aware multi-language RTS approach, which selectively compiles and executes affected code modules and regression tests, respectively, for a pull request. We evaluate our RTS technique on 397 pull requests, covering roughly 2,700 commits. The results show that we are able to safely exclude up to 75% of tests on average (no undetected real failures slip into the target branches) and thereby save 72% of testing time, whereas end-to-end CI pipeline time is reduced by up to 63% on average.},
booktitle = {Proceedings of the 44th International Conference on Software Engineering: Software Engineering in Practice},
pages = {87–96},
numpages = {10},
keywords = {continuous integration, regression test selection, software testing},
location = {Pittsburgh, Pennsylvania},
series = {ICSE-SEIP '22}
}

@inproceedings{10.1145/3678719.3685692,
author = {Bergsmann, Severin and Schmidt, Alexander and Fischer, Stefan and Ramler, Rudolf},
title = {First Experiments on Automated Execution of Gherkin Test Specifications with Collaborating LLM Agents},
year = {2024},
isbn = {9798400711091},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3678719.3685692},
doi = {10.1145/3678719.3685692},
abstract = {Gherkin is a domain-specific language for describing test scenarios in natural language, which are the basis for automated acceptance testing. The emergence of Large Language Models (LLMs) has opened up new possibilities for processing such test specifications and for generating executable test code. This paper investigates the feasibility of employing LLMs to execute Gherkin test specifications utilizing the AutoGen multi-agent framework. Our findings show that our LLM agent system is able to automatically run the given test scenarios by autonomously exploring the system under test, generating executable test code on the fly, and evaluating execution results. We observed high success rates for executing simple as well as more complex test scenarios, but we also identified difficulties regarding failure scenarios and fault detection.},
booktitle = {Proceedings of the 15th ACM International Workshop on Automating Test Case Design, Selection and Evaluation},
pages = {12–15},
numpages = {4},
keywords = {Domain Specific Language, LLMs, Test Automation},
location = {Vienna, Austria},
series = {A-TEST 2024}
}

@inproceedings{10.1145/2851613.2851749,
author = {Mohr, David and Stefanovic, Darko},
title = {Stella: a python-based domain-specific language for simulations},
year = {2016},
isbn = {9781450337397},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2851613.2851749},
doi = {10.1145/2851613.2851749},
abstract = {We wish to make it easier and quicker to write well-performing scientific simulations that (1) have single-thread performance competitive with low-level languages, (2) use object-oriented programming to properly structure the code, and (3) are very easy to develop. Instead of prototyping in a high-level language and then rewriting in a lower-level language, we created a DSL embedded in Python that is transparently usable, retains some OOP features, compiles to machine code, and executes at speed similar to C.},
booktitle = {Proceedings of the 31st Annual ACM Symposium on Applied Computing},
pages = {1952–1959},
numpages = {8},
keywords = {Python, domain-specific languages, scientific simulations},
location = {Pisa, Italy},
series = {SAC '16}
}

@inproceedings{10.1145/3573105.3575684,
author = {Ni, Haobin and Delignat-Lavaud, Antoine and Fournet, C\'{e}dric and Ramananandro, Tahina and Swamy, Nikhil},
title = {ASN1*: Provably Correct, Non-malleable Parsing for ASN.1 DER},
year = {2023},
isbn = {9798400700262},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3573105.3575684},
doi = {10.1145/3573105.3575684},
abstract = {Abstract Syntax Notation One (ASN.1) is a language for structured data exchange between computers, standardized by both ITU-T and ISO/IEC since 1984. The Distinguished Encoding Rules (DER) specify its non-malleable binary format: for a given ASN.1 data type, every value has a distinct, unique binary representation. ASN.1 DER is used in many security-critical interfaces for telecommunications and networking, such as the X.509 public key infrastructure, where non-malleability is essential. However, due to the expressiveness and flexibility of the general-purpose ASN.1 language, correctly parsing ASN.1 DER data formats is still considered a serious security challenge in practice.  We present ASN1*, the first formalization of ASN.1 DER with a mechanized proof of non-malleability. Our development provides a shallow embedding of ASN.1 in the F* proof assistant and formalizes its DER semantics within the EverParse parser generator framework. It guarantees that any ASN.1 data encoded using our DER semantics is non-malleable. It yields verified code that parses valid binary representations into values of the corresponding ASN.1 data type while rejecting invalid ones.   We empirically confirm that our semantics models ASN.1 DER usage in practice by evaluating ASN1* parsers extracted to OCaml on both positive and negative test cases involving X.509 certificates and Certificate Revocation Lists (CRLs).},
booktitle = {Proceedings of the 12th ACM SIGPLAN International Conference on Certified Programs and Proofs},
pages = {275–289},
numpages = {15},
keywords = {Parsing, Formal verification, Domain-specific Language, ASN.1},
location = {Boston, MA, USA},
series = {CPP 2023}
}

@article{10.1007/s00165-016-0359-1,
author = {Keshishzadeh, Sarmen and Mooij, Arjan J.},
title = {Formalizing and testing the consistency of DSL transformations},
year = {2016},
issue_date = {Apr 2016},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
volume = {28},
number = {2},
issn = {0934-5043},
url = {https://doi.org/10.1007/s00165-016-0359-1},
doi = {10.1007/s00165-016-0359-1},
abstract = {A domain specific language (DSL) focuses on the essential concepts in a specific problem domain, and abstracts from low-level implementation details. The development of DSLs usually centers around the meta-model, grammar and code generator, possibly extended with transformations to analysis models. Typically, little attention is given to the formal semantics of the language, whereas this is essential for reasoning about DSL models, and for assessing the correctness of the generated code and analysis models. We argue that the semantics of a DSL should be defined explicitly and independently of any code generator, to avoid all kinds of complexities from low-level implementation details. As the generated analysis models must reflect some of these implementation details, we propose to formalize them separately. To assess the correctness and consistency of the generated code and analysis models in a practical way, we use conformance testing. We extensively illustrate this general approach using specific formalizations for an industrial DSL on collision prevention. We do not aim for a generic semantic model for any DSL, but this specific DSL indicates the potential of a modular semantics to facilitate reuse among DSLs.},
journal = {Form. Asp. Comput.},
month = apr,
pages = {181–206},
numpages = {26},
keywords = {Conformance testing, Code generation, Semantics, Domain specific language (DSL)}
}

@article{10.1145/2659118.2659136,
author = {Zhou, Jingang and Yin, Kun},
title = {Automated web testing based on textual-visual UI patterns: the UTF approach},
year = {2014},
issue_date = {September 2014},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {39},
number = {5},
issn = {0163-5948},
url = {https://doi.org/10.1145/2659118.2659136},
doi = {10.1145/2659118.2659136},
abstract = {Automated software testing is the only resort for delivering quality software, since there are usually large test suites to be executed, especially for regression testing. Though many automated testing tools and techniques have been developed, they still do not solve all problems like cost and maintenance, and they can even be brittle in some situations, thus confining their adoption. To address these issues, we develop a pattern-based automated testing framework, called UTF (User-oriented Testing Framework), for Web applications. UTF encodes textual-visual information about and relationships between widgets into a domain specific language for test scripts based on the underlying invariant structural patterns in the DOM, which allows test scripts to be easily created and maintained. In addition, UTF provides flexible extension and customization capabilities to make it adaptable for various Web-application scenarios. Our experiences show UTF can greatly reduce the cost of adopting automated testing and facilitate its institutionalization.},
journal = {SIGSOFT Softw. Eng. Notes},
month = sep,
pages = {1–6},
numpages = {6},
keywords = {web application, user-interface pattern, domain-specific language, automated testing}
}

@inproceedings{10.1145/3624062.3624132,
author = {Jacobsen, Douglas and Bird, Robert F},
title = {Ramble: A flexible, extensible, and composable experimentation framework},
year = {2023},
isbn = {9798400707858},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3624062.3624132},
doi = {10.1145/3624062.3624132},
abstract = {Reproducibility and replicability are extremely important components of scientific computing, and any computational research. The ability to replicate a set of experiments aids many other computational use cases, such as systems acceptance where a compute center requires the ability to create and execute the same experiment as a hardware vendor. Several test harnesses and frameworks currently exist, with the aim of improving experiment replicability. In this paper, we introduce Ramble, a new Python based experimentation framework. Ramble provides a domain specific language for abstracting how experiments can be created from application definitions, and a flexible templating engine for creating experiments. Ramble can be used for automating system tests, scientific parameter studies, performance focused benchmarking, and many other types of computational experiments. We will introduce Ramble, describe its architecture, and give some concrete use cases where it can be applied to HPC application experimentation.},
booktitle = {Proceedings of the SC '23 Workshops of the International Conference on High Performance Computing, Network, Storage, and Analysis},
pages = {600–608},
numpages = {9},
keywords = {benchmarking, experimentation, framework, harness, testing},
location = {Denver, CO, USA},
series = {SC-W '23}
}

@inproceedings{10.1145/3340433.3342825,
author = {Kessel, Marcus and Atkinson, Colin},
title = {A platform for diversity-driven test amplification},
year = {2019},
isbn = {9781450368506},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3340433.3342825},
doi = {10.1145/3340433.3342825},
abstract = {Test amplification approaches take a manually written set of tests (input/output mappings) and enhance their effectiveness for some clearly defined engineering goal such as detecting faults. Conceptually, they can either achieve this in a ``black box'' way using only the initial ``seed'' tests or in a ``white box'' way utilizing additional inputs such as the source code or specification of the software under test. However, no fully black box approach to test amplification is currently available even though they can be used to enhance white box approaches. In this paper we introduce a new approach that uses the seed tests to search for existing redundant implementations of the software under test and leverages them as oracles in the generation and evaluation of new tests. The approach can therefore be used as a stand alone black box test amplification method or in tandem with other methods. In this paper we explain the approach, describe its synergies with other approaches and provide some evidence for its practical feasibility.},
booktitle = {Proceedings of the 10th ACM SIGSOFT International Workshop on Automating TEST Case Design, Selection, and Evaluation},
pages = {35–41},
numpages = {7},
keywords = {test amplification, oracle problem, observations, mining software repositories, behavior, automated testing},
location = {Tallinn, Estonia},
series = {A-TEST 2019}
}

@inproceedings{10.1145/3183895.3183897,
author = {Schuts, Mathijs and Hooman, Jozef and Tielemans, Paul},
title = {Industrial Experience with the Migration of Legacy Models using a DSL},
year = {2018},
isbn = {9781450363556},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3183895.3183897},
doi = {10.1145/3183895.3183897},
abstract = {Software departments of companies that exist for several decades often have to deal with legacy models. Important business assets have been modelled with tools that are no longer preferred within the company. Manually remodelling these models with a new tool would be too costly. In this paper, we describe an approach to migrate from Rhapsody models to models of another tool. To perform the migration, we created a Domain Specific Language (DSL) that accepts Rhapsody models as instances. A generator of this DSL can then produces model instances for the new tool. To get confidence in the transformation in a pragmatic way, we applied a combination of model learning and equivalence checking. Learning has been applied to both the source code generated by Rhapsody and the code generated by the new tool. The resulting models are compared using equivalence checking.},
booktitle = {Proceedings of the Real World Domain Specific Languages Workshop 2018},
articleno = {1},
numpages = {10},
keywords = {Tool migration, Model-based development, Model transformation, Legacy, Domain specific languages},
location = {Vienna, Austria},
series = {RWDSL2018}
}

@article{10.1145/1151695.1151697,
author = {Sinha, Avik and Smidts, Carol},
title = {HOTTest: A model-based test design technique for enhanced testing of domain-specific applications},
year = {2006},
issue_date = {July 2006},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {15},
number = {3},
issn = {1049-331X},
url = {https://doi.org/10.1145/1151695.1151697},
doi = {10.1145/1151695.1151697},
abstract = {Model-based testing is an effective black-box test generation technique for applications. Existing model-based testing techniques, however, fail to capture implicit domain-specific properties, as they overtly rely on software artifacts such as design documents, requirement specifications, etc., for completeness of the test model. This article presents a technique, HOTTest, which uses a strongly typed domain-specific language to model the system under test. This allows extraction of type-related system invariants, which can be related to various domain-specific properties of the application. Thus, using HOTTest, it is possible to automatically extract and embed domain-specific requirements into the test models. In this article we describe HOTTest, its principles and methodology, and how it is possible to relate domain-specific properties to specific type constraints. HOTTest is described using the example of HaskellDB, which is a Haskell-based embedded domain-specific language for relational databases. We present an example application of the technique and compare the results to some other commonly used Model-based test automation techniques like ASML-based testing, UML-based testing, and EFSM-based testing.},
journal = {ACM Trans. Softw. Eng. Methodol.},
month = jul,
pages = {242–278},
numpages = {37},
keywords = {test generation tools, model-based testing, domain-specific testing, domain-specific languages, database-specific test case generation, Test case generation, HaskellDB, Haskell}
}

@article{10.1145/2693208.2693226,
author = {Bokil, Prasad and Krishnan, Padmanabhan and Venkatesh, R.},
title = {Achieving Effective Test Suites for Reactive Systems using Specification Mining and Test Suite Reduction Techniques},
year = {2015},
issue_date = {January 2015},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {40},
number = {1},
issn = {0163-5948},
url = {https://doi.org/10.1145/2693208.2693226},
doi = {10.1145/2693208.2693226},
abstract = {Failures in reactive embedded systems are often unacceptable. Moreover, effective testing of such systems to detect potential critical failures is a difficult task.We present an automated black box test suite generation technique for reactive systems. The technique is based on dynamic mining of specifications, in form of a finite state machine (FSM), from initial runs. The set of test cases thus produced contain several redundant test cases, many of which are eliminated by a simple greedy test suite reduction algorithm to give the final test suite. The effectiveness of tests generated by our technique was evaluated using five case studies from the reactive embedded domain. Results indicate that a test suite generated by our technique is promising in terms of effectiveness and scalability. While the test suite reduction algorithm removes redundant test cases, the change in effectiveness of test suites due to this reduction is examined in the experimentation.We present our specification mining based test suite generation technique, the test suite reduction technique and results on industrial case studies.},
journal = {SIGSOFT Softw. Eng. Notes},
month = feb,
pages = {1–8},
numpages = {8},
keywords = {test suite reduction, specification mining, black box testing}
}

@inproceedings{10.1145/2993236.2993257,
author = {Makki, Majid and Van Landuyt, Dimitri and Joosen, Wouter},
title = {Automated regression testing of BPMN 2.0 processes: a capture and replay framework for continuous delivery},
year = {2016},
isbn = {9781450344463},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2993236.2993257},
doi = {10.1145/2993236.2993257},
abstract = {Regression testing is a form of software quality assurance (QA) that involves comparing the behavior of a newer version of a software artifact to its earlier correct behavior, and signaling the QA engineer when deviations are detected. Given the large potential in automated generation and execution of regression test cases for business process models in the context of running systems, powerful tools are required to make this practically feasible, more specifically to limit the potential impact on production systems, and to reduce the manual effort required from QA engineers.  In this paper, we present a regression testing automation framework that implements the capture &amp; replay paradigm in the context of BPMN 2.0, a domain-specific language for modeling and executing business processes. The framework employs parallelization techniques and efficient communication patterns to reduce the performance overhead of capturing. Based on inputs from the QA engineer, it manipulates the BPMN2 model before executing tests for isolating the latter from external dependencies (e.g. human actors or expensive web services) and for avoiding undesired side-effects. Finally, it performs a regression detection algorithm and reports the results to the QA engineer.  We have implemented our framework on top of a BPMN2-compliant execution engine, namely jBPM, and performed functional validations and evaluations of its performance and fault-tolerance. The results, indicating 3.9% average capturing performance overhead, demonstrate that the implemented framework can be the foundation of a practical regression testing tool for BPMN 2.0, and a key enabler for continuous delivery of business process-driven applications and services.},
booktitle = {Proceedings of the 2016 ACM SIGPLAN International Conference on Generative Programming: Concepts and Experiences},
pages = {178–189},
numpages = {12},
keywords = {jBPM, Test Automation, Regression Testing, Performance Overhead, Node Mocking, Business Process Execution, BPMN 2.0},
location = {Amsterdam, Netherlands},
series = {GPCE 2016}
}

@inproceedings{10.1145/3053600.3053636,
author = {Ferme, Vincenzo and Pautasso, Cesare},
title = {Towards Holistic Continuous Software Performance Assessment},
year = {2017},
isbn = {9781450348997},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3053600.3053636},
doi = {10.1145/3053600.3053636},
abstract = {In agile, fast and continuous development lifecycles, software performance analysis is fundamental to confidently release continuously improved software versions. Researchers and industry practitioners have identified the importance of integrating performance testing in agile development processes in a timely and efficient way. However, existing techniques are fragmented and not integrated taking into account the heterogeneous skills of the users developing polyglot distributed software, and their need to automate performance practices as they are integrated in the whole lifecycle without breaking its intrinsic velocity. In this paper we present our vision for holistic continuous software performance assessment, which is being implemented in the BenchFlow tool. BenchFlow enables performance testing and analysis practices to be pervasively integrated in continuous development lifecycle activities. Users can specify performance activities (e.g., standard performance tests) by relying on an expressive Domain Specific Language for objective-driven performance analysis. Collected performance knowledge can be thus reused to speed up performance activities throughout the entire process.},
booktitle = {Proceedings of the 8th ACM/SPEC on International Conference on Performance Engineering Companion},
pages = {159–164},
numpages = {6},
keywords = {performance test, performance analysis, continuous software performance assessment, continuous integration},
location = {L'Aquila, Italy},
series = {ICPE '17 Companion}
}

@inproceedings{10.1145/2422518.2422521,
author = {Sousa, Gustavo C. M. and Costa, F\'{a}bio M. and Clarke, Peter J. and Allen, Andrew A.},
title = {Model-driven development of DSML execution engines},
year = {2012},
isbn = {9781450318020},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2422518.2422521},
doi = {10.1145/2422518.2422521},
abstract = {The combination of domain-specific modeling languages and model-driven engineering techniques hold the promise of a breakthrough in the way applications are developed. By raising the level of abstraction and specializing in building blocks that are familiar in a particular domain, it has the potential to turn domain experts into application developers. Applications are developed as models, which in turn are interpreted at runtime by a specialized execution engine in order to produce the intended behavior. This approach has been successfully applied in different domains, such as communication and smart grid management to execute applications described by models that can be created and changed at runtime. However, each time the approach has to be realized in a different domain, substantial re-implementation has to take place in order to put together an execution engine for the respective DSML. In this paper, we present our work towards a generalization of the approach in the form of a metamodel which captures the domain-independent aspects of runtime model interpretation and allow the definition of domain-specific execution engines.},
booktitle = {Proceedings of the 7th Workshop on Models@run.Time},
pages = {10–15},
numpages = {6},
keywords = {models@run.time, model-driven engineering, metamodeling, domain-specific modeling languages},
location = {Innsbruck, Austria},
series = {MRT '12}
}

@inproceedings{10.1145/3555776.3577829,
author = {G\"{u}demann, Matthias and Schrammel, Peter},
title = {BlueCov: Integrating Test Coverage and Model Checking with JBMC},
year = {2023},
isbn = {9781450395175},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3555776.3577829},
doi = {10.1145/3555776.3577829},
abstract = {Automated test case generation tools help businesses to write tests and increase the safety net provided by high regression test coverage when making code changes. Test generation needs to cover as much as possible of the uncovered code while avoiding generating redundant tests for code that is already covered by an existing test-suite.In this paper we present our work on a tool for the real world application of integrating formal analysis with automatic test case generation. The test case generation is based on coverage analysis using the Java bounded model checker (JBMC). Counterexamples of the model checker can be translated into Java method calls with specific parameters.In order to avoid the generation of redundant tests, it is necessary to measure the coverage in the exact same way as JBMC generates its coverage goals. Each existing coverage measurement tool uses a slightly different instrumentation and thus a different coverage criterion. This makes integration with a test case generator based on formal analysis difficult. Therefore, we developed BlueCov as a specific runtime coverage measurement tool which uses the exact same coverage criteria as JBMC does. This approach also allows for incremental test-case generation, only generating test coverage for previously untested code, e.g., to complete existing test suites.},
booktitle = {Proceedings of the 38th ACM/SIGAPP Symposium on Applied Computing},
pages = {1695–1697},
numpages = {3},
keywords = {Java, test coverage, model-checking},
location = {Tallinn, Estonia},
series = {SAC '23}
}

@inproceedings{10.1145/2884781.2884809,
author = {Menendez, David and Nagarakatte, Santosh},
title = {Termination-checking for LLVM peephole optimizations},
year = {2016},
isbn = {9781450339001},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2884781.2884809},
doi = {10.1145/2884781.2884809},
abstract = {Mainstream compilers contain a large number of peephole optimizations, which perform algebraic simplification of the input program with local rewriting of the code. These optimizations are a persistent source of bugs. Our recent research on Alive, a domain-specific language for expressing peephole optimizations in LLVM, addresses a part of the problem by automatically verifying the correctness of these optimizations and generating C++ code for use with LLVM.This paper identifies a class of non-termination bugs that arise when a suite of peephole optimizations is executed until a fixed point. An optimization can undo the effect of another optimization in the suite, which results in non-terminating compilation. This paper (1) proposes a methodology to detect non-termination bugs with a suite of peephole optimizations, (2) identifies the necessary condition to ensure termination while composing peephole optimizations, and (3) provides debugging support by generating concrete input programs that cause non-terminating compilation. We have discovered 184 optimization sequences, involving 38 optimizations, that cause non-terminating compilation in LLVM with Alive-generated C++ code.},
booktitle = {Proceedings of the 38th International Conference on Software Engineering},
pages = {191–202},
numpages = {12},
keywords = {termination, peephole optimization, compiler verification, alive},
location = {Austin, Texas},
series = {ICSE '16}
}

@inproceedings{10.1145/2670979.2671004,
author = {Li, Kaituo and Joshi, Pallavi and Gupta, Aarti and Ganai, Malay K.},
title = {ReproLite: A Lightweight Tool to Quickly Reproduce Hard System Bugs},
year = {2014},
isbn = {9781450332521},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2670979.2671004},
doi = {10.1145/2670979.2671004},
abstract = {Cloud systems have become ubiquitous today -- they are used to store and process the tremendous amounts of data being generated by Internet users. These systems run on hundreds of commodity machines, and have a huge amount of non-determinism (thousands of threads and hundreds of processes) in their execution. Therefore, bugs that occur in cloud systems are hard to understand, reproduce, and fix. The state-of-the-art of debugging in the industry is to log messages during execution, and refer to those messages later in case of errors. In ReproLite, we augment the already widespread process of debugging using logs by enabling testers to quickly and easily specify the conjectures that they form regarding the cause of an error (or bug) from execution logs, and to also automatically validate those conjectures.ReproLite includes a Domain Specific Language (DSL) that allows testers to specify all aspects of a potential scenario (e.g., specific workloads, execution operations and their orders, environment non-determinism) that causes a given bug. Given such a scenario, ReproLite can enforce the conditions in the scenario during system execution. Potential buggy scenarios can also be automatically generated from a sequence of log messages that a tester believes indicates the cause of the bug. We have experimented ReproLite with 11 bugs from two popular cloud systems, Cassandra and HBase. We were able to reproduce all of the bugs using ReproLite. We report on our experience with using ReproLite on those bugs.},
booktitle = {Proceedings of the ACM Symposium on Cloud Computing},
pages = {1–13},
numpages = {13},
keywords = {Lightweight, Hard System Bug, Debugging, Cloud Computing},
location = {Seattle, WA, USA},
series = {SOCC '14}
}

@inproceedings{10.1145/3550355.3552451,
author = {Khorram, Faezeh and Bousse, Erwan and Mottu, Jean-Marie and Suny\'{e}, Gerson and G\'{o}mez-Abajo, Pablo and Ca\~{n}izares, Pablo C. and Guerra, Esther and de Lara, Juan},
title = {Automatic test amplification for executable models},
year = {2022},
isbn = {9781450394666},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3550355.3552451},
doi = {10.1145/3550355.3552451},
abstract = {Behavioral models are important assets that must be thoroughly verified early in the design process. This can be achieved with manually-written test cases that embed carefully hand-picked domain-specific input data. However, such test cases may not always reach the desired level of quality, such as high coverage or being able to localize faults efficiently. Test amplification is an interesting emergent approach to improve a test suite by automatically generating new test cases out of existing manually-written ones. Yet, while ad-hoc test amplification solutions have been proposed for a few programming languages, no solution currently exists for amplifying the test cases of behavioral models.In this paper, we fill this gap with an automated and generic approach. Given an executable DSL, a conforming behavioral model, and an existing test suite, our approach generates new regression test cases in three steps: (i) generating new test inputs by applying a set of generic modifiers on the existing test inputs; (ii) running the model under test with new inputs and generating assertions from the execution traces; and (iii) selecting the new test cases that increase the mutation score. We provide tool support for the approach atop the Eclipse GEMOC Studio1 and show its applicability in an empirical study. In the experiment, we applied the approach to 71 test suites written for models conforming to two different DSLs, and for 67 of the 71 cases, it successfully improved the mutation score between 3.17% and 54.11% depending on the initial setup.},
booktitle = {Proceedings of the 25th International Conference on Model Driven Engineering Languages and Systems},
pages = {109–120},
numpages = {12},
keywords = {test amplification, regression testing, executable model, executable DSL},
location = {Montreal, Quebec, Canada},
series = {MODELS '22}
}

@article{10.1145/3716309,
author = {Aehle, Max and Bl\"{u}hdorn, Johannes and Sagebaum, Max and Gauger, Nicolas R.},
title = {Forward-Mode Automatic Differentiation of Compiled Programs},
year = {2025},
issue_date = {June 2025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {51},
number = {2},
issn = {0098-3500},
url = {https://doi.org/10.1145/3716309},
doi = {10.1145/3716309},
abstract = {Algorithmic differentiation (AD) is a set of techniques that provide partial derivatives of computer-implemented functions. Such functions can be supplied to state-of-the-art AD tools via their source code, or via intermediate representations produced while compiling their source code.We present the novel AD tool Derivgrind, which augments the machine code of compiled programs with forward-mode AD logic. Derivgrind leverages the Valgrind instrumentation framework for structured access to the machine code, and a shadow memory tool to store dot values. Access to the source code is required at most for the files in which input and output variables are defined.Derivgrind’s versatility mainly comes at the price of reduced run-time performance. According to our extensive regression test suite, Derivgrind produces correct results on GCC- and Clang-compiled programs, including a Python interpreter, with a small number of exceptions. We provide a list of “bit-tricks” that Derivgrind does not handle correctly, some of which actually appear in highly optimized math libraries. As long as differentiating those is avoided, Derivgrind enables black-box forward-mode AD for an unprecedentedly wide range of cross-language software with little integration efforts.},
journal = {ACM Trans. Math. Softw.},
month = may,
articleno = {7},
numpages = {25},
keywords = {Algorithmic Differentiation, Automatic Differentiation, Differentiable Programming, Dynamic Binary Instrumentation, Valgrind, Derivgrind}
}

@inproceedings{10.1145/3425174.3425213,
author = {Toennemann, Jan and Anicul\u{a}esei, Adina and Rausch, Andreas},
title = {Asserting Functional Equivalence between C Code and SCADE Models in Code-to-Model Transformations},
year = {2020},
isbn = {9781450387552},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3425174.3425213},
doi = {10.1145/3425174.3425213},
abstract = {Model-based development is on the rise and tool chains employing automated code generation from models using certified code generators are getting increasingly common. We present an approach which enables the reverse operation and creates an ANSYS SCADE model that is functionally equivalent to the C code. The main motivation behind this development is to enable original equipment manufacturers (OEMs) to further use and maintain legacy code in new development environments, rather than having to re-develop the respective functionality from scratch.While the model transformation itself is performed manually, the testing process is fully automated and enabled the transfer of existing test cases for the C function to the SCADE Test Environment. The presented approach enables white-box testing of the model, requiring the original C implementation and its original test cases as well as a bi-directional mapping of variable names between C code and SCADE model. This is done by extending the original code in a way that generates SCADE test scenarios during runtime, allowing to use these white-box test scenarios to assert functional equivalence of code and model using empirical validation.},
booktitle = {Proceedings of the 5th Brazilian Symposium on Systematic and Automated Software Testing},
pages = {60–68},
numpages = {9},
keywords = {white-box testing, test case generation, test automation, model-driven engineering, equivalence testing, embedded software, code-to-model transformation, C code, ANSYS SCADE model},
location = {Natal, Brazil},
series = {SAST '20}
}

@proceedings{10.1145/3678719,
title = {A-TEST 2024: Proceedings of the 15th ACM International Workshop on Automating Test Case Design, Selection and Evaluation},
year = {2024},
isbn = {9798400711091},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
abstract = {Welcome to the 15th ACM International Workshop on Automating Test Case Design, Selection and Evaluation (A-TEST), co-located with ECOOP and ISSTA 2024, in Vienna, on 19th of September, 2024.  This year's theme of the workshop is "Using DSLs for testing and the testing of DSLs", right at intersection of the topics of the two main conferences.    A-TEST'24 received six submissions, three of which were accepted for presentation. All papers were reviewed by three program committee members. Next to the regular session with papers the workshop features a hands-on session, titled "Testing DSLs with DSLs in Rascal and TESTAR", showcasing state-of-the-art automated testing techniques applied to a DSL implementation in the context of the Rascal language workbench. In particular, it highlights how a (formal) model of a DSL can function as an oracle for regular acceptance tests, and as a driver from scriptless UI testing, using tools like TESTAR.},
location = {Vienna, Austria}
}

@inproceedings{10.1145/3524481.3527239,
author = {Eisner, Daniel and Wuersching, Roland and Schnappinger, Markus and Pretschner, Alexander},
title = {Probe-based syscall tracing for efficient and practical file-level test traces},
year = {2022},
isbn = {9781450392860},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3524481.3527239},
doi = {10.1145/3524481.3527239},
abstract = {Efficiently collecting per-test execution traces is a common prerequisite of dynamic regression test optimization techniques. However, as these test traces are typically recorded through language-specific code instrumentation, non-code artifacts and multi-language source code are usually not included. In contrast, more complete test traces can be obtained by instrumenting operating system calls and thereby tracing all accessed files during a test's execution. Yet, existing test optimization techniques that use syscall tracing are impractical as they either modify the Linux kernel or operate in user space, thus raising transferability, performance, and security concerns. Recent advances in operating system development provide versatile, lightweight, and safe kernel instrumentation frameworks: They allow to trace syscalls by instrumenting probes in the operating system kernel. Probe-based Syscall Tracing (ProST), our novel technique, harnesses this potential to collect file-level test traces that go beyond language boundaries and consider non-code artifacts. To evaluate ProST's efficiency and the completeness of obtained test traces, we perform an empirical study on 25 multi-language open-source software projects and compare our approach to existing language-specific instrumentation techniques. Our results show that most studied projects use source files from multiple languages (22/25) or non-code artifacts during testing (22/25) that are missed by language-specific techniques. With the low execution time overhead of 4.6% compared to non-instrumented test execution, ProST is more efficient than language-specific instrumentation. Furthermore, it collects on average 89% more files on top of those collected by language-specific techniques. Consequently, ProST paves the way for efficiently extracting valuable information through dynamic analysis to better understand and optimize testing in multi-language software systems.},
booktitle = {Proceedings of the 3rd ACM/IEEE International Conference on Automation of Software Test},
pages = {126–137},
numpages = {12},
keywords = {software testing, non-code artifacts, multi-language software, dynamic program analysis},
location = {Pittsburgh, Pennsylvania},
series = {AST '22}
}

@inproceedings{10.1145/3152688.3152692,
author = {Gabrielova, Eugenia},
title = {End-to-end regression testing for distributed systems},
year = {2017},
isbn = {9781450351997},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3152688.3152692},
doi = {10.1145/3152688.3152692},
abstract = {Even with substantial advances in tools and research techniques, distributed systems remain challenging to test. One frustrating aspect of distributed systems development is the resurfacing of old problems due to code changes. Regression test suites replicate previously known bugs and ensure they do not resurface as the code evolves. Conventional unit regression tests miss a substantial amount of distributed system problems; end-to-end testing is almost always required in order to reproduce complex bugs. We describe a framework for regression testing that bridges a gap between local ad-hoc experiments and end-to-end stress testing, potentially lowering the recurrence of critical bugs.},
booktitle = {Proceedings of the 18th Doctoral Symposium of the 18th International Middleware Conference},
pages = {9–12},
numpages = {4},
location = {Las Vegas, Nevada},
series = {Middleware '17}
}

@inproceedings{10.1145/3293882.3330561,
author = {Golagha, Mojdeh and Lehnhoff, Constantin and Pretschner, Alexander and Ilmberger, Hermann},
title = {Failure clustering without coverage},
year = {2019},
isbn = {9781450362245},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3293882.3330561},
doi = {10.1145/3293882.3330561},
abstract = {Developing and integrating software in the automotive industry is a complex task and requires extensive testing. An important cost factor in testing and debugging is the time required to analyze failing tests. In the context of regression testing, usually, large numbers of tests fail due to a few underlying faults. Clustering failing tests with respect to their underlying faults can, therefore, help in reducing the required analysis time. In this paper, we propose a clustering technique to group failing hardware-in-the-loop tests based on non-code-based features, retrieved from three different sources. To effectively reduce the analysis effort, the clustering tool selects a representative test for each cluster. Instead of analyzing all failing tests, testers only inspect the representative tests to find the underlying faults. We evaluated the effectiveness and efficiency of our solution in a major automotive company using 86 regression test runs, 8743 failing tests, and 1531 faults. The results show that utilizing our clustering tool, testers can reduce the analysis time more than 60% and find more than 80% of the faults only by inspecting the representative tests.},
booktitle = {Proceedings of the 28th ACM SIGSOFT International Symposium on Software Testing and Analysis},
pages = {134–145},
numpages = {12},
keywords = {Failure Clustering, Debugging},
location = {Beijing, China},
series = {ISSTA 2019}
}

@article{10.1145/3729362,
author = {Jang, Sujin and Ryou, Yeonhee and Lee, Heewon and Heo, Kihong},
title = {UnitCon: Synthesizing Targeted Unit Tests for Java Runtime Exceptions},
year = {2025},
issue_date = {July 2025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {2},
number = {FSE},
url = {https://doi.org/10.1145/3729362},
doi = {10.1145/3729362},
abstract = {We present UnitCon, a system for synthesizing targeted unit testsfor runtime exceptions in Java programs. Targeted unit tests aim to reveal a bug at a specific location in the program under test. This capability benefits various tasks in software development, such as patch testing, crash reproduction, or static analysis alarm inspection. However, conventional unit test generation tools are mainly designed for regression tests by maximizing code coverage; hence they are not effective at such target-specific tasks. In this paper, we propose a novel synthesis technique that effectively guides the search for targeted unit tests. The key idea is to use static analysis to prune and prioritize the search space by estimating the semantics of candidate test cases. This allows us to efficiently focus on promising unit tests that are likely to trigger runtime exceptions at the target location. According to our experiments on a suite of Java programs, our approach outperforms the state-of-the-art unit test generation tools. We also applied UnitCon for inspecting static analysis alarms for null pointer exceptions (NPEs) in 51 open-source projects and discovered 21 previously unknown NPE bugs.},
journal = {Proc. ACM Softw. Eng.},
month = jun,
articleno = {FSE092},
numpages = {22},
keywords = {Program analysis, Program synthesis, Software testing}
}

@inproceedings{10.1145/3393527.3393531,
author = {Zhang, Yuxiang and Chen, Kang and Liu, Weidong},
title = {Online Judge for FPGA-based Lab Projects in Computer Organization Course},
year = {2020},
isbn = {9781450375344},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3393527.3393531},
doi = {10.1145/3393527.3393531},
abstract = {While online judge systems are widely used in programming related courses, they are rarely used in hardware-related courses such as the computer organization course requiring the digital circuit design. With the widely available FPGA hardware, students now have fewer difficulties in building hardware by only writing hardware description language (HDL) code. We have built a cloud-based lab environment that students can build CPUs online by submitting their Verilog HDL code. Our HDL online judge system is applied to test the submitted code. It greatly reduces the efforts of checking the code manually.},
booktitle = {Proceedings of the ACM Turing Celebration Conference - China},
pages = {15–20},
numpages = {6},
keywords = {Online Judge, FPGA, Digital Circuit, Computer Organization},
location = {Hefei, China},
series = {ACM TURC '20}
}

@article{10.1145/1416563.1416566,
author = {Huang, Shan Shan and Zook, David and Smaragdakis, Yannis},
title = {Domain-specific languages and program generation with meta-AspectJ},
year = {2008},
issue_date = {November 2008},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {18},
number = {2},
issn = {1049-331X},
url = {https://doi.org/10.1145/1416563.1416566},
doi = {10.1145/1416563.1416566},
abstract = {Meta-AspectJ (MAJ) is a language for generating AspectJ programs using code templates. MAJ itself is an extension of Java, so users can interleave arbitrary Java code with AspectJ code templates. MAJ is a structured metaprogramming tool: a well-typed generator implies a syntactically correct generated program. MAJ promotes a methodology that combines aspect-oriented and generative programming. A valuable application is in implementing small domain-specific language extensions as generators using unobtrusive annotations for syntax extension and AspectJ as a back-end. The advantages of this approach are twofold. First, the generator integrates into an existing software application much as a regular API or library, instead of as a language extension. Second, a mature language implementation is easy to achieve with little effort since AspectJ takes care of the low-level issues of interfacing with the base Java language.In addition to its practical value, MAJ offers valuable insights to metaprogramming tool designers. It is a mature metaprogramming tool for AspectJ (and, by extension, Java): a lot of emphasis has been placed on context-sensitive parsing and error reporting. As a result, MAJ minimizes the number of metaprogramming (quote/unquote) operators and uses type inference to reduce the need to remember type names for syntactic entities.},
journal = {ACM Trans. Softw. Eng. Methodol.},
month = nov,
articleno = {6},
numpages = {32},
keywords = {program verification, program transformation, program synthesis, language extensions, domain-specific languages, Metaprogramming}
}

@article{10.1145/3617175,
author = {Golmohammadi, Amid and Zhang, Man and Arcuri, Andrea},
title = {Testing RESTful APIs: A Survey},
year = {2023},
issue_date = {January 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {33},
number = {1},
issn = {1049-331X},
url = {https://doi.org/10.1145/3617175},
doi = {10.1145/3617175},
abstract = {In industry, RESTful APIs are widely used to build modern Cloud Applications. Testing them is challenging, because not only do they rely on network communications, but also they deal with external services like databases. Therefore, there has been a large amount of research sprout in recent years on how to automatically verify this kind of web services. In this article, we present a comprehensive review of the current state-of-the-art in testing RESTful APIs based on the analysis of 92 scientific articles. These articles were gathered by utilizing search queries formulated around the concept of RESTful API testing on seven popular databases. We eliminated irrelevant articles based on our predefined criteria and conducted a snowballing phase to minimize the possibility of missing any relevant paper. This survey categorizes and summarizes the existing scientific work on testing RESTful APIs and discusses the current challenges in the verification of RESTful APIs. This survey clearly shows an increasing interest among researchers in this field, from 2017 onward. However, there are still a lot of open research challenges to overcome.},
journal = {ACM Trans. Softw. Eng. Methodol.},
month = nov,
articleno = {27},
numpages = {41},
keywords = {web service, fuzzing, test case generation, testing, API, REST, literature review, Survey}
}

@inproceedings{10.1145/1866307.1866358,
author = {Henecka, Wilko and K \"{o}gl, Stefan and Sadeghi, Ahmad-Reza and Schneider, Thomas and Wehrenberg, Immo},
title = {TASTY: tool for automating secure two-party computations},
year = {2010},
isbn = {9781450302456},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1866307.1866358},
doi = {10.1145/1866307.1866358},
abstract = {Secure two-party computation allows two untrusting parties to jointly compute an arbitrary function on their respective private inputs while revealing no information beyond the outcome. Existing cryptographic compilers can automatically generate secure computation protocols from high-level specifications, but are often limited in their use and efficiency of generated protocols as they are based on either garbled circuits or (additively) homomorphic encryption only.In this paper we present TASTY, a novel tool for automating, i.e., describing, generating, executing, benchmarking, and comparing, efficient secure two-party computation protocols. TASTY is a new compiler that can generate protocols based on homomorphic encryption and efficient garbled circuits as well as combinations of both, which often yields the most efficient protocols available today. The user provides a high-level description of the computations to be performed on encrypted data in a domain-specific language. This is automatically transformed into a protocol. TASTY provides most recent techniques and optimizations for practical secure two-party computation with low online latency. Moreover, it allows to efficiently evaluate circuits generated by the well-known Fairplay compiler.We use TASTY to compare protocols for secure multiplication based on homomorphic encryption with those based on garbled circuits and highly efficient Karatsuba multiplication. Further, we show how TASTY improves the online latency for securely evaluating the AES functionality by an order of magnitude compared to previous software implementations. TASTY allows to automatically generate efficient secure protocols for many privacy-preserving applications where we consider the use cases for private set intersection and face recognition protocols.},
booktitle = {Proceedings of the 17th ACM Conference on Computer and Communications Security},
pages = {451–462},
numpages = {12},
keywords = {secure function evaluation, homomorphic encryption, garbled circuits, cryptography, compiler},
location = {Chicago, Illinois, USA},
series = {CCS '10}
}

@inproceedings{10.1145/3375959.3375967,
author = {Wolde, Behailu Getachew and Boltana, Abiot Sinamo},
title = {Combinatorial Testing Approach for Cloud Mobility Service},
year = {2020},
isbn = {9781450372633},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3375959.3375967},
doi = {10.1145/3375959.3375967},
abstract = {Currently, software product becomes an essential component in running many stakeholders' activities. For instance, the industries mostly use cloud services to execute their important business functionality. However, by a few input's parameter interacting, this functionality can be pended. Such constraint poses challenging to cover various features of failure especially in ensuring cloud application. One way is to devise a strategy to cover input parameters' characteristics based on Combinatorial testing approach. This technique includes all possible combinations of test inputs for detecting bugs on the System Under Test (SUT). The paper explains the Combinatorial covering arrays to generate relatively exhaustive testing by modeling features of sample services using Feature IDE plugin in Eclipse IDE. This way, we build the input domain model to represent coverage of the existing mobility service running on NEMo Mobility cloud platform. Using this model, covering arrays is applied to generate t-way test cases by leveraging IPOg algorithm, which is implemented in a CiTLab. As a test case management, the JUnit testing framework uses test stubs to validate the test methods of generated test cases on the specified service (SUT).},
booktitle = {Proceedings of the 2019 2nd Artificial Intelligence and Cloud Computing Conference},
pages = {6–13},
numpages = {8},
keywords = {Software Testing, Feature Model, Combinatorial Testing, Cloud Mobility Service, CiTLAB},
location = {Kobe, Japan},
series = {AICCC '19}
}

@inproceedings{10.1145/3379597.3387482,
author = {Pinto, Gustavo and Miranda, Breno and Dissanayake, Supun and d'Amorim, Marcelo and Treude, Christoph and Bertolino, Antonia},
title = {What is the Vocabulary of Flaky Tests?},
year = {2020},
isbn = {9781450375177},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3379597.3387482},
doi = {10.1145/3379597.3387482},
abstract = {Flaky tests are tests whose outcomes are non-deterministic. Despite the recent research activity on this topic, no effort has been made on understanding the vocabulary of flaky tests. This work proposes to automatically classify tests as flaky or not based on their vocabulary. Static classification of flaky tests is important, for example, to detect the introduction of flaky tests and to search for flaky tests after they are introduced in regression test suites.We evaluated performance of various machine learning algorithms to solve this problem. We constructed a data set of flaky and non-flaky tests by running every test case, in a set of 64k tests, 100 times (6.4 million test executions). We then used machine learning techniques on the resulting data set to predict which tests are flaky from their source code. Based on features, such as counting stemmed tokens extracted from source code identifiers, we achieved an F-measure of 0.95 for the identification of flaky tests. The best prediction performance was obtained when using Random Forest and Support Vector Machines. In terms of the code identifiers that are most strongly associated with test flakiness, we noted that job, action, and services are commonly associated with flaky tests. Overall, our results provides initial yet strong evidence that static detection of flaky tests is effective.},
booktitle = {Proceedings of the 17th International Conference on Mining Software Repositories},
pages = {492–502},
numpages = {11},
keywords = {Text classification, Test flakiness, Regression testing},
location = {Seoul, Republic of Korea},
series = {MSR '20}
}

@inproceedings{10.1145/3183440.3195036,
author = {Santos, Ernani C\'{e}sar Dos and Vilain, Patr\'{\i}cia and Longo, Douglas Hiura},
title = {A systematic literature review to support the selection of user acceptance testing techniques},
year = {2018},
isbn = {9781450356633},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3183440.3195036},
doi = {10.1145/3183440.3195036},
abstract = {User Acceptance Testing (UAT) aims to determine whether or not a software satisfies users acceptance criteria. Although some studies have used acceptance tests as software requirements, no previous study has collected information about available UAT techniques and established a comparison of them, to support an organization in the selection of one over another. This work presents a Systematic Literature Review on UAT to find out available techniques and compare their main features. We selected 80 studies and found out 21 UAT techniques. As result, we created a comparative table summarizing these techniques and their features.},
booktitle = {Proceedings of the 40th International Conference on Software Engineering: Companion Proceeedings},
pages = {418–419},
numpages = {2},
keywords = {classification, features, techniques, user acceptance testing},
location = {Gothenburg, Sweden},
series = {ICSE '18}
}

@article{10.1145/3678169,
author = {Ruan, Haifeng and Noller, Yannic and Tizpaz-Niari, Saeid and Chattopadhyay, Sudipta and Roychoudhury, Abhik},
title = {Timing Side-Channel Mitigation via Automated Program Repair},
year = {2024},
issue_date = {November 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {33},
number = {8},
issn = {1049-331X},
url = {https://doi.org/10.1145/3678169},
doi = {10.1145/3678169},
abstract = {Side-channel vulnerability detection has gained prominence recently due to Spectre and Meltdown attacks. Techniques for side-channel detection range from fuzz testing to program analysis and program composition. Existing side-channel mitigation techniques repair the vulnerability at the IR/binary level or use runtime monitoring solutions. In both cases, the source code itself is not modified, can evolve while keeping the vulnerability, and the developer would get no feedback on how to develop secure applications in the first place. Thus, these solutions do not help the developer understand the side-channel risks in her code and do not provide guidance to avoid code patterns with side-channel risks. In this article, we present Pendulum, the first approach for automatically locating and repairing side-channel vulnerabilities in the source code, specifically for timing side channels. Our approach uses a quantitative estimation of found vulnerabilities to guide the fix localization, which goes hand-in-hand with a pattern-guided repair. Our evaluation shows that Pendulum can repair a large number of side-channel vulnerabilities in real-world applications. Overall, our approach integrates vulnerability detection, quantization, localization, and repair into one unified process. This also enhances the possibility of our side-channel mitigation approach being adopted into programmingenvironments.},
journal = {ACM Trans. Softw. Eng. Methodol.},
month = nov,
articleno = {206},
numpages = {27},
keywords = {side-channel vulnerability, program repair, software engineering}
}

@inproceedings{10.1145/3510003.3510176,
author = {Gerten, Michael C. and Marsh, Alexis L. and Lathrop, James I. and Cohen, Myra B. and Miner, Andrew S. and Klinge, Titus H.},
title = {Inference and test generation using program invariants in chemical reaction networks},
year = {2022},
isbn = {9781450392211},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3510003.3510176},
doi = {10.1145/3510003.3510176},
abstract = {Chemical reaction networks (CRNs) are an emerging distributed computational paradigm where programs are encoded as a set of abstract chemical reactions. CRNs can be compiled into DNA strands which perform the computations in vitro, creating a foundation for intelligent nanodevices. Recent research proposed a software testing framework for stochastic CRN programs in simulation, however, it relies on existing program specifications. In practice, specifications are often lacking and when they do exist, transforming them into test cases is time-intensive and can be error prone. In this work, we propose an inference technique called ChemFlow which extracts 3 types of invariants from an existing CRN model. The extracted invariants can then be used for test generation or model validation against program implementations. We applied ChemFlow to 13 CRN programs ranging from toy examples to real biological models with hundreds of reactions. We find that the invariants provide strong fault detection and often exhibit less flakiness than specification derived tests. In the biological models we showed invariants to developers and they confirmed that some of these point to parts of the model that are biologically incorrect or incomplete suggesting we may be able to use ChemFlow to improve model quality.},
booktitle = {Proceedings of the 44th International Conference on Software Engineering},
pages = {1193–1205},
numpages = {13},
keywords = {chemical reaction networks, invariants, petri nets, test generation},
location = {Pittsburgh, Pennsylvania},
series = {ICSE '22}
}

@article{10.1145/3468504,
author = {Sundelin, Anders and Gonzalez-huerta, Javier and Wnuk, Krzysztof and Gorschek, Tony},
title = {Towards an Anatomy of Software Craftsmanship},
year = {2021},
issue_date = {January 2022},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {31},
number = {1},
issn = {1049-331X},
url = {https://doi.org/10.1145/3468504},
doi = {10.1145/3468504},
abstract = {Context: The concept of software craftsmanship has early roots in computing, and in 2009, the Manifesto for Software Craftsmanship was formulated as a reaction to how the Agile methods were practiced and taught. But software craftsmanship has seldom been studied from a software engineering perspective.Objective: The objective of this article is to systematize an anatomy of software craftsmanship through literature studies and a longitudinal case study.Method: We performed a snowballing literature review based on an initial set of nine papers, resulting in&nbsp;18 papers and 11 books. We also performed a case study following seven years of software development of a product for the financial market, eliciting qualitative, and quantitative results. We used thematic coding to synthesize the results into categories.Results: The resulting anatomy is centered around four themes, containing 17 principles and 47 hierarchical practices connected to the principles. We present the identified practices based on the experiences gathered from the case study, triangulating with the literature results.Conclusion: We provide our systematically derived anatomy of software craftsmanship with the goal of inspiring more research into the principles and practices of software craftsmanship and how these relate to other principles within software engineering in general.},
journal = {ACM Trans. Softw. Eng. Methodol.},
month = sep,
articleno = {6},
numpages = {49},
keywords = {deliberate practice, principles of software development, Software craftsmanship}
}

@article{10.1145/3759454,
author = {Berardinelli, Luca and Muttillo, Vittoriano and Eramo, Romina and Bruneliere, Hugo and Rahimi, Abbas and Cicchetti, Antonio and Giner-Miguelez, Joan and G\'{o}mez, Abel and Potena, Pasqualina and Saadatmand, Mehrdad},
title = {Model Driven Engineering, Artificial Intelligence, and DevOps for Software and Systems Engineering: A Systematic Mapping Study of Synergies and Challenges},
year = {2025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
issn = {1049-331X},
url = {https://doi.org/10.1145/3759454},
doi = {10.1145/3759454},
abstract = {This paper presents a systematic mapping study classifying existing scientific contributions on synergies of Model Driven Engineering (MDE), Artificial Intelligence/Machine Learning (AI/ML), and DevOps, with the overall objective of supporting the continuous development of Cyber-Physical Systems (CPSs). We collected papers from bibliographic sources and selected primary studies to analyse. Then, we characterised and classified the current state of the art, focusing on 1) main aspects already tackled at the intersection of at least two of the three studied areas, and 2) findings emerging from the analysis as a framework for potential future research, notably regarding the integration of the three studied areas. The results reveal that few approaches combine MDE, AI/ML, and DevOps for software and systems engineering. In contrast, several approaches have combined two of them, specifically MDE and DevOps. Approaches combining AI/ML with MDE or DevOps are also becoming more frequent and will most likely continue to progress in the future. These synergies cover a range of engineering activities, from requirements and design to monitoring, maintenance, and evolution. Open research challenges include advancing AI/ML, MDE, and DevOps integration, supporting scalable, data-oriented solutions, proposing new continuous engineering methods, and adapting DevOps practices to diverse systems.},
note = {Just Accepted},
journal = {ACM Trans. Softw. Eng. Methodol.},
month = aug,
keywords = {Model-Driven Engineering, DevOps, Continuous Integration, Artificial Intelligence, Machine Learning, Cyber-Physical Systems, Internet of Things, Cloud Computing}
}

@proceedings{10.1145/3622780,
title = {SPLASH-E 2023: Proceedings of the 2023 ACM SIGPLAN International Symposium on SPLASH-E},
year = {2023},
isbn = {9798400703904},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
abstract = {The SPLASH-E symposium is a forum for researchers and educators to discuss   the intersection of education and the core SPLASH research areas: systems, programming languages, and their applications. We investigate how to deliver systems   and programming language concepts to students, how systems and languages can   aid in education broadly, and how to prepare students to apply these concepts to   their later work in industry or academia.},
location = {Cascais, Portugal}
}

@proceedings{10.1145/3637792,
title = {ICSED '23: Proceedings of the 2023 5th International Conference on Software Engineering and Development},
year = {2023},
isbn = {9798400709463},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Singapore, Singapore}
}

@inproceedings{10.1145/3623476.3623527,
author = {Heithoff, Malte and Jansen, Nico and Kirchhof, J\"{o}rg Christian and Michael, Judith and Rademacher, Florian and Rumpe, Bernhard},
title = {Deriving Integrated Multi-Viewpoint Modeling Languages from Heterogeneous Modeling Languages: An Experience Report},
year = {2023},
isbn = {9798400703966},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3623476.3623527},
doi = {10.1145/3623476.3623527},
abstract = {In modern systems engineering, domain experts increasingly utilize models to define domain-specific viewpoints in a highly interdisciplinary context. Despite considerable advances in developing model composition techniques, their integration in a largely heterogeneous language landscape still poses a challenge. Until now, composition in practice mainly focuses on developing foundational language components or applying language composition in smaller scenarios, while the application to extensive, heterogeneous languages is still missing. In this paper, we report on our experiences of composing sophisticated modeling languages using different techniques simultaneously in the context of heterogeneous application areas such as assistive systems and cyber-physical systems in the Internet of Things. We apply state-of-the-art practices, show their realization, and discuss which techniques are suitable for particular modeling scenarios. Pushing model composition to the next level by integrating complex, heterogeneous languages is essential for establishing modeling languages for highly interdisciplinary development teams.},
booktitle = {Proceedings of the 16th ACM SIGPLAN International Conference on Software Language Engineering},
pages = {194–207},
numpages = {14},
keywords = {Software Language Engineering, Reuse, Language Families, Language Composition, Internet of Things, Domain-Specific Languages, Assistive Systems},
location = {Cascais, Portugal},
series = {SLE 2023}
}

@inproceedings{10.1145/3184558.3191656,
author = {Vu, Henry and Fertig, Tobias and Braun, Peter},
title = {Verification of Hypermedia Characteristic of RESTful Finite-State Machines},
year = {2018},
isbn = {9781450356404},
publisher = {International World Wide Web Conferences Steering Committee},
address = {Republic and Canton of Geneva, CHE},
url = {https://doi.org/10.1145/3184558.3191656},
doi = {10.1145/3184558.3191656},
abstract = {Being an architectural style rather than a specification or a standard, the proper design of REpresentational State Transfer (REST) APIs is not trivial, since developers have to deal with a flood of recommendations and best practices, especially the proper application of the hypermedia constraint requires some decent experience. Furthermore, testing RESTful APIs is a missing topic within literature and especially, hypermedia testing is not mentioned at all. To deal with this state of affairs, we have elaborated a Model-Driven Software Development (MDSD) approach for creating RESTful APIs. As this project matured, we also explored the possibility of Model-Driven Testing (MDT). This work addresses the challenges of hypermedia testing and proposes approaches to overcome them with MDT techniques. We present the results of hypermedia testing for RESTful APIs using a model verification approach that were discovered within our research. MDT enables the verification of the underlying model of a RESTful API and ensuring its correctness before initiating any code generation. Therefore, we can prevent a poorly designed model from being transformed into a poorly designed RESTful API.},
booktitle = {Companion Proceedings of the The Web Conference 2018},
pages = {1881–1886},
numpages = {6},
keywords = {MDSD, MDT, REST, RESTful applications, RESTful systems, hypermedia, hypermedia testing},
location = {Lyon, France},
series = {WWW '18}
}

@inproceedings{10.1109/ICSE-SEIP.2019.00035,
author = {Giorgi, Fabio and Paulisch, Frances},
title = {Transition towards continuous delivery in the healthcare domain},
year = {2019},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/ICSE-SEIP.2019.00035},
doi = {10.1109/ICSE-SEIP.2019.00035},
abstract = {Continuous Delivery is meanwhile well-established in many parts of the software industry. In a transition towards continuous delivery in the healthcare domain, there are a number of additional challenges that should be addressed. We present how we have addressed some of these challenges and highlight some potential research topics that could be addressed in this space to make further progress in this important area. Although our focus is on the healthcare domain, the approach and the research topics are applicable also to a broad range of other application domains.},
booktitle = {Proceedings of the 41st International Conference on Software Engineering: Software Engineering in Practice},
pages = {253–254},
numpages = {2},
keywords = {test-driven development, test automation, pair-programming, domain-driven design, deployment pipeline, continuous delivery, behavior-driven development, agile},
location = {Montreal, Quebec, Canada},
series = {ICSE-SEIP '19}
}

@inproceedings{10.1145/2038558.2038583,
author = {D\'{\i}az, Oscar and Puente, Gorka},
title = {Wiki scaffolding: helping organizations to set up wikis},
year = {2011},
isbn = {9781450309097},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2038558.2038583},
doi = {10.1145/2038558.2038583},
abstract = {Organizational wikis are framed by an existing organization. This makes these wikis be especially vigilant upon (1) facilitating the alignment of the wiki with organizational practices, (2) engaging management or (3), promoting employees' participation. To this end, we advocate for the use of "wiki scaffoldings". A wiki scaffolding is a wiki installation that is provided at the onset, before any contribution is made. It aims to frame wiki contribution along the concerns already known in the hosting organization in terms of glossaries, schedules, organigrams and the like. Thus, wiki contributions do not start from scratch but within a known setting. This paper introduces a language to capture wiki scaffolding in terms of FreeMind's mind maps. These maps can later be mapped into wiki installations in MediaWiki. The paper seeks to validate the approach in a twofold manner. Firstly, by providing literature quotes that suggest the need for scaffolding. Secondly, by providing scaffolding examples for wikis reported in the literature. The findings suggest that wiki scaffolding can be useful to smoothly align wiki activity along the practices of the hosting organization from the onset.},
booktitle = {Proceedings of the 7th International Symposium on Wikis and Open Collaboration},
pages = {154–162},
numpages = {9},
keywords = {DSL, collaboration, wiki scaffolding, wikis},
location = {Mountain View, California},
series = {WikiSym '11}
}

@article{10.1145/3523056,
author = {Troya, Javier and Segura, Sergio and Burgue\~{n}o, Lola and Wimmer, Manuel},
title = {Model Transformation Testing and Debugging: A Survey},
year = {2022},
issue_date = {April 2023},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {55},
number = {4},
issn = {0360-0300},
url = {https://doi.org/10.1145/3523056},
doi = {10.1145/3523056},
abstract = {Model transformations are the key technique in Model-Driven Engineering (MDE) to manipulate and construct models. As a consequence, the correctness of software systems built with MDE approaches relies mainly on the correctness of model transformations, and thus, detecting and locating bugs in model transformations have been popular research topics in recent years. This surge of work has led to a vast literature on model transformation testing and debugging, which makes it challenging to gain a comprehensive view of the current state-of-the-art. This is an obstacle for newcomers to this topic and MDE practitioners to apply these approaches. This article presents a survey on testing and debugging model transformations based on the analysis of 140&nbsp;papers on the topics. We explore the trends, advances, and evolution over the years, bringing together previously disparate streams of work and providing a comprehensive view of these thriving areas. In addition, we present a conceptual framework to understand and categorize the different proposals. Finally, we identify several open research challenges and propose specific action points for the model transformation community.},
journal = {ACM Comput. Surv.},
month = nov,
articleno = {72},
numpages = {39},
keywords = {survey, debugging, testing, Model transformation}
}

@inproceedings{10.1145/3350768.3350790,
author = {Diniz, Thomaz and Alves, Everton L.G. and Silva, Anderson G.F. and Andrade, Wilkerson L.},
title = {Reducing the Discard of MBT Test Cases using Distance Functions},
year = {2019},
isbn = {9781450376518},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3350768.3350790},
doi = {10.1145/3350768.3350790},
abstract = {Model-Based Testing (MBT) is used for generating test suites from system models. However, as software evolves, its models tend to be updated, which often leads to obsolete test cases that are discarded. Test case discard can be very costly since essential data, such as execution history, are lost. In this paper, we investigate the use of distance functions to help to reduce the discard of MBT tests. For that, we ran a series of empirical studies using artifacts from industrial systems, and we analyzed how ten distance functions can classify the impact of MBT-centred use case edits. Our results showed that distance functions are effective for identifying low impact edits that lead to test cases that can be updated with little effort. Moreover, we found the optimal configuration for each distance function. Finally, we ran a case study that showed that, by using distance functions, we could reduce the discard of test cases by 15%.},
booktitle = {Proceedings of the XXXIII Brazilian Symposium on Software Engineering},
pages = {337–346},
numpages = {10},
keywords = {test suite evolution, distance functions, agile development, MBT},
location = {Salvador, Brazil},
series = {SBES '19}
}

@proceedings{10.1145/3640310,
title = {MODELS '24: Proceedings of the ACM/IEEE 27th International Conference on Model Driven Engineering Languages and Systems},
year = {2024},
isbn = {9798400705045},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Linz, Austria}
}

@proceedings{10.1145/3687997,
title = {SLE '24: Proceedings of the 17th ACM SIGPLAN International Conference on Software Language Engineering},
year = {2024},
isbn = {9798400711800},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
abstract = {Welcome to the 17th ACM SIGPLAN International Conference on Software Language Engineering (SLE), held in Pasadena, California, USA, October 20–21 2024, as part of SPLASH 2024. The SLE conference is devoted to the principles of software languages: their design, their implementation, and their evolution.},
location = {Pasadena, CA, USA}
}

@inproceedings{10.5555/2555523.2555535,
author = {da Silva, Elias Adriano Nogueira and Fortes, Renata P. M. and Lucr\'{e}dio, Daniel},
title = {A model-driven approach for promoting cloud PaaS portability},
year = {2013},
publisher = {IBM Corp.},
address = {USA},
abstract = {Cloud computing has become an important research subject in software engineering. Among the many research gaps related to this new computing model is the lack of portability between cloud platforms, which generates the Lock-In problem. The Lock-In is the difficulty in migrating data and applications from a cloud platform to another. Current attempts to address this problem revolve around standardization of APIs and frameworks. We propose a different path, using model-driven engineering (MDE). We selected two cloud platforms and built a DSL and a set of automated transformations that generate code for each platform, based on a single portable model. We present the results of two studies. In a first study, subjects were asked to use the two versions of the same application, each one generated for a different platform from a single model. The subjects did not notice any difference between the two versions in terms of functionality. In a second study, we observed that besides facilitating cloud portability, MDE can increase productivity and reusability. These results indicate that MDE may be an alternative to standardization, not only helping to solve portability problems but also leading to additional benefits.},
booktitle = {Proceedings of the 2013 Conference of the Center for Advanced Studies on Collaborative Research},
pages = {92–105},
numpages = {14},
location = {Ontario, Canada},
series = {CASCON '13}
}

@inproceedings{10.1145/3350768.3351300,
author = {Kudo, Taciana Novo and Bulc\~{a}o-Neto, Renato F. and Vincenzi, Auri M. R.},
title = {A Conceptual Metamodel to Bridging Requirement Patterns to Test Patterns},
year = {2019},
isbn = {9781450376518},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3350768.3351300},
doi = {10.1145/3350768.3351300},
abstract = {Requirement patterns represent an abstraction of an application's behaviors and services that, in turn, may be replicated in similar applications. However, there has been a lack of efforts exploiting the benefits of requirement patterns in other phases of the software development life cycle, besides the requirements engineering itself. To address this gap, we propose the Software Pattern MetaModel (SoPaMM) that bridges requirement patterns to groups of scenarios with similar behaviors in the form of test patterns. SoPaMM allows the description of the behavior of a requirement pattern through a time executable and easy-to-use language aiming at the automatic generation of test patterns. Using SoPaMM, we model and implement a behavior-driven functional requirement pattern for a web-based user authentication application. Our preliminary results point out that a requirement pattern can be an executable specification capable of generating automated tests.},
booktitle = {Proceedings of the XXXIII Brazilian Symposium on Software Engineering},
pages = {155–160},
numpages = {6},
keywords = {behavior, metamodeling, requirement pattern, reuse, test pattern},
location = {Salvador, Brazil},
series = {SBES '19}
}

@inproceedings{10.1145/3468264.3468605,
author = {Wu, Xiuheng and Zhu, Chenguang and Li, Yi},
title = {DIFFBASE: a differential factbase for effective software evolution management},
year = {2021},
isbn = {9781450385626},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3468264.3468605},
doi = {10.1145/3468264.3468605},
abstract = {Numerous tools and techniques have been developed to extract and analyze information from software development artifacts. Yet, there is a lack of effective method to process, store, and exchange information among different analyses. In this paper, we propose differential factbase, a uniform exchangeable representation supporting efficient querying and manipulation, based on the existing concept of program facts. We consider program changes as first-class objects, which establish links between intra-version facts of single program snapshots and provide insights on how certain artifacts evolve over time via inter-version facts. We implement a series of differential fact extractors supporting different programming languages and platforms, and demonstrate with usage scenarios the benefits of adopting differential facts in supporting software evolution management.},
booktitle = {Proceedings of the 29th ACM Joint Meeting on European Software Engineering Conference and Symposium on the Foundations of Software Engineering},
pages = {503–515},
numpages = {13},
keywords = {software maintenance, reverse engineering, program facts, Software evolution},
location = {Athens, Greece},
series = {ESEC/FSE 2021}
}

@proceedings{10.1145/2997364,
title = {SLE 2016: Proceedings of the 2016 ACM SIGPLAN International Conference on Software Language Engineering},
year = {2016},
isbn = {9781450344470},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Amsterdam, Netherlands}
}

@proceedings{10.5555/3623288,
title = {ICSE-NIER '23: Proceedings of the 45th International Conference on Software Engineering: New Ideas and Emerging Results},
year = {2023},
isbn = {9798350300390},
publisher = {IEEE Press},
abstract = {ICSE is the leading and by far the largest conference in Software Engineering, attracting researchers, practitioners and students from around the world. ICSE2023 is co-located with 10 conferences and symposia this year, many long-established and prestigious venues in their own right.},
location = {Melbourne, Australia}
}

@inproceedings{10.1145/3183440.3183480,
author = {Kr\"{o}her, Christian and El-Sharkawy, Sascha and Schmid, Klaus},
title = {KernelHaven: an experimentation workbench for analyzing software product lines},
year = {2018},
isbn = {9781450356633},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3183440.3183480},
doi = {10.1145/3183440.3183480},
abstract = {Systematic exploration of hypotheses is a major part of any empirical research. In software engineering, we often produce unique tools for experiments and evaluate them independently on different data sets. In this paper, we present KernelHaven as an experimentation workbench supporting a significant number of experiments in the domain of static product line analysis and verification. It addresses the need for extracting information from a variety of artifacts in this domain by means of an open plug-in infrastructure. Available plug-ins encapsulate existing tools, which can now be combined efficiently to yield new analyses. As an experimentation workbench, it provides configuration-based definitions of experiments, their documentation, and technical services, like parallelization and caching. Hence, researchers can abstract from technical details and focus on the algorithmic core of their research problem.KernelHaven supports different types of analyses, like correctness checks, metrics, etc., in its specific domain. The concepts presented in this paper can also be transferred to support researchers of other software engineering domains. The infrastructure is available under Apache 2.0: https://github.com/KernelHaven. The plug-ins are available under their individual licenses.Video: https://youtu.be/IbNc-H1NoZU},
booktitle = {Proceedings of the 40th International Conference on Software Engineering: Companion Proceeedings},
pages = {73–76},
numpages = {4},
keywords = {empirical software engineering, software product line analysis, static analysis, variability extraction},
location = {Gothenburg, Sweden},
series = {ICSE '18}
}

@proceedings{10.1145/3732771,
title = {SLE '25: Proceedings of the 18th ACM SIGPLAN International Conference on Software Language Engineering},
year = {2025},
isbn = {9798400718847},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Koblenz, Germany}
}

@proceedings{10.1145/3625223,
title = {RSP '23: Proceedings of the 34th International Workshop on Rapid System Prototyping},
year = {2023},
isbn = {9798400704109},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Hamburg, Germany}
}

@inproceedings{10.1145/2997364.2997367,
author = {Meyers, Bart and Denil, Joachim and D\'{a}vid, Istv\'{a}n and Vangheluwe, Hans},
title = {Automated testing support for reactive domain-specific modelling languages},
year = {2016},
isbn = {9781450344470},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2997364.2997367},
doi = {10.1145/2997364.2997367},
abstract = {Domain-specific modelling languages (DSML) enable domain users  to model systems in their problem domain, using concepts and  notations they are familiar with. The process of domain-specific  modelling (DSM) consists of two stages: a language engineering stage where a DSML is created, and a system modelling stage where  the DSML is used. Because techniques such as metamodelling and  model transformation allow for a efficient creation of DSMLs, and  using DSMLs significantly increases productivity, DSM is very suitable for early prototyping. Many systems that are modelled  using DSMLs are reactive, meaning that during their execution, they  respond to external input. Because of the complexity of input and  response behaviour of reactive systems, it is desirable to test models  as early as possible. However, while dedicated testing support for  specific DSMLs has been provided, no systematic support exists for  testing DSML models according to DSM principles.   In this paper, we introduce a technique to automatically generate a domain-specific testing framework from an annotated DSML  definition. In our approach, the DSML definition consists of a metamodel,  a concrete syntax definition and operational semantics described  as a schedule of graph rewrite rules, thus covering a large  class of DSMLs. Currently, DSMLs with deterministic behaviour  are supported, but we provide an outlook to other (nondeterministic,  real-time or continuous-time) DSMLs. We illustrate the approach  with a DSML for describing an elevator controller. We evaluate  the approach and conclude that compared to the state-of-the-art,  our testing support is significantly less costly, and similar or better  (according to DSM principles) testing support is achieved. Additionally,  the generative nature of the approach makes testing support for  DSMLs less error-prone while catering the need for early testing.},
booktitle = {Proceedings of the 2016 ACM SIGPLAN International Conference on Software Language Engineering},
pages = {181–194},
numpages = {14},
keywords = {Verification, Language Engineering, Domain-Specific Modelling},
location = {Amsterdam, Netherlands},
series = {SLE 2016}
}

@inproceedings{10.1145/3597503.3639581,
author = {Goldstein, Harrison and Cutler, Joseph W. and Dickstein, Daniel and Pierce, Benjamin C. and Head, Andrew},
title = {Property-Based Testing in Practice},
year = {2024},
isbn = {9798400702174},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3597503.3639581},
doi = {10.1145/3597503.3639581},
abstract = {Property-based testing (PBT) is a testing methodology where users write executable formal specifications of software components and an automated harness checks these specifications against many automatically generated inputs. From its roots in the QuickCheck library in Haskell, PBT has made significant inroads in mainstream languages and industrial practice at companies such as Amazon, Volvo, and Stripe. As PBT extends its reach, it is important to understand how developers are using it in practice, where they see its strengths and weaknesses, and what innovations are needed to make it more effective.We address these questions using data from 30 in-depth interviews with experienced users of PBT at Jane Street, a financial technology company making heavy and sophisticated use of PBT. These interviews provide empirical evidence that PBT's main strengths lie in testing complex code and in increasing confidence beyond what is available through conventional testing methodologies, and, moreover, that most uses fall into a relatively small number of high-leverage idioms. Its main weaknesses, on the other hand, lie in the relative complexity of writing properties and random data generators and in the difficulty of evaluating their effectiveness. From these observations, we identify a number of potentially high-impact areas for future exploration, including performance improvements, differential testing, additional high-leverage testing scenarios, better techniques for generating random input data, test-case reduction, and methods for evaluating the effectiveness of tests.},
booktitle = {Proceedings of the IEEE/ACM 46th International Conference on Software Engineering},
articleno = {187},
numpages = {13},
location = {Lisbon, Portugal},
series = {ICSE '24}
}

@article{10.1145/3210256,
author = {Florence, Spencer P. and Fetscher, Burke and Flatt, Matthew and Temps, William H. and St-Amour, Vincent and Kiguradze, Tina and West, Dennis P. and Niznik, Charlotte and Yarnold, Paul R. and Findler, Robert Bruce and Belknap, Steven M.},
title = {POP-PL: A Patient-Oriented Prescription Programming Language},
year = {2018},
issue_date = {September 2018},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {40},
number = {3},
issn = {0164-0925},
url = {https://doi.org/10.1145/3210256},
doi = {10.1145/3210256},
abstract = {A medical prescription is a set of health care instructions that govern the plan of care for an individual patient, which may include orders for drug therapy, diet, clinical assessment, and laboratory testing. Clinicians have long used algorithmic thinking to describe and implement prescriptions but without the benefit of a formal programming language. Instead, medical algorithms are expressed using a natural language patois, flowcharts, or as structured data in an electronic medical record system. The lack of a prescription programming language inhibits expressiveness; results in prescriptions that are difficult to understand, hard to debug, and awkward to reuse; and increases the risk of fatal medical error.This article reports on the design and evaluation of Patient-Oriented Prescription Programming Language (POP-PL), a domain-specific programming language designed for expressing prescriptions. The language is based around the idea that programs and humans have complementary strengths that, when combined properly, can make for safer, more accurate performance of prescriptions. Use of POP-PL facilitates automation of certain low-level vigilance tasks, freeing up human cognition for abstract thinking, compassion, and human communication.We implemented this language and evaluated its design attempting to write prescriptions in the new language and evaluated its usability by assessing whether clinicians can understand and modify prescriptions written in the language. We found that some medical prescriptions can be expressed in a formal domain-specific programming language, and we determined that medical professionals can understand and correctly modify programs written in POP-PL. We also discuss opportunities for refining and further developing POP-PL.},
journal = {ACM Trans. Program. Lang. Syst.},
month = jul,
articleno = {10},
numpages = {37},
keywords = {DSL design, empirical evaluation, medical prescriptions, medical programming languages}
}

@inproceedings{10.1145/3213846.3213852,
author = {Shin, Seung Yeob and Nejati, Shiva and Sabetzadeh, Mehrdad and Briand, Lionel C. and Zimmer, Frank},
title = {Test case prioritization for acceptance testing of cyber physical systems: a multi-objective search-based approach},
year = {2018},
isbn = {9781450356992},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3213846.3213852},
doi = {10.1145/3213846.3213852},
abstract = {Acceptance testing validates that a system meets its requirements and determines whether it can be sufficiently trusted and put into operation. For cyber physical systems (CPS), acceptance testing is a hardware-in-the-loop process conducted in a (near-)operational environment. Acceptance testing of a CPS often necessitates that the test cases be prioritized, as there are usually too many scenarios to consider given time constraints. CPS acceptance testing is further complicated by the uncertainty in the environment and the impact of testing on hardware. We propose an automated test case prioritization approach for CPS acceptance testing, accounting for time budget constraints, uncertainty, and hardware damage risks. Our approach is based on multi-objective search, combined with a test case minimization algorithm that eliminates redundant operations from an ordered sequence of test cases. We evaluate our approach on a representative case study from the satellite domain. The results indicate that, compared to test cases that are prioritized manually by satellite engineers, our automated approach more than doubles the number of test cases that fit into a given time frame, while reducing to less than one third the number of operations that entail the risk of damage to key hardware components.},
booktitle = {Proceedings of the 27th ACM SIGSOFT International Symposium on Software Testing and Analysis},
pages = {49–60},
numpages = {12},
keywords = {Test Case Prioritization, Search-based Software Engineering, Multi-objective Optimization, Cyber Physical Systems, Acceptance Testing},
location = {Amsterdam, Netherlands},
series = {ISSTA 2018}
}

@inproceedings{10.1145/2607023.2610278,
author = {Hesenius, Marc and Griebe, Tobias and Gruhn, Volker},
title = {Towards a behavior-oriented specification and testing language for multimodal applications},
year = {2014},
isbn = {9781450327251},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2607023.2610278},
doi = {10.1145/2607023.2610278},
abstract = {Initiated by the ubiquity of mobile devices, human computer interaction has evolved beyond the classic PCs' mouse and keyboard setup. Smartphones and tablets introduced new interaction modalities to the mass market and created the need for specialized software engineering methods. While more and more powerful SDKs are released to develop interactive applications, specifying user interaction is still ambiguous and error-prone, causing software defects as well as misunderstandings and frustration among project team members and stakeholders. We present an approach addressing this problems by demonstrating how to incorporate multimodal interaction into user acceptance tests written in near-natural language using Gherkin and formal gesture descriptions.},
booktitle = {Proceedings of the 2014 ACM SIGCHI Symposium on Engineering Interactive Computing Systems},
pages = {117–122},
numpages = {6},
keywords = {specification, software engineering, multimodal user interfaces},
location = {Rome, Italy},
series = {EICS '14}
}

@inproceedings{10.5555/2337223.2337371,
author = {Devos, Nicolas and Ponsard, Christophe and Deprez, Jean-Christophe and Bauvin, Renaud and Moriau, Benedicte and Anckaerts, Guy},
title = {Efficient reuse of domain-specific test knowledge: an industrial case in the smart card domain},
year = {2012},
isbn = {9781467310673},
publisher = {IEEE Press},
abstract = {While testing is heavily used and largely automated in software development projects, the reuse of test practices across similar projects in a given domain is seldom systematized and supported by adequate methods and tools. This paper presents a practical approach that emerged from a concrete industrial case in the smart card domain at STMicroelectronics Belgium in order to better address this kind of challenge. The central concept is a test knowledge repository organized as a collection of specific patterns named QPatterns. A systematic process was followed, first to gather, structure and abstract the test practices, then to produce and validate an initial repository, and finally to make it evolve later on Testers can then rely on this repository to produce high quality test plans identifying all the functional and non-functional aspects that have to be addressed, as well as the concrete tests that have to be developed within the context of a new project. A tool support was also developed and integrated in a traceable way into the existing industrial test environment. The approach was validated and is currently under deployment at STMicroelectronics Belgium.},
booktitle = {Proceedings of the 34th International Conference on Software Engineering},
pages = {1123–1132},
numpages = {10},
location = {Zurich, Switzerland},
series = {ICSE '12}
}

@proceedings{10.1145/3723325,
title = {IFL '24: Proceedings of the 36th Symposium on Implementation and Application of Functional Languages},
year = {2024},
isbn = {9798400710254},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {
}
}

@inproceedings{10.5555/2663575.2663588,
author = {Morrison, Patrick and Holmgreen, Casper and Massey, Aaron and Williams, Laurie},
title = {Proposing regulatory-driven automated test suites for electronic health record systems},
year = {2013},
isbn = {9781467362825},
publisher = {IEEE Press},
abstract = {In regulated domains such as finance and health care, failure to comply with regulation can lead to financial, civil and criminal penalties. While systems vary from organization to organization, regulations apply across organizations. We propose the use of Behavior-Driven-Development (BDD) scenarios as the basis of an automated compliance test suite for standards such as regulation and interoperability. Such test suites could become a shared asset for use by all systems subject to these regulations and standards. Each system, then, need only create their own system-specific test driver code to automate their compliance checks. The goal of this research is to enable organizations to compare their systems to regulation in a repeatable and traceable way through the use of BDD. To evaluate our proposal, we developed an abbreviated HIPAA test suite and applied it to three open-source electronic health record systems. The scenarios covered all security behavior defined by the selected regulation. The system-specific test driver code covered all security behavior defined in the scenarios, and identified where the tested system lacked such behavior.},
booktitle = {Proceedings of the 5th International Workshop on Software Engineering in Health Care},
pages = {46–49},
numpages = {4},
keywords = {software testing, software engineering, security, regulatory compliance, healthcare it, behavior-driven-development},
location = {San Francisco, California},
series = {SEHC '13}
}

@proceedings{10.1145/3623476,
title = {SLE 2023: Proceedings of the 16th ACM SIGPLAN International Conference on Software Language Engineering},
year = {2023},
isbn = {9798400703966},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
abstract = {Welcome to the 16th ACM SIGPLAN International Conference on Software Language Engineering (SLE) held in October 2023 as part of SPLASH 2023. Software Language Engineering (SLE) is a thriving research discipline targeted at establishing an engineering approach to the development, use, and maintenance of software languages, that is, of languages for the specification, modeling and tooling of software. Key topics of interest for SLE include approaches, methodologies and tools for language design and implementation with a focus on techniques for static and behavioral semantics, generative or interpretative approaches (including transformation languages and code generation) as well as meta-languages and tools (including language workbenches). Techniques enabling the testing, simulation or formal verification for language validation purposes are also of particular interest. SLE also accommodates empirical evaluation and experience reports of language engineering tools, such as user studies evaluating usability, performance benchmarks or industrial applications.},
location = {Cascais, Portugal}
}

@article{10.1145/3579851,
author = {Greca, Renan and Miranda, Breno and Bertolino, Antonia},
title = {State of Practical Applicability of Regression Testing Research: A Live Systematic Literature Review},
year = {2023},
issue_date = {December 2023},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {55},
number = {13s},
issn = {0360-0300},
url = {https://doi.org/10.1145/3579851},
doi = {10.1145/3579851},
abstract = {Context: Software regression testing refers to rerunning test cases after the system under test is modified, ascertaining that the changes have not (re-)introduced failures. Not all researchers’ approaches consider applicability and scalability concerns, and not many have produced an impact in practice. Objective: One goal is to investigate industrial relevance and applicability of proposed approaches. Another is providing a live review, open to continuous updates by the community. Method: A systematic review of regression testing studies that are clearly motivated by or validated against industrial relevance and applicability is conducted. It is complemented by follow-up surveys with authors of the selected papers and 23 practitioners. Results: A set of 79 primary studies published between 2016–2022 is collected and classified according to approaches and metrics. Aspects relative to their relevance and impact are discussed, also based on their authors’ feedback. All the data are made available from the live repository that accompanies the study. Conclusions: While widely motivated by industrial relevance and applicability, not many approaches are evaluated in industrial or large-scale open-source systems, and even fewer approaches have been adopted in practice. Some challenges hindering the implementation of relevant approaches are synthesized, also based on the practitioners’ feedback.},
journal = {ACM Comput. Surv.},
month = jul,
articleno = {274},
numpages = {36},
keywords = {systematic literature review, test suite amplification, test suite reduction, test case prioritization, test case selection, Regression Testing}
}

@inproceedings{10.1145/3510003.3510040,
author = {Noller, Yannic and Shariffdeen, Ridwan and Gao, Xiang and Roychoudhury, Abhik},
title = {Trust enhancement issues in program repair},
year = {2022},
isbn = {9781450392211},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3510003.3510040},
doi = {10.1145/3510003.3510040},
abstract = {Automated program repair is an emerging technology that seeks to automatically rectify bugs and vulnerabilities using learning, search, and semantic analysis. Trust in automatically generated patches is necessary for achieving greater adoption of program repair. Towards this goal, we survey more than 100 software practitioners to understand the artifacts and setups needed to enhance trust in automatically generated patches. Based on the feedback from the survey on developer preferences, we quantitatively evaluate existing test-suite based program repair tools. We find that they cannot produce high-quality patches within a top-10 ranking and an acceptable time period of 1 hour. The developer feedback from our qualitative study and the observations from our quantitative examination of existing repair tools point to actionable insights to drive program repair research. Specifically, we note that producing repairs within an acceptable time-bound is very much dependent on leveraging an abstract search space representation of a rich enough search space. Moreover, while additional developer inputs are valuable for generating or ranking patches, developers do not seem to be interested in a significant human-in-the-loop interaction.},
booktitle = {Proceedings of the 44th International Conference on Software Engineering},
pages = {2228–2240},
numpages = {13},
location = {Pittsburgh, Pennsylvania},
series = {ICSE '22}
}

@inproceedings{10.1145/331960.331978,
author = {Jennings, James and Beuscher, Eric},
title = {Verischemelog: Verilog embedded in Scheme},
year = {2000},
isbn = {1581132557},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/331960.331978},
doi = {10.1145/331960.331978},
abstract = {Verischemelog (pronounced with 5 syllables, veruh-scheme-uh-log) is a language and programming environment embedded in Scheme for designing digital electronic hardware systems and for controlling the simulation of these circuits. Simulation is performed by a separate program, often a commercial product. Verischemelog compiles to Verilog, an industry standard language accepted by several commercial and public domain simulators.Because many design elements are easily parameterized, design engineers currently write scripts which generate hardware description code in Verilog. These scripts work by textual substitution, and are typically ad-hoc and quite limited. Preprocessors for Verilog, on the other hand, are hampered by their macro-expansion languages, which support few data types and lack procedures. Verischemelog obviates the need for scripts and preprocessors by providing a hardware description language with list-based syntax, and Scheme to manipulate it.An interactive development environment gives early and specific feedback about errors, and structured access to the compiler and run-time environment provide a high degree of reconfigurability and extensibility of Verischemelog.},
booktitle = {Proceedings of the 2nd Conference on Domain-Specific Languages},
pages = {123–134},
numpages = {12},
location = {Austin, Texas, USA},
series = {DSL '99}
}

@inproceedings{10.1145/3338906.3338972,
author = {Dutta, Saikat and Zhang, Wenxian and Huang, Zixin and Misailovic, Sasa},
title = {Storm: program reduction for testing and debugging probabilistic programming systems},
year = {2019},
isbn = {9781450355728},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3338906.3338972},
doi = {10.1145/3338906.3338972},
abstract = {Probabilistic programming languages offer an intuitive way to model uncertainty by representing complex probability models as simple probabilistic programs. Probabilistic programming systems (PP systems) hide the complexity of inference algorithms away from the program developer. Unfortunately, if a failure occurs during the run of a PP system, a developer typically has very little support in finding the part of the probabilistic program that causes the failure in the system.  This paper presents Storm, a novel general framework for reducing probabilistic programs. Given a probabilistic program (with associated data and inference arguments) that causes a failure in a PP system, Storm finds a smaller version of the program, data, and arguments that cause the same failure. Storm leverages both generic code and data transformations from compiler testing and domain-specific, probabilistic transformations. The paper presents new transformations that reduce the complexity of statements and expressions, reduce data size, and simplify inference arguments (e.g., the number of iterations of the inference algorithm).  We evaluated Storm on 47 programs that caused failures in two popular probabilistic programming systems, Stan and Pyro. Our experimental results show Storm’s effectiveness. For Stan, our minimized programs have 49% less code, 67% less data, and 96% fewer iterations. For Pyro, our minimized programs have 58% less code, 96% less data, and 99% fewer iterations. We also show the benefits of Storm when debugging probabilistic programs.},
booktitle = {Proceedings of the 2019 27th ACM Joint Meeting on European Software Engineering Conference and Symposium on the Foundations of Software Engineering},
pages = {729–739},
numpages = {11},
keywords = {Software Testing, Probabilistic Programming Languages},
location = {Tallinn, Estonia},
series = {ESEC/FSE 2019}
}

@inproceedings{10.1145/3597926.3604924,
author = {Peldszus, Sven and Akopian, Noubar and Berger, Thorsten},
title = {RobotBT: Behavior-Tree-Based Test-Case Specification for the Robot Framework},
year = {2023},
isbn = {9798400702211},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3597926.3604924},
doi = {10.1145/3597926.3604924},
abstract = {The Robot Framework is a popular and widely used test automation framework that abstracts test case specifications toward natural language specifications. This makes it well suited for implementing high-level test cases, at least as long as the functions provided by Robot can support the intended functionality. For more complicated test cases, custom and often deeply nested functionality specifications are required, and the readability of Robot test cases tends to decrease. We present RobotBT, a library for the Robot framework that addresses these shortcomings by adding support for specifying test cases using behavior trees. Behavior trees are a comprehensive method for specifying complex behaviors based on a control flow model that orchestrates the execution of functionality. We evaluated RobotBT on a test suite for GUI testing from G~DATA CyberDefense AG and interviewed their engineers about the usability, readability, and applicability of RobotBT. Our results show that BTs improve the expressiveness and readability of Robot Framework test cases and are applicable to practical problems.},
booktitle = {Proceedings of the 32nd ACM SIGSOFT International Symposium on Software Testing and Analysis},
pages = {1503–1506},
numpages = {4},
keywords = {Test Case Specification, Robot Framework, Behavior Tree},
location = {Seattle, WA, USA},
series = {ISSTA 2023}
}

@inproceedings{10.1145/2628363.2628391,
author = {Hesenius, Marc and Griebe, Tobias and Gries, Stefan and Gruhn, Volker},
title = {Automating UI tests for mobile applications with formal gesture descriptions},
year = {2014},
isbn = {9781450330046},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2628363.2628391},
doi = {10.1145/2628363.2628391},
abstract = {Touch- and gesture-based interfaces are common in applications for mobile devices. By evolving into mass market products, smartphones and tablets created an increased need for specialized software engineering methods. To ensure high quality applications, constant and efficient testing is crucial in software development. However, testing mobile applications is still cumbersome, time-consuming and error-prone. One reason is the devices' focus on touch-based interaction - gestures cannot be easily incorporated into automated application tests. We present an extension to the popular Calabash testing framework solving this problem by allowing to describe gestures with a formal language in tests scripts.},
booktitle = {Proceedings of the 16th International Conference on Human-Computer Interaction with Mobile Devices &amp; Services},
pages = {213–222},
numpages = {10},
keywords = {testing, test automation, software engineering, mobile applications, gestures, gesture formalization},
location = {Toronto, ON, Canada},
series = {MobileHCI '14}
}

@inproceedings{10.1145/2554850.2554942,
author = {Griebe, Tobias and Gruhn, Volker},
title = {A model-based approach to test automation for context-aware mobile applications},
year = {2014},
isbn = {9781450324694},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2554850.2554942},
doi = {10.1145/2554850.2554942},
abstract = {Current testing tools for mobile applications do not provide sufficient support for context-aware application testing. In addition to regular input vectors (e.g. touch events, text entry) context parameters must be considered (e.g. accelerometer data interpreted as shake gestures, GPS location data, etc.). A multitude of possible application faults resulting from these additional context parameters requires an appropriately selected set of test cases. In this paper, we propose a model-based approach to improve the testing of context-aware mobile applications by deducing test cases from design-time system models. Using a custom-built version of the calabash-android testing framework enhanced by an arbitrary context parameter facility, our approach to test case generation and automated execution is validated on a context-aware mobile application.},
booktitle = {Proceedings of the 29th Annual ACM Symposium on Applied Computing},
pages = {420–427},
numpages = {8},
keywords = {testing, model-based, mobile, context-awareness},
location = {Gyeongju, Republic of Korea},
series = {SAC '14}
}

@inproceedings{10.1145/3238147.3240463,
author = {Gafurov, Davrondzhon and Hurum, Arne Erik and Markman, Martin},
title = {Achieving test automation with testers without coding skills: an industrial report},
year = {2018},
isbn = {9781450359375},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3238147.3240463},
doi = {10.1145/3238147.3240463},
abstract = {We present a process driven test automation solution which enables delegating (part of) automation tasks from test automation engineer (expensive resource) to test analyst (non-developer, less expensive). In our approach, a test automation engineer implements test steps (or actions) which are executed automatically. Such automated test steps represent user actions in the system under test and specified by a natural language which is understandable by a non-technical person. Then, a test analyst with a domain knowledge organizes automated steps combined with test input to create an automated test case. It should be emphasized that the test analyst does not need to possess programming skills to create, modify or execute automated test cases. We refine benchmark test automation architecture to be better suitable for an effective separation and sharing of responsibilities between the test automation engineer (with coding skills) and test analyst (with a domain knowledge). In addition, we propose a metric to empirically estimate cooperation between test automation engineer and test analyst's works. The proposed automation solution has been defined based on our experience in the development and maintenance of Helsenorg, the national electronic health services in Norway which has had over one million of visits per month past year, and we still use it to automate the execution of regression tests.},
booktitle = {Proceedings of the 33rd ACM/IEEE International Conference on Automated Software Engineering},
pages = {749–756},
numpages = {8},
keywords = {process-driven test automation, keyword-driven test automation, Test automation, Helsenorge, DSL for test automation},
location = {Montpellier, France},
series = {ASE '18}
}

@article{10.1145/3428212,
author = {Sotiropoulos, Thodoris and Chaliasos, Stefanos and Mitropoulos, Dimitris and Spinellis, Diomidis},
title = {A model for detecting faults in build specifications},
year = {2020},
issue_date = {November 2020},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {4},
number = {OOPSLA},
url = {https://doi.org/10.1145/3428212},
doi = {10.1145/3428212},
abstract = {Incremental and parallel builds are crucial features of modern build systems. Parallelism enables fast builds by running independent tasks simultaneously, while incrementality saves time and computing resources by processing the build operations that were affected by a particular code change. Writing build definitions that lead to error-free incremental and parallel builds is a challenging task. This is mainly because developers are often unable to predict the effects of build operations on the file system and how different build operations interact with each other. Faulty build scripts may seriously degrade the reliability of automated builds, as they cause build failures, and non-deterministic and incorrect outputs.  To reason about arbitrary build executions, we present BuildFS, a generally-applicable model that takes into account the specification (as declared in build scripts) and the actual behavior (low-level file system operation) of build operations. We then formally define different types of faults related to incremental and parallel builds in terms of the conditions under which a file system operation violates the specification of a build operation. Our testing approach, which relies on the proposed model, analyzes the execution of single full build, translates it into BuildFS, and uncovers faults by checking for corresponding violations.  We evaluate the effectiveness, efficiency, and applicability of our approach by examining 612 Make and Gradle projects. Notably, thanks to our treatment of build executions, our method is the first to handle JVM-oriented build systems. The results indicate that our approach is (1) able to uncover several important issues (247 issues found in 47 open-source projects have been confirmed and fixed by the upstream developers), and (2) much faster than a state-of-the-art tool for Make builds (the median and average speedup is 39X and 74X respectively).},
journal = {Proc. ACM Program. Lang.},
month = nov,
articleno = {144},
numpages = {30},
keywords = {parallel builds, incremental builds, Make, JVM-based builds, Gradle}
}

@inproceedings{10.1145/3622758.3622888,
author = {Schuts, Mathijs and Hooman, Jozef},
title = {Towards an Industrial Stateful Software Rejuvenation Toolchain using Model Learning},
year = {2023},
isbn = {9798400703881},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3622758.3622888},
doi = {10.1145/3622758.3622888},
abstract = {We present our vision for creating an industrial legacy software rejuvenation toolchain. The goal is to semi automatically remove code smells from stateful software used in Cyber Physical Systems (CPS). Compared to existing tools that remove code smells, our toolchain can remove more than one type of code smell. Additionally, our approach supports multiple programming languages because we use abstract models obtained by means of model learning. Supporting more than one programming language is often lacking in state of art refactoring tools.},
booktitle = {Proceedings of the 2023 ACM SIGPLAN International Symposium on New Ideas, New Paradigms, and Reflections on Programming and Software},
pages = {15–31},
numpages = {17},
keywords = {state machine, software rejuvenation, software refactoring, model learning, model based development},
location = {Cascais, Portugal},
series = {Onward! 2023}
}

@article{10.1145/3530813,
author = {Fahmideh, Mahdi and Grundy, John and Ahmad, Aakash and Shen, Jun and Yan, Jun and Mougouei, Davoud and Wang, Peng and Ghose, Aditya and Gunawardana, Anuradha and Aickelin, Uwe and Abedin, Babak},
title = {Engineering Blockchain-based Software Systems: Foundations, Survey, and Future Directions},
year = {2022},
issue_date = {June 2023},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {55},
number = {6},
issn = {0360-0300},
url = {https://doi.org/10.1145/3530813},
doi = {10.1145/3530813},
abstract = {Many scientific and practical areas have shown increasing interest in reaping the benefits of blockchain technology to empower software systems. However, the unique characteristics and requirements associated with Blockchain-based Software (BBS) systems raise new challenges across the development lifecycle that entail an extensive improvement of conventional software engineering. This article presents a systematic literature review of the state-of-the-art in BBS engineering research from the perspective of the software engineering discipline. We characterize BBS engineering based on the key aspects of theoretical foundations, processes, models, and roles. Based on these aspects, we present a rich repertoire of development tasks, design principles, models, roles, challenges, and resolution techniques. The focus and depth of this survey not only give software engineering practitioners and researchers a consolidated body of knowledge about current BBS development but also underpin a starting point for further research in this field.},
journal = {ACM Comput. Surv.},
month = dec,
articleno = {110},
numpages = {44},
keywords = {blockchain-based software systems, blockchain, Systems development methods, Software engineering}
}

@proceedings{10.1145/3624032,
title = {SAST '23: Proceedings of the 8th Brazilian Symposium on Systematic and Automated Software Testing},
year = {2023},
isbn = {9798400716294},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Campo Grande, MS, Brazil}
}

@inproceedings{10.1145/3424771.3424821,
author = {Zimmermann, Olaf and Pautasso, Cesare and L\"{u}bke, Daniel and Zdun, Uwe and Stocker, Mirko},
title = {Data-Oriented Interface Responsibility Patterns: Types of Information Holder Resources},
year = {2020},
isbn = {9781450377690},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3424771.3424821},
doi = {10.1145/3424771.3424821},
abstract = {Remote Application Programming Interfaces (APIs) are used in almost any distributed system today, for instance in microservices-based systems, and are thus enablers for many digitalization efforts. API design not only impacts whether software provided as a service is easy and efficient to develop applications with, but also affects the long term evolution of the software system. In general, APIs are responsible for providing remote and controlled access to the functionality provided as services; however, APIs often are also used to expose and share information. We focus on such data-related aspects of microservice APIs in this paper. Depending on the life cycle of the information published through the API, its mutability and the endpoint role, data-oriented APIs can be designed following patterns such as Operational Data Holder, Master Data Holder, Reference Data Holder, Data Transfer Holder, and Link Lookup Resource. Known uses and examples of the patterns are drawn from public Web APIs as well as application development and integration projects we have been involved in.},
booktitle = {Proceedings of the European Conference on Pattern Languages of Programs 2020},
articleno = {11},
numpages = {25},
location = {Virtual Event, Germany},
series = {EuroPLoP '20}
}

@article{10.1145/3447680,
author = {Jeong, Eunjin and Jeong, Dowhan and Ha, Soonhoi},
title = {Dataflow Model–based Software Synthesis Framework for Parallel and Distributed Embedded Systems},
year = {2021},
issue_date = {September 2021},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {26},
number = {5},
issn = {1084-4309},
url = {https://doi.org/10.1145/3447680},
doi = {10.1145/3447680},
abstract = {Existing software development methodologies mostly assume that an application runs on a single device without concern about the non-functional requirements of an embedded system such as latency and resource consumption. Besides, embedded software is usually developed after the hardware platform is determined, since a non-negligible portion of the code depends on the hardware platform. In this article, we present a novel model-based software synthesis framework for parallel and distributed embedded systems. An application is specified as a set of tasks with the given rules for execution and communication. Having such rules enables us to perform static analysis to check some software errors at compile-time to reduce the verification difficulty. Platform-specific programs are synthesized automatically after the mapping of tasks onto processing elements is determined. The proposed framework is expandable to support new hardware platforms easily. The proposed communication code synthesis method is extensible and flexible to support various communication methods between devices. In addition, the fault-tolerant feature can be added by modifying the task graph automatically according to the selected fault-tolerance configurations by the user. The viability of the proposed software development methodology is evaluated with a real-life surveillance application that runs on six processing elements.},
journal = {ACM Trans. Des. Autom. Electron. Syst.},
month = jun,
articleno = {35},
numpages = {38},
keywords = {embedded software development, synchronous dataflow, fault tolerance, Code generation}
}

@inproceedings{10.1145/2134243.2134248,
author = {Sadowski, Caitlin and Yi, Jaeheon},
title = {&lt;u&gt;T&lt;/u&gt;i&lt;u&gt;d&lt;/u&gt;d&lt;u&gt;l&lt;/u&gt;e: a &lt;u&gt;t&lt;/u&gt;race &lt;u&gt;d&lt;/u&gt;escription &lt;u&gt;l&lt;/u&gt;anguage for generating concurrent benchmarks to test dynamic analyses},
year = {2009},
isbn = {9781605586564},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2134243.2134248},
doi = {10.1145/2134243.2134248},
abstract = {Dynamic analysis is a promising technique for finding concurrency bugs in multithreaded programs. However, testing a dynamic analysis tool can be difficult. Researchers end up writing large amounts of small benchmark programs. Since the benchmarks themselves are concurrent programs, they may execute nondeterministically, complicating testing of the analysis tool.We propose testing dynamic analyses by writing traces in a simple trace description language, Tiddle. Our implementation, written in Haskell, generates deterministic multithreaded Java programs for testing dynamic analyses. We report that it is substantially easier to write programs with incriminating bugs such as race conditions in Tiddle than the corresponding Java source code version, reducing the amount of source code to maintain and understand. Although our implementation is targeted towards Java, the ideas extend to any other languages which support mutable fields and multiple threads.},
booktitle = {Proceedings of the Seventh International Workshop on Dynamic Analysis},
pages = {15–21},
numpages = {7},
keywords = {traces, race conditions, dynamic analysis, concurrency, atomicity violations},
location = {Chicago, Illinois},
series = {WODA '09}
}

@article{10.1145/3394979,
author = {Rocha Silva, Thiago and Winckler, Marco and Tr\ae{}tteberg, Hallvard},
title = {Ensuring the Consistency between User Requirements and Task Models: A Behavior-Based Automated Approach},
year = {2020},
issue_date = {June 2020},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {4},
number = {EICS},
url = {https://doi.org/10.1145/3394979},
doi = {10.1145/3394979},
abstract = {Evaluating and ensuring the consistency between user requirements and modeling artifacts is a long-time issue for model-based software design. Conflicts in requirements specifications can lead to many design errors and have a decisive impact on the quality of systems under development. This article presents an approach based on Behavior-Driven Development (BDD) to provide automated assessment for task models, which are intended to model the flow of user and system tasks in an interactive system. The approach has been evaluated by exploiting user requirements described by a group of experts in the domain of business trips. Such requirements gave rise to a set of BDD stories that have been used to automatically assess scenarios extracted from task models that were reengineered from an existing web system for booking business trips. The results have shown our approach, by performing a static analysis of the source files, was able to identify different types of inconsistencies between the user requirements and the set of task models analyzed.},
journal = {Proc. ACM Hum.-Comput. Interact.},
month = jun,
articleno = {77},
numpages = {32},
keywords = {user stories, task models, behavior-driven development (BDD), automated requirements assessment}
}

@article{10.1145/2579281.2579312,
author = {Ionita, Anca Daniela and Lewis, Grace A. and Litoiu, Marin},
title = {Report of the 2013 IEEE 7th international symposium on the maintenance and evolution of service-oriented and cloud-based systems (MESOCA 2013)},
year = {2014},
issue_date = {March 2014},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {39},
number = {2},
issn = {0163-5948},
url = {https://doi.org/10.1145/2579281.2579312},
doi = {10.1145/2579281.2579312},
abstract = {The 2013 IEEE 7th International Symposium on the Maintenance and Evolution of Service-Oriented and Cloud-Based Systems (MESOCA 2013) took place in Eindhoven, The Netherlands, on September 24, 2013, as a co-located event of the 29th IEEE International Conference on Software Maintenance (ICSM 2013). MESOCA 2013 covered a wide range of academic and industrial experiences, brought together through one keynote, two invited presentations and eleven paper presentations, which triggered lively discussions. They approached aspects related to the entire software maintenance process, from requirements to testing, with specific solutions for Service-Oriented Architecture and Cloud Computing environments. Technical and business perspectives were discussed, including issues about optimization techniques, pre-migration evaluation of legacy software, decision analysis, energy efficiency, multi-cloud architectures and adaptability. It thus confirmed MESOCA as an ongoing forum for researchers and practitioners to identify and address the increasing challenges related to the evolution of service-provisioning systems.},
journal = {SIGSOFT Softw. Eng. Notes},
month = mar,
pages = {34–37},
numpages = {4},
keywords = {software maintenance, software evolution, services, serviceoriented architecture, service-oriented systems, cloudbased systems, cloud computing, SOA}
}

@article{10.1145/3105906,
author = {Monperrus, Martin},
title = {Automatic Software Repair: A Bibliography},
year = {2018},
issue_date = {January 2019},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {51},
number = {1},
issn = {0360-0300},
url = {https://doi.org/10.1145/3105906},
doi = {10.1145/3105906},
abstract = {This article presents a survey on automatic software repair. Automatic software repair consists of automatically finding a solution to software bugs without human intervention. This article considers all kinds of repairs. First, it discusses behavioral repair where test suites, contracts, models, and crashing inputs are taken as oracle. Second, it discusses state repair, also known as runtime repair or runtime recovery, with techniques such as checkpoint and restart, reconfiguration, and invariant restoration. The uniqueness of this article is that it spans the research communities that contribute to this body of knowledge: software engineering, dependability, operating systems, programming languages, and security. It provides a novel and structured overview of the diversity of bug oracles and repair operators used in the literature.},
journal = {ACM Comput. Surv.},
month = jan,
articleno = {17},
numpages = {24},
keywords = {self-healing software, Program repair}
}

@inproceedings{10.1145/3624032.3624049,
author = {Ferreira, Vin\'{\i}cius Gomes and Herrera, Caio Guimar\~{a}es and Souza, Simone and Santos, Ricardo Ribeiro dos and Souza, Paulo S\'{e}rgio Lopes de},
title = {Software Testing applied to the Development of IoT Systems: preliminary results},
year = {2023},
isbn = {9798400716294},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3624032.3624049},
doi = {10.1145/3624032.3624049},
abstract = {Software testing is a fundamental activity of the broader software engineering process. Internet of Things (IoT) testing activities present unique characteristics that make their execution different from conventional software testing, including specific challenges, tools, approaches, and processes. Although the literature contains several secondary studies that summarize the contributions on this topic, there still needs to be more organization of these studies along a software development process. This paper reports preliminary literature results showing how the knowledge about software testing has been applied to developing and using IoT systems. We conducted an initial search on known papers’ databases in computing and supplemented this search by snowballing two literature reviews found in this previous search. This study’s main results show that most approaches and tools for software testing on IoT systems are grouped in the stages of Validation by Emulation or Simulation with approximately 43% of the total of papers, followed by Validation by Testbed with approximately 24%. Hence, there is an opportunity for exploring further the Development and Operation/Support stages. Our results will help researchers and practitioners know when and in what sequence to use techniques, processes, and test tools reported in the literature.},
booktitle = {Proceedings of the 8th Brazilian Symposium on Systematic and Automated Software Testing},
pages = {113–122},
numpages = {10},
keywords = {testing, systematic mapping, software development life cycle, internet of things},
location = {Campo Grande, MS, Brazil},
series = {SAST '23}
}

@article{10.1145/3095807,
author = {Bowen, Judy and Reeves, Steve},
title = {Generating Obligations, Assertions and Tests from UI Models},
year = {2017},
issue_date = {June 2017},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {1},
number = {EICS},
url = {https://doi.org/10.1145/3095807},
doi = {10.1145/3095807},
abstract = {Model-based development of interactive systems provides a number of benefits which can support the creation of robust and correct systems, particularly important when the interactive systems are safety-critical. Many different approaches have been proposed which target the models at different aspects of the development process (for example task analysis, interface layouts, functional behaviours etc.) and which can be used in different ways (verification of correctness, plasticity, usability).One of the aims for any modelling method should be simplicity - we are after all trying to hide complexity via abstraction in order to make reasoning about systems more tractable than working at the programming level. One of the challenges that exists however we do our modelling is ensuring the consistency between the model of the interface and interactivity and model of the functional behaviour of the system. This is primarily due to the different types of models that most naturally describe these different elements. In this paper we propose a method of tightening the integration of models of these different components of the system by generating obligations which explicitly describe the coupling of functional behaviour with interactive elements. We then show how these obligations can be used to support the development process during the programming and testing of the system.},
journal = {Proc. ACM Hum.-Comput. Interact.},
month = jun,
articleno = {5},
numpages = {18},
keywords = {testing, model-driven development}
}

@inproceedings{10.1145/3670474.3685948,
author = {Batten, Christopher and Pinckney, Nathaniel and Liu, Mingjie and Ren, Haoxing and Khailany, Brucek},
title = {PyHDL-Eval: An LLM Evaluation Framework for Hardware Design Using Python-Embedded DSLs},
year = {2024},
isbn = {9798400706998},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3670474.3685948},
doi = {10.1145/3670474.3685948},
abstract = {Embedding hardware design frameworks within Python is a promising technique to improve the productivity of hardware engineers. At the same time, there is significant interest in using large-language models (LLMs) to improve key chip design tasks. This paper describes PyHDL-Eval, a new framework for evaluating LLMs on specification-to-RTL tasks in the context of Python-embedded domain-specific languages (DSLs). The framework includes 168 problems, Verilog reference solutions, Verilog test benches, Python test scripts, and workflow orchestration scripts. We use the framework to conduct a detailed case study comparing five LLMs (CodeGemma 7B, Llama3 8B/70B, GPT4, and GPT4 Turbo) targeting Verilog and five Python-embedded DSLs (PyMTL3, PyRTL, MyHDL, Migen, and Amaranth). Our results demonstrate the promise of in-context learning when applied to smaller models (e.g., pass rate for CodeGemma 7B improves from 14.9% to 32.7% on Verilog) and Python-embedded DSLs (e.g., pass rate for LLama3 70B improves from 0.6% to 33.0% on PyMTL3). We find LLMs perform better when targeting Verilog as compared to Python-embedded DSLs (e.g., pass rate for GPT4 Turbo is 72.2% on Verilog and 29.8-62.0% on the Python-embedded DSLs) despite using a popular general-purpose host language. PyHDL-Eval will serve as a useful framework for future research at the intersection of Python-embedded DSLs and LLMs.},
booktitle = {Proceedings of the 2024 ACM/IEEE International Symposium on Machine Learning for CAD},
articleno = {10},
numpages = {17},
keywords = {Python-embedded domain-specific languages, hardware description languages, large language models},
location = {Salt Lake City, UT, USA},
series = {MLCAD '24}
}

@inproceedings{10.5555/2662413.2662432,
author = {Diepenbeck, Melanie and Soeken, Mathias and Gro\ss{}e, Daniel and Drechsler, Rolf},
title = {Towards automatic scenario generation from coverage information},
year = {2013},
isbn = {9781467361613},
publisher = {IEEE Press},
abstract = {Nowadays, the design of software systems is pushed towards agile development practices. One of its most fundamental approaches is Test Driven Development (TDD). This procedure is based on test cases which are incrementally written prior to the implementation. Recently, Behavior Driven Development (BDD) has been introduced as an extension of TDD, in which natural language scenarios are the starting point for the test cases. This description offers a ubiquitous communication mean for both the software developers and stakeholders.Following the BDD methodology thoroughly, one would expect 100% code coverage, since code is only written to make the test cases pass. However, as we show in an empirical study this expectation is not valid in practice. It becomes even worse in the process of development, i.e. the coverage decreases over time. To close the coverage gap, we sketch an algorithm that generates BDD-style scenarios based on uncovered code.},
booktitle = {Proceedings of the 8th International Workshop on Automation of Software Test},
pages = {82–88},
numpages = {7},
location = {San Francisco, California},
series = {AST '13}
}

@inproceedings{10.1145/2814270.2814276,
author = {Voelter, Markus and Deursen, Arie van and Kolb, Bernd and Eberle, Stephan},
title = {Using C language extensions for developing embedded software: a case study},
year = {2015},
isbn = {9781450336895},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2814270.2814276},
doi = {10.1145/2814270.2814276},
abstract = {We report on an industrial case study on developing the embedded software for a smart meter using the C programming language and domain-specific extensions of C such as components, physical units, state machines, registers and interrupts. We find that the extensions help significantly with managing the complexity of the software. They improve testability mainly by supporting hardware-independent testing, as illustrated by low integration efforts. The extensions also do not incur significant overhead regarding memory consumption and performance. Our case study relies on mbeddr, an extensible version of C. mbeddr, in turn, builds on the MPS language workbench which supports modular extension of languages and IDEs.},
booktitle = {Proceedings of the 2015 ACM SIGPLAN International Conference on Object-Oriented Programming, Systems, Languages, and Applications},
pages = {655–674},
numpages = {20},
keywords = {Real-time and embedded systems, Program Editors, Extensible languages, Code Generation},
location = {Pittsburgh, PA, USA},
series = {OOPSLA 2015}
}

@inproceedings{10.5555/2666719.2666727,
author = {Landh\"{a}u\ss{}er, Mathias and Genaid, Adrian},
title = {Connecting user stories and code for test development},
year = {2012},
isbn = {9781467317597},
publisher = {IEEE Press},
abstract = {User Stories are short feature descriptions from the user's point of view. Functional tests ensure that the feature described by a User Story is fully implemented.We present a tool that builds an ontology for code and links completed User Stories in natural language with the related code artifacts. The ontology also contains links to API components that were used to implement the functional tests. Preliminary results show that these links can be used to recommend reusable test steps for new User Stories.},
booktitle = {Proceedings of the Third International Workshop on Recommendation Systems for Software Engineering},
pages = {33–37},
numpages = {5},
keywords = {traceability, reasoning, ontology, functional testing, code mining},
location = {Zurich, Switzerland},
series = {RSSE '12}
}

@article{10.1145/1507195.1517461,
author = {Torkar, Richard and Gorschek, Tony and Feldt, Robert},
title = {Eight conference on software engineering research and practice in Sweden (SERPS'08)},
year = {2009},
issue_date = {March 2009},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {34},
number = {2},
issn = {0163-5948},
url = {https://doi.org/10.1145/1507195.1517461},
doi = {10.1145/1507195.1517461},
abstract = {The eight conference on software engineering research and practice in Sweden (SERPS'08) was held in Karlskrona, Sweden, on the 4th-5th of Nov. 2008. The aim with SERPS'08 is to bring researchers and industry practitioners together to discuss software engineering issues, problems, solutions and experiences, not necessarily from a Swedish perspective. During the conference a number of research and industry papers were presented and questions in connection to the presentations were discussed. This paper is a report on the discussions that took place, pointing towards needs and challenges as well as areas of interest in both academia and industry.},
journal = {SIGSOFT Softw. Eng. Notes},
month = feb,
pages = {31–33},
numpages = {3}
}

@proceedings{10.1145/3528227,
title = {SERP4IoT '22: Proceedings of the 4th International Workshop on Software Engineering Research and Practice for the IoT},
year = {2022},
isbn = {9781450393324},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
abstract = {SERP4IoT begins to be recognised as an annual venue gathering researchers, industrials, and practitioners to share their vision, experience, and opinion on how to address the challenges of, find solutions for, and share experiences with the development, release, and testing of robust software systems for IoT devices.},
location = {Pittsburgh, Pennsylvania}
}

@inproceedings{10.1145/3297858.3304019,
author = {Banerjee, Subho S. and Kalbarczyk, Zbigniew T. and Iyer, Ravishankar K.},
title = {AcMC 2 : Accelerating Markov Chain Monte Carlo Algorithms for Probabilistic Models},
year = {2019},
isbn = {9781450362405},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3297858.3304019},
doi = {10.1145/3297858.3304019},
abstract = {Probabilistic models (PMs) are ubiquitously used across a variety of machine learning applications. They have been shown to successfully integrate structural prior information about data and effectively quantify uncertainty to enable the development of more powerful, interpretable, and efficient learning algorithms. This paper presents AcMC2, a compiler that transforms PMs into optimized hardware accelerators (for use in FPGAs or ASICs) that utilize Markov chain Monte Carlo methods to infer and query a distribution of posterior samples from the model. The compiler analyzes statistical dependencies in the PM to drive several optimizations to maximally exploit the parallelism and data locality available in the problem. We demonstrate the use of AcMC2 to implement several learning and inference tasks on a Xilinx Virtex-7 FPGA. AcMC2-generated accelerators provide a 47-100\texttimes{} improvement in runtime performance over a 6-core IBM Power8 CPU and a 8-18\texttimes{} improvement over an NVIDIA K80 GPU. This corresponds to a 753-1600\texttimes{} improvement over the CPU and 248-463\texttimes{} over the GPU in performance-per-watt terms.},
booktitle = {Proceedings of the Twenty-Fourth International Conference on Architectural Support for Programming Languages and Operating Systems},
pages = {515–528},
numpages = {14},
keywords = {accelerator, markov chain monte carlo, probabilistic graphical models, probabilistic programming},
location = {Providence, RI, USA},
series = {ASPLOS '19}
}

@inproceedings{10.1109/ICSE-SEIP58684.2023.00042,
author = {Valle, Pablo and Arrieta, Aitor and Arratibel, Maite},
title = {Automated Misconfiguration Repair of Configurable Cyber-Physical Systems with Search: An Industrial Case Study on Elevator Dispatching Algorithms},
year = {2023},
isbn = {9798350300376},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/ICSE-SEIP58684.2023.00042},
doi = {10.1109/ICSE-SEIP58684.2023.00042},
abstract = {Real-world Cyber-Physical Systems (CPSs) are usually configurable. Through parameters, it is possible to configure, select or unselect different system functionalities. While this provides high flexibility, it also becomes a source for failures due to misconfigurations. The large number of parameters these systems have and the long test execution time in this context due to the use of simulation-based testing make the manual repair process a cumbersome activity. Subsequently, in this context, automated repairing methods are paramount. In this paper, we propose an approach to automatically repair CPSs' misconfigurations. Our approach is evaluated with an industrial CPS case study from the elevation domain. Experiments with a real building and data obtained from operation suggests that our approach outperforms a baseline algorithm as well as the state of the practice (i.e., manual repair carried out by domain experts).},
booktitle = {Proceedings of the 45th International Conference on Software Engineering: Software Engineering in Practice},
pages = {396–408},
numpages = {13},
keywords = {configurable systems, debugging, repair, cyber-physical systems},
location = {Melbourne, Australia},
series = {ICSE-SEIP '23}
}

@inproceedings{10.1145/2678015.2682533,
author = {Li, Huiqing and Thompson, Simon},
title = {Safe Concurrency Introduction through Slicing},
year = {2015},
isbn = {9781450332972},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2678015.2682533},
doi = {10.1145/2678015.2682533},
abstract = {Traditional refactoring is about modifying the structure of existing code without changing its behaviour, but with the aim of making code easier to understand, modify, or reuse. In this paper, we introduce three novel refactorings for retrofitting concurrency to Erlang applications, and demonstrate how the use of program slicing makes the automation of these refactorings possible.},
booktitle = {Proceedings of the 2015 Workshop on Partial Evaluation and Program Manipulation},
pages = {103–113},
numpages = {11},
keywords = {slicing, refactoring, parallelisation, functional programming, erlang, concurrency},
location = {Mumbai, India},
series = {PEPM '15}
}

@proceedings{10.1145/3524614,
title = {IWSiB '22: Proceedings of the 5th International Workshop on Software-intensive Business: Towards Sustainable Software Business},
year = {2022},
isbn = {9781450393027},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
abstract = {There are many researchers and practitioners whose work is related to the field of software-intensive business. However, they are often not fully aware of each other's work as the research is scattered. For example, individual research contributions have emerged related to, for example, software engineering economics, digital ecosystems and software startups. The goal of the workshop on Software-intensive Business is to bring these different sub-fields together and strengthen their ties.},
location = {Pittsburgh, Pennsylvania}
}

@proceedings{10.1145/3644815,
title = {CAIN '24: Proceedings of the IEEE/ACM 3rd International Conference on AI Engineering - Software Engineering for AI},
year = {2024},
isbn = {9798400705915},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
abstract = {The goal of the CAIN Conference Series is to bring together researchers and practitioners in software engineering, data science, and artificial intelligence (AI) as part of a growing community that is targeting the challenges of Software Engineering for AI-enabled systems.},
location = {Lisbon, Portugal}
}

@inproceedings{10.1145/3236024.3236055,
author = {Hu, Gang and Zhu, Linjie and Yang, Junfeng},
title = {AppFlow: using machine learning to synthesize robust, reusable UI tests},
year = {2018},
isbn = {9781450355735},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3236024.3236055},
doi = {10.1145/3236024.3236055},
abstract = {UI testing is known to be difficult, especially as today’s development cycles become faster. Manual UI testing is tedious, costly and error- prone. Automated UI tests are costly to write and maintain. This paper presents AppFlow, a system for synthesizing highly robust, highly reusable UI tests. It leverages machine learning to automatically recognize common screens and widgets, relieving developers from writing ad hoc, fragile logic to use them in tests. It enables developers to write a library of modular tests for the main functionality of an app category (e.g., an “add to cart” test for shopping apps). It can then quickly test a new app in the same category by synthesizing full tests from the modular ones in the library. By focusing on the main functionality, AppFlow provides “smoke testing” requiring little manual work. Optionally, developers can customize AppFlow by adding app-specific tests for completeness. We evaluated AppFlow on 60 popular apps in the shopping and the news category, two case studies on the BBC news app and the JackThreads shopping app, and a user-study of 15 subjects on the Wish shopping app. Results show that AppFlow accurately recognizes screens and widgets, synthesizes highly robust and reusable tests, covers 46.6% of all automatable tests for Jackthreads with the tests it synthesizes, and reduces the effort to test a new app by up to 90%. Interestingly, it found eight bugs in the evaluated apps, including seven functionality bugs, despite that they were publicly released and supposedly went through thorough testing.},
booktitle = {Proceedings of the 2018 26th ACM Joint Meeting on European Software Engineering Conference and Symposium on the Foundations of Software Engineering},
pages = {269–282},
numpages = {14},
keywords = {test synthesis, test reuse, mobile testing, machine learning, UI testing, UI recognition},
location = {Lake Buena Vista, FL, USA},
series = {ESEC/FSE 2018}
}

@inproceedings{10.1145/2983990.2984038,
author = {Sun, Chengnian and Le, Vu and Su, Zhendong},
title = {Finding compiler bugs via live code mutation},
year = {2016},
isbn = {9781450344449},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2983990.2984038},
doi = {10.1145/2983990.2984038},
abstract = {Validating optimizing compilers is challenging because it is hard to generate valid test programs (i.e., those that do not expose any undefined behavior). Equivalence Modulo Inputs (EMI) is an effective, promising methodology to tackle this problem. Given a test program with some inputs, EMI mutates the program to derive variants that are semantically equivalent w.r.t. these inputs. The state-of-the-art instantiations of EMI are Orion and Athena, both of which rely on deleting code from or inserting code into code regions that are not executed under the inputs. Although both have demonstrated their ability in finding many bugs in GCC and LLVM, they are still limited due to their mutation strategies that operate only on dead code regions.  This paper presents a novel EMI technique that allows mutation in the entire program (i.e., both live and dead regions). By removing the restriction of mutating only the dead regions, our technique significantly increases the EMI variant space. It also helps to more thoroughly stress test compilers as compilers must optimize mutated live code, whereas mutated dead code might be eliminated. Finally, our technique also makes compiler bugs more noticeable as miscompilations on mutated dead code may not be observable. We have realized the proposed technique in Hermes. The evaluation demonstrates Hermes’s effectiveness. In 13 months, Hermes found 168 confirmed, valid bugs in GCC and LLVM, of which 132 have already been fixed.},
booktitle = {Proceedings of the 2016 ACM SIGPLAN International Conference on Object-Oriented Programming, Systems, Languages, and Applications},
pages = {849–863},
numpages = {15},
keywords = {miscompilation, equivalent program variants, automated testing, Compiler testing},
location = {Amsterdam, Netherlands},
series = {OOPSLA 2016}
}

@article{10.1145/3180495,
author = {Kulla, Christopher and Conty, Alejandro and Stein, Clifford and Gritz, Larry},
title = {Sony Pictures Imageworks Arnold},
year = {2018},
issue_date = {June 2018},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {37},
number = {3},
issn = {0730-0301},
url = {https://doi.org/10.1145/3180495},
doi = {10.1145/3180495},
abstract = {Sony Imageworks’ implementation of the Arnold renderer is a fork of the commercial product of the same name, which has evolved independently since around 2009. This article focuses on the design choices that are unique to this version and have tailored the renderer to the specific requirements of film rendering at our studio. We detail our approach to subdivision surface tessellation, hair rendering, sampling, and variance reduction techniques, as well as a description of our open source texturing and shading language components. We also discuss some ideas we once implemented but have since discarded to highlight the evolution of the software over the years.},
journal = {ACM Trans. Graph.},
month = aug,
articleno = {29},
numpages = {18},
keywords = {rendering, path tracing, Ray tracing, Monte Carlo}
}

@inproceedings{10.1145/3643991.3644912,
author = {Oliver, Philip and Dietrich, Jens and Anslow, Craig and Homer, Michael},
title = {CrashJS: A NodeJS Benchmark for Automated Crash Reproduction},
year = {2024},
isbn = {9798400705878},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3643991.3644912},
doi = {10.1145/3643991.3644912},
abstract = {Software bugs often lead to software crashes, which cost US companies upwards of $2.08 trillion annually. Automated Crash Reproduction (ACR) aims to generate unit tests that successfully reproduce a crash. The goal of ACR is to aid developers with debugging, providing them with another tool to locate where a bug is in a program. The main approach ACR currently takes is to replicate a stack trace from an error thrown within a program. Currently, ACR has been developed for C, Java, and Python, but there are no tools targeting JavaScript programs. To aid the development of JavaScript ACR tools, we propose CrashJS: a benchmark dataset of 453 Node.js crashes from several sources. CrashJS includes a mix of real-world and synthesised tests, multiple projects, and different levels of complexity for both crashes and target programs.},
booktitle = {Proceedings of the 21st International Conference on Mining Software Repositories},
pages = {75–87},
numpages = {13},
keywords = {automated crash reproduction, benchmark, data collection, dataset, software testing, test generation},
location = {Lisbon, Portugal},
series = {MSR '24}
}

@inproceedings{10.1145/2814204.2814221,
author = {Florence, Spencer P. and Fetscher, Bruke and Flatt, Matthew and Temps, William H. and Kiguradze, Tina and West, Dennis P. and Niznik, Charlotte and Yarnold, Paul R. and Findler, Robert Bruce and Belknap, Steven M.},
title = {POP-PL: a patient-oriented prescription programming language},
year = {2015},
isbn = {9781450336871},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2814204.2814221},
doi = {10.1145/2814204.2814221},
abstract = {Medical professionals have long used algorithmic thinking to describe and implement health care processes without the benefit of the conceptual framework provided by a programming language. Instead, medical algorithms are expressed using English, flowcharts, or data tables. This results in prescriptions that are difficult to understand, hard to debug, and awkward to reuse. This paper reports on the design and evaluation of a domain-specific programming language, POP-PL for expressing medical algorithms. The design draws on the experience of researchers in two disciplines, programming languages and medicine. The language is based around the idea that programs and humans have complementary strengths, that when combined can make for safer, more accurate performance of prescriptions. We implemented a prototype of our language and evaluated its design by writing prescriptions in the new language and administering a usability survey to medical professionals. This formative evaluation suggests that medical prescriptions can be conveyed by a programming language's mode of expression and provides useful information for refining the language. Analysis of the survey results suggests that medical professionals can understand and correctly modify programs in POP-PL.},
booktitle = {Proceedings of the 2015 ACM SIGPLAN International Conference on Generative Programming: Concepts and Experiences},
pages = {131–140},
numpages = {10},
keywords = {Medical Programming Languages, Med- ical Prescriptions, Empirical Evaluation, DSL Design},
location = {Pittsburgh, PA, USA},
series = {GPCE 2015}
}

@article{10.14778/3415478.3415481,
author = {Khurana, Kapil and Haritsa, Jayant R.},
title = {UNMASQUE: a hidden SQL query extractor},
year = {2020},
issue_date = {August 2020},
publisher = {VLDB Endowment},
volume = {13},
number = {12},
issn = {2150-8097},
url = {https://doi.org/10.14778/3415478.3415481},
doi = {10.14778/3415478.3415481},
abstract = {Given a database instance and a populated result, query reverse-engineering attempts to identify candidate SQL queries that produce this result on the instance. A variant of this problem arises when a ground-truth is additionally available, but hidden within an opaque database application. In this demo, we present UN-MASQUE, an extraction algorithm that is capable of precisely identifying a substantive class of such hidden queries. A hallmark of its design is that the extraction is completely non-invasive to the application. Specifically, it only examines the results obtained from application executions on databases derived with a combination of data mutation and data generation techniques, thereby achieving platform-independence. Further, potent optimizations, such as database size reduction to a few rows, are incorporated to minimize the extraction overheads. The demo showcases these features on both declarative and imperative applications.},
journal = {Proc. VLDB Endow.},
month = aug,
pages = {2809–2812},
numpages = {4}
}

@proceedings{10.1145/3639477,
title = {ICSE-SEIP '24: Proceedings of the 46th International Conference on Software Engineering: Software Engineering in Practice},
year = {2024},
isbn = {9798400705014},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Lisbon, Portugal}
}

@inproceedings{10.1145/2002931.2002935,
author = {Choudhary, Shauvik Roy and Zhao, Dan and Versee, Husayn and Orso, Alessandro},
title = {WATER: Web Application TEst Repair},
year = {2011},
isbn = {9781450308083},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2002931.2002935},
doi = {10.1145/2002931.2002935},
abstract = {Web applications tend to evolve quickly, resulting in errors and failures in test automation scripts that exercise them. Repairing such scripts to work on the updated application is essential for maintaining the quality of the test suite. Updating such scripts manually is a time consuming task, which is often difficult and is prone to errors if not performed carefully. In this paper, we propose a technique to automatically suggest repairs for such web application test scripts. Our technique is based on differential testing and compares the behavior of the test case on two successive versions of the web application: first version in which the test script runs successfully and the second version in which the script results in an error or failure. By analyzing the difference between these two executions, our technique suggests repairs that can be applied to repair the scripts. To evaluate our technique, we implemented it in a tool called WATER and exercised it on real web applications with test cases. Our experiments show that WATER can suggest meaningful repairs for practical test cases, many of which correspond to those made later by developers themselves.},
booktitle = {Proceedings of the First International Workshop on End-to-End Test Script Engineering},
pages = {24–29},
numpages = {6},
keywords = {web testing, test repair},
location = {Toronto, Ontario, Canada},
series = {ETSE '11}
}

@proceedings{10.1145/3643794,
title = {SERP4IoT '24: Proceedings of the ACM/IEEE 6th International Workshop on Software Engineering Research &amp; Practices for the Internet of Things},
year = {2024},
isbn = {9798400705786},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
abstract = {SERP4IoT begins to be recognized as an annual venue gathering researchers, industrials, and practitioners to share their vision, experience, and opinion on how to address the challenges of, find solutions for, and share experiences with the development, release, and testing of robust software for IoT systems.Even today, there is no precise definition of what is software engineering for the IoT, because it encompasses many different aspects of software design, development, evolution, deployment, and operation, with varying and conflicting criteria such as success, longevity, growth, resilience, survival, diversity, sustainability, transparency, privacy, security, etc.Yet, software engineering is vital for IoT to design systems that are secure, interoperable, modifiable, and scalable. It is crucial to bring good practices for developing projects for IoT, to devise and study the best architectures, to understand and secure communication protocols, and, generally, to overcome the many challenges faced by practitioners and researchers.},
location = {Lisbon, Portugal}
}

@inproceedings{10.1145/3328433.3328447,
author = {Stocco, Andrea},
title = {How artificial intelligence can improve web development and testing},
year = {2019},
isbn = {9781450362573},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3328433.3328447},
doi = {10.1145/3328433.3328447},
abstract = {The Artificial Intelligence (AI) revolution in software development is just around the corner. With the rise of AI, developers are expected to play a different role from the traditional role of programmers, as they will need to adapt their know-how and skillsets to complement and apply AI-based tools and techniques into their traditional web development workflow. In this extended abstract, some of the current trends on how AI is being leveraged to enhance web development and testing are discussed, along with some of the main opportunities and challenges for researchers.},
booktitle = {Companion Proceedings of the 3rd International Conference on the Art, Science, and Engineering of Programming},
articleno = {13},
numpages = {4},
keywords = {web testing, web development, artificial intelligence},
location = {Genova, Italy},
series = {Programming '19}
}

@inproceedings{10.1145/3323503.3360639,
author = {Pinto, Thiago Delgado and Gon\c{c}alves, Willian Inacio and Costa, Pablo Veiga},
title = {User interface prototype generation from agile requirements specifications written in concordia},
year = {2019},
isbn = {9781450367639},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3323503.3360639},
doi = {10.1145/3323503.3360639},
abstract = {User interface prototypes (UIP) are widely used to get feedback before building a software feature. They can prevent misunderstandings between the software development team and other stakeholders (e.g., users, investors) that lead to rework or a resulting software that does not meet their needs. UIP can also be a valuable resource in Agile software development, in which feedback is key. In this paper, we present an approach to generate UIP automatically from Agile requirements specifications written in Concordia and its corresponding prototype tool. The tool is able to generate UIP for web-based applications. We evaluated the approach and the tool with questionnaires, and the results revealed that: (i) the generated UIP are very similar to those drawn by respondents; (ii) the generated source code has good enough quality to be reused by developers; and (iii) they save design and development time.},
booktitle = {Proceedings of the 25th Brazillian Symposium on Multimedia and the Web},
pages = {61–64},
numpages = {4},
keywords = {user story, user interface, generation, concordia, agile},
location = {Rio de Janeiro, Brazil},
series = {WebMedia '19}
}

@proceedings{10.1145/3660829,
title = {Programming '24: Companion Proceedings of the 8th International Conference on the Art, Science, and Engineering of Programming},
year = {2024},
isbn = {9798400706349},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Lund, Sweden}
}

@inproceedings{10.1145/2304656.2304658,
author = {Rupanov, Vladimir and Buckl, Christian and Fiege, Ludger and Armbruster, Michael and Knoll, Alois and Spiegelberg, Gernot},
title = {Early safety evaluation of design decisions in E/E architecture according to ISO 26262},
year = {2012},
isbn = {9781450313476},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2304656.2304658},
doi = {10.1145/2304656.2304658},
abstract = {ISO 26262 addresses development of safe in-vehicle functions by specifying methods potentially used in the design and development lifecycle. It does not indicate what is sufficient and leaves room for interpretation. However, the architects of electric/electronic systems need design boundaries to make decisions during architecture evolution without adding a risk of late architectural changes. Designing and changing a system benefits from correct selection of safety mechanisms at early design stages. This paper presents an iterative architecture design and refinement process that is centered around ISO 26262 requirements. We propose a domain-specific modeling scheme and component repositories to build up a bottom-up analysis framework that allows early quantitative safety evaluation. To guarantee that the target ASIL level can be reached, we complement our design-time component-level analysis with conservative top-down analysis. Given that analysis starts at early design stages, evolution of the architecture is supported by different levels of detail used in the analysis framework.},
booktitle = {Proceedings of the 3rd International ACM SIGSOFT Symposium on Architecting Critical Systems},
pages = {1–10},
numpages = {10},
keywords = {integration of analysis techniques, functional safety, automotive systems, architecture modeling},
location = {Bertinoro, Italy},
series = {ISARCS '12}
}

@article{10.1007/s00165-017-0443-1,
author = {Corrodi, Claudio and Heu\ss{}ner, Alexander and Poskitt, Christopher M.},
title = {A semantics comparison workbench for a concurrent, asynchronous, distributed programming language},
year = {2018},
issue_date = {Jan 2018},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
volume = {30},
number = {1},
issn = {0934-5043},
url = {https://doi.org/10.1007/s00165-017-0443-1},
doi = {10.1007/s00165-017-0443-1},
abstract = {A number of high-level languages and libraries have been proposed that offer novel and simple to use abstractions for concurrent, asynchronous, and distributed programming. The execution models that realise them, however, often change over time—whether to improve performance, or to extend them to new language features—potentially affecting behavioural and safety properties of existing programs. This is exemplified by Scoop, a message-passing approach to concurrent object-oriented programming that has seen multiple changes proposed and implemented, with demonstrable consequences for an idiomatic usage of its core abstraction. We propose a semantics comparison workbench for Scoop with fully and semi-automatic tools for analysing and comparing the state spaces of programs with respect to different execution models or semantics. We demonstrate its use in checking the consistency of properties across semantics by applying it to a set of representative programs, and highlighting a deadlock-related discrepancy between the principal execution models of Scoop. Furthermore, we demonstrate the extensibility of the workbench by generalising the formalisation of an execution model to support recently proposed extensions for distributed programming. Our workbench is based on a modular and parameterisable graph transformation semantics implemented in the Groove tool. We discuss how graph transformations are leveraged to atomically model intricate language abstractions, how the visual yet&nbsp;algebraic nature of the model can be used to ascertain soundness, and highlight how the approach could be applied to similar languages.},
journal = {Form. Asp. Comput.},
month = jan,
pages = {163–192},
numpages = {30},
keywords = {Groove, Scoop, Software engineering, Object-oriented programming, Concurrency abstractions, Verification/analysis parameterised by semantics, Graph transformation systems, Runtime semantics, Operational semantics, Distributed programming with message passing, Concurrent asynchronous programming}
}

@inproceedings{10.1145/1982185.1982464,
author = {Haupt, Michael and Perscheid, Michael and Hirschfeld, Robert},
title = {Type harvesting: a practical approach to obtaining typing information in dynamic programming languages},
year = {2011},
isbn = {9781450301138},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1982185.1982464},
doi = {10.1145/1982185.1982464},
abstract = {Dynamically typed programming languages are powerful tools for rapid software development. However, there are scenarios that would benefit from actual type information being available---e. g., code generation and optimisation as well as program comprehension. Since code written in such languages usually makes little or no explicit assumptions about types, type inference is not particularly well suited to obtain the desired information. This paper introduces type harvesting, a practical approach to obtaining type information. It is based on stepwise code execution of the code in question, closely observing the types of entities in question. Type harvesting allows for exploiting unit tests to automatically obtain type information for a code base. The approach has been implemented in Squeak/Smalltalk. Its evaluation, using several complex applications, shows that type harvesting yields excellent results with high precision.},
booktitle = {Proceedings of the 2011 ACM Symposium on Applied Computing},
pages = {1282–1289},
numpages = {8},
keywords = {unit tests, type inference, type harvesting, dynamically typed programming languages, dynamic analysis},
location = {TaiChung, Taiwan},
series = {SAC '11}
}

@proceedings{10.1145/3708493,
title = {CC '25: Proceedings of the 34th ACM SIGPLAN International Conference on Compiler Construction},
year = {2025},
isbn = {9798400714078},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
abstract = {Welcome to the 34th ACM SIGPLAN International Conference on Compiler Construction (CC 2025), held in Las Vegas, Nevada, USA over March 1-2, 2025. As has been the case for the last 10 years, CC is part of a co-located cluster together with IEEE HPCA, IEEE/ACM CGO, and ACM PPoPP. The co-location brings together researchers with complementary expertise in compilation, architecture, and parallel programming, creating a thriving and unique ecosystem for scientific discovery and advancement.},
location = {Las Vegas, NV, USA}
}

@proceedings{10.1145/3593663,
title = {ECSEE '23: Proceedings of the 5th European Conference on Software Engineering Education},
year = {2023},
isbn = {9781450399562},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Seeon/Bavaria, Germany}
}

@inproceedings{10.1109/ICSE43902.2021.00118,
author = {Mayr-Dorn, Christoph and Vierhauser, Michael and Bichler, Stefan and Keplinger, Felix and Cleland-Huang, Jane and Egyed, Alexander and Mehofer, Thomas},
title = {Supporting Quality Assurance with Automated Process-Centric Quality Constraints Checking},
year = {2021},
isbn = {9781450390859},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/ICSE43902.2021.00118},
doi = {10.1109/ICSE43902.2021.00118},
abstract = {Regulations, standards, and guidelines for safety-critical systems stipulate stringent traceability but do not prescribe the corresponding, detailed software engineering process. Given the industrial practice of using only semi-formal notations to describe engineering processes, processes are rarely "executable" and developers have to spend significant manual effort in ensuring that they follow the steps mandated by quality assurance. The size and complexity of systems and regulations makes manual, timely feedback from Quality Assurance (QA) engineers infeasible. In this paper we propose a novel framework for tracking processes in the background, automatically checking QA constraints depending on process progress, and informing the developer of unfulfilled QA constraints. We evaluate our approach by applying it to two different case studies; one open source community system and a safety-critical system in the air-traffic control domain. Results from the analysis show that trace links are often corrected or completed after the fact and thus timely and automated constraint checking support has significant potential on reducing rework.},
booktitle = {Proceedings of the 43rd International Conference on Software Engineering},
pages = {1298–1310},
numpages = {13},
keywords = {traceability, software engineering process, developer support},
location = {Madrid, Spain},
series = {ICSE '21}
}

@proceedings{10.1145/3627345,
title = {CCIOT '23: Proceedings of the 2023 8th International Conference on Cloud Computing and Internet of Things},
year = {2023},
isbn = {9798400708046},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Okinawa, Japan}
}

@inproceedings{10.1145/2467307.2467316,
author = {Taromirad, Masoumeh and Paige, Richard F.},
title = {Agile requirements traceability using domain-specific modelling languages},
year = {2012},
isbn = {9781450318044},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2467307.2467316},
doi = {10.1145/2467307.2467316},
abstract = {Requirements traceability is an important mechanism for managing verification, validation and change impact analysis challenges in system engineering. Numerous model-based approaches have been proposed to support requirements traceability, but significant challenges remain, including finding the appropriate level of granularity for modelling traceability and coping with the lack of uniformity in requirements management tools. This paper argues for an agile modelling approach to managing requirements traceability and, in this context, proposes a domain/project-specific requirements traceability modelling approach. The preliminary approach is illustrated briefly in the context of the safety-critical systems engineering domain, where agile traceability from functional and safety requirements is necessary to underpin certification.},
booktitle = {Proceedings of the 2012 Extreme Modeling Workshop},
pages = {45–50},
numpages = {6},
location = {Innsbruck, Austria},
series = {XM '12}
}

@inproceedings{10.1007/978-3-642-33666-9_2,
author = {S\'{a}nchez-Cuadrado, Jes\'{u}s and De Lara, Juan and Guerra, Esther},
title = {Bottom-up meta-modelling: an interactive approach},
year = {2012},
isbn = {9783642336652},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-642-33666-9_2},
doi = {10.1007/978-3-642-33666-9_2},
abstract = {The intensive use of models in Model-Driven Engineering (MDE) raises the need to develop meta-models with different aims, like the construction of textual and visual modelling languages and the specification of source and target ends of model-to-model transformations. While domain experts have the knowledge about the concepts of the domain, they usually lack the skills to build meta-models. These should be tailored according to their future usage and specific implementation platform, which demands knowledge available only to engineers with great expertise in MDE platforms. These issues hinder a wider adoption of MDE both by domain experts and software engineers.In order to alleviate this situation we propose an interactive, iterative approach to meta-model construction enabling the specification of model fragments by domain experts, with the possibility of using informal drawing tools like Dia. These fragments can be annotated with hints about the intention or needs for certain elements. A meta-model is automatically induced, which can be refactored in an interactive way, and then compiled into an implementation meta-model using profiles and patterns for different platforms and purposes.},
booktitle = {Proceedings of the 15th International Conference on Model Driven Engineering Languages and Systems},
pages = {3–19},
numpages = {17},
keywords = {meta-modelling, meta-model design exploration, interactive meta-modelling, domain-specific modelling languages},
location = {Innsbruck, Austria},
series = {MODELS'12}
}

@inproceedings{10.1145/1481848.1481860,
author = {Erk\"{o}k, Levent and Matthews, John},
title = {Pragmatic equivalence and safety checking in Cryptol},
year = {2009},
isbn = {9781605583303},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1481848.1481860},
doi = {10.1145/1481848.1481860},
abstract = {Cryptol is programming a language designed for specifying and programming cryptographic algorithms. In order to meet high-assurance requirements, Cryptol comes with a suite of formal-methods based tools allowing users to perform various program verification tasks. In the fully automated mode, Cryptol uses modern off-the-shelf SAT and SMT solvers to perform verification in a push-button manner. In the manual mode, Cryptol produces Isabelle/HOL specifications that can be interactively verified using the Isabelle theorem prover. In this paper, we provide an overview of Cryptol's verification toolset, describing our experiences with building a practical programming environment with dedicated support for formal verification.},
booktitle = {Proceedings of the 3rd Workshop on Programming Languages Meets Program Verification},
pages = {73–82},
numpages = {10},
keywords = {theorem proving, size polymorphism, sat/smt solving, formal methods, equivalence checking, cryptography},
location = {Savannah, GA, USA},
series = {PLPV '09}
}

@proceedings{10.1145/2993236,
title = {GPCE 2016: Proceedings of the 2016 ACM SIGPLAN International Conference on Generative Programming: Concepts and Experiences},
year = {2016},
isbn = {9781450344463},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Amsterdam, Netherlands}
}

@inproceedings{10.5555/227726.227842,
author = {Kieburtz, Richard B. and McKinney, Laura and Bell, Jeffrey M. and Hook, James and Kotov, Alex and Lewis, Jeffrey and Oliva, Dino P. and Sheard, Tim and Smith, Ira and Walton, Lisa},
title = {A software engineering experiment in software component generation},
year = {1996},
isbn = {0818672463},
publisher = {IEEE Computer Society},
address = {USA},
abstract = {The paper presents results of a software engineering experiment in which a new technology for constructing program generators from domain-specific specification languages has been compared with a reuse technology that employs sets of reusable Ada program templates. Both technologies were applied to a common problem domain, constructing message translation and validation modules for military command, control, communications and information systems (C/sup 3/I). The experiment employed four subjects to conduct trials of use of the two technologies on a common set of test examples. The experiment was conducted with personnel supplied and supervised by an independent contractor. Test cases consisted of message specifications taken from Air Force C/sup 3/I systems. The main results are that greater productivity was achieved and fewer error were introduced when subjects used the program generator than when they used Ada templates to implement software modules from sets of specifications. The differences in the average performance of the subjects are statistically significant at confidence levels exceeding 99 percent.},
booktitle = {Proceedings of the 18th International Conference on Software Engineering},
pages = {542–552},
numpages = {11},
keywords = {usability, software component generation, reliability, productivity, flexibility},
location = {Berlin, Germany},
series = {ICSE '96}
}

@inproceedings{10.1145/2103656.2103709,
author = {Zhao, Jianzhou and Nagarakatte, Santosh and Martin, Milo M.K. and Zdancewic, Steve},
title = {Formalizing the LLVM intermediate representation for verified program transformations},
year = {2012},
isbn = {9781450310833},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2103656.2103709},
doi = {10.1145/2103656.2103709},
abstract = {This paper presents Vellvm (verified LLVM), a framework for reasoning about programs expressed in LLVM's intermediate representation and transformations that operate on it. Vellvm provides a mechanized formal semantics of LLVM's intermediate representation, its type system, and properties of its SSA form. The framework is built using the Coq interactive theorem prover. It includes multiple operational semantics and proves relations among them to facilitate different reasoning styles and proof techniques.To validate Vellvm's design, we extract an interpreter from the Coq formal semantics that can execute programs from LLVM test suite and thus be compared against LLVM reference implementations. To demonstrate Vellvm's practicality, we formalize and verify a previously proposed transformation that hardens C programs against spatial memory safety violations. Vellvm's tools allow us to extract a new, verified implementation of the transformation pass that plugs into the real LLVM infrastructure; its performance is competitive with the non-verified, ad-hoc original.},
booktitle = {Proceedings of the 39th Annual ACM SIGPLAN-SIGACT Symposium on Principles of Programming Languages},
pages = {427–440},
numpages = {14},
keywords = {memory safety, LLVM, Coq},
location = {Philadelphia, PA, USA},
series = {POPL '12}
}

@proceedings{10.1145/3644033,
title = {FormaliSE '24: Proceedings of the 2024 IEEE/ACM 12th International Conference on Formal Methods in Software Engineering (FormaliSE)},
year = {2024},
isbn = {9798400705892},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
abstract = {Historically, formal methods academic research and practical software development have had limited mutual interactions—except possibly in specialized domains such as safety-critical software. In recent times, the outlook has considerably improved: on the one hand, formal methods research has delivered more flexible techniques and tools that can support various aspects of the software development process—from user requirements elicitation, to design, implementation, verification and validation, as well as the creation of documentation. On the other hand, software engineering has developed a growing interest in rigorous techniques applied at scale.This evolution, and the desire to further improve it, motivated the creation of FormaliSE: a well-established annual conference whose main goal is to promote work at the intersection of the formal methods and software engineering communities, providing a venue to exchange ideas, experiences, techniques, and results. The collaboration between these two communities can be mutually beneficial by fostering the creation of formal methods that are practically useful and by helping develop higher-quality software.},
location = {Lisbon, Portugal}
}

@proceedings{10.1145/3696443,
title = {CGO '25: Proceedings of the 23rd ACM/IEEE International Symposium on Code Generation and Optimization},
year = {2025},
isbn = {9798400712753},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
abstract = {Welcome to the 23nd ACM/IEEE International Symposium on Code Generation and Optimization (CGO ’25), where we invite you to fabulous Las Vegas.},
location = {Las Vegas, NV, USA}
}

@article{10.1145/3241743,
author = {Stol, Klaas-Jan and Fitzgerald, Brian},
title = {The ABC of Software Engineering Research},
year = {2018},
issue_date = {July 2018},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {27},
number = {3},
issn = {1049-331X},
url = {https://doi.org/10.1145/3241743},
doi = {10.1145/3241743},
abstract = {A variety of research methods and techniques are available to SE researchers, and while several overviews exist, there is consistency neither in the research methods covered nor in the terminology used. Furthermore, research is sometimes critically reviewed for characteristics inherent to the methods. We adopt a taxonomy from the social sciences, termed here the ABC framework for SE research, which offers a holistic view of eight archetypal research strategies. ABC refers to the research goal that strives for generalizability over Actors (A) and precise measurement of their Behavior (B), in a realistic Context (C). The ABC framework uses two dimensions widely considered to be key in research design: the level of obtrusiveness of the research and the generalizability of research findings. We discuss metaphors for each strategy and their inherent limitations and potential strengths. We illustrate these research strategies in two key SE domains, global software engineering and requirements engineering, and apply the framework on a sample of 75 articles. Finally, we discuss six ways in which the framework can advance SE research.},
journal = {ACM Trans. Softw. Eng. Methodol.},
month = sep,
articleno = {11},
numpages = {51},
keywords = {research strategy, Research methodology}
}

@proceedings{10.1145/3671016,
title = {Internetware '24: Proceedings of the 15th Asia-Pacific Symposium on Internetware},
year = {2024},
isbn = {9798400707056},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Macau, China}
}

@proceedings{10.1145/3578527,
title = {ISEC '23: Proceedings of the 16th Innovations in Software Engineering Conference},
year = {2023},
isbn = {9798400700644},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Allahabad, India}
}

@inproceedings{10.5555/2819009.2819099,
author = {Abreu, Rui and Erdogmus, Hakan and Perez, Alexandre},
title = {CodeAware: sensor-based fine-grained monitoring and management of software artifacts},
year = {2015},
publisher = {IEEE Press},
abstract = {Current continuous integration (CI) tools, although extensible, can be limiting in terms of flexibility. In particular, artifact analysis capabilities available through plugin mechanisms are both coarse-grained and centralized. To address this limitation, this paper introduces a new paradigm, CodeAware, for distributed and fine-grained artifact analysis. CodeAware is an ecosystem inspired by sensor networks, consisting of monitors and actuators, aimed at improving code quality and team productivity. CodeAware's vision entails (a) the ability to probe software artifacts of any granularity and localization, from variables to classes or files to entire systems; (b) the ability to perform both static and dynamic analyses on these artifacts; and (c) the ability to describe targeted remediation actions, for example to notify interested developers, through automated actuators. We provide motivational examples for the use of CodeAware that leverage current CI solutions, sketch the architecture of its underlying ecosystem, and outline research challenges.},
booktitle = {Proceedings of the 37th International Conference on Software Engineering - Volume 2},
pages = {551–554},
numpages = {4},
location = {Florence, Italy},
series = {ICSE '15}
}

@inproceedings{10.1145/331960.331968,
author = {Reichwein, James and Rothermel, Gregg and Burnett, Margaret},
title = {Slicing spreadsheets: an integrated methodology for spreadsheet testing and debugging},
year = {2000},
isbn = {1581132557},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/331960.331968},
doi = {10.1145/331960.331968},
abstract = {Spreadsheet languages, which include commercial spreadsheets and various research systems, have proven to be flexible tools in many domain specific settings. Research shows, however, that spreadsheets often contain faults. We would like to provide at least some of the benefits of formal testing and debugging methodologies to spreadsheet developers. This paper presents an integrated testing and debugging methodology for spreadsheets. To accommodate the modeless and incremental development, testing and debugging activities that occur during spreadsheet creation, our methodology is tightly integrated into the spreadsheet environment. To accommodate the users of spreadsheet languages, we provide an interface to our methodology that does not require an understanding of testing and debugging theory, and that takes advantage of the immediate visual feedback that is characteristic of the spreadsheet paradigm.},
booktitle = {Proceedings of the 2nd Conference on Domain-Specific Languages},
pages = {25–38},
numpages = {14},
location = {Austin, Texas, USA},
series = {DSL '99}
}

@proceedings{10.1145/3639478,
title = {ICSE-Companion '24: Proceedings of the 2024 IEEE/ACM 46th International Conference on Software Engineering: Companion Proceedings},
year = {2024},
isbn = {9798400705021},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
abstract = {ICSE is the leading and, by far, the largest conference in Software Engineering, attracting researchers, practitioners, and students worldwide. ICSE2024 is co-located with 11 conferences and symposia this year, many long-established and prestigious venues in their own right.},
location = {Lisbon, Portugal}
}

@proceedings{10.1145/3670474,
title = {MLCAD '24: Proceedings of the 2024 ACM/IEEE International Symposium on Machine Learning for CAD},
year = {2024},
isbn = {9798400706998},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Salt Lake City, UT, USA}
}

@inproceedings{10.1145/3242744.3242748,
author = {Breitner, Joachim},
title = {A promise checked is a promise kept: inspection testing},
year = {2018},
isbn = {9781450358354},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3242744.3242748},
doi = {10.1145/3242744.3242748},
abstract = {Occasionally, developers need to ensure that the compiler treats their code in a specific way that is only visible by inspecting intermediate or final compilation artifacts. This is particularly common with carefully crafted compositional libraries, where certain usage patterns are expected to trigger an intricate sequence of compiler optimizations – stream fusion is a well-known example. The developer of such a library has to manually inspect build artifacts and check for the expected properties. Because this is too tedious to do often, it will likely go unnoticed if the property is broken by a change to the library code, its dependencies or the compiler. The lack of automation has led to released versions of such libraries breaking their documented promises. This indicates that there is an unrecognized need for a new testing paradigm, inspection testing, where the programmer declaratively describes non-functional properties of an compilation artifact and the compiler checks these properties. We define inspection testing abstractly, implement it in the context of the Haskell Compiler GHC and show that it increases the quality of such libraries.},
booktitle = {Proceedings of the 11th ACM SIGPLAN International Symposium on Haskell},
pages = {14–25},
numpages = {12},
keywords = {Testing, Haskell, Compilers},
location = {St. Louis, MO, USA},
series = {Haskell 2018}
}

@proceedings{10.1145/3573105,
title = {CPP 2023: Proceedings of the 12th ACM SIGPLAN International Conference on Certified Programs and Proofs},
year = {2023},
isbn = {9798400700262},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
abstract = {Welcome to the 12th ACM SIGPLAN International Conference on Certified Programs and Proofs (CPP 2023)! CPP covers the practical and theoretical topics in all areas that consider formal verification and certification as essential paradigms for their work. CPP spans topics in computer science, mathematics, logic, and education. CPP 2023 will be held on 16-17 January 2023 in Boston, Massachusetts, United States. The conference is co-located with POPL 2023, and is sponsored by ACM SIGPLAN in cooperation with ACM SIGLOG},
location = {Boston, MA, USA}
}

@inproceedings{10.5555/2050655.2050704,
author = {Wilke, Claas and G\"{o}tz, Sebastian and Reimann, Jan and A\ss{}mann, Uwe},
title = {Vision paper: towards model-based energy testing},
year = {2011},
isbn = {9783642244841},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
abstract = {Today, energy consumption is one of the major challenges for optimisation of future software applications and ICT infrastructures. To develop software w.r.t. its energy consumption, testing is an essential activity, since testing allows quality assurance and thus, energy consumption reduction during the software's development. Although first approaches measuring and predicting software's energy consumption for its execution on a specific hardware platform exist, no model-based testing approach has been developed, yet. In this paper we present our vision of a model-based energy testing approach that uses a combination of abstract interpretation and run-time profiling to predict the energy consumption of software applications and to derive energy consumption test cases.},
booktitle = {Proceedings of the 14th International Conference on Model Driven Engineering Languages and Systems},
pages = {480–489},
numpages = {10},
keywords = {unit testing, profiling, model-based testing, energy consumption testing, abstract interpretation},
location = {Wellington, New Zealand},
series = {MODELS'11}
}

@proceedings{10.5555/3623293,
title = {ICSE-SEIP '23: Proceedings of the 45th International Conference on Software Engineering: Software Engineering in Practice},
year = {2023},
isbn = {9798350300376},
publisher = {IEEE Press},
location = {Melbourne, Australia}
}

@proceedings{10.1145/3551349,
title = {ASE '22: Proceedings of the 37th IEEE/ACM International Conference on Automated Software Engineering},
year = {2022},
isbn = {9781450394758},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Rochester, MI, USA}
}

@proceedings{10.1145/3617232,
title = {ASPLOS '24: Proceedings of the 29th ACM International Conference on Architectural Support for Programming Languages and Operating Systems, Volume 1},
year = {2024},
isbn = {9798400703720},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {1},
abstract = {Welcome to the first volume of ASPLOS'24: the 29th ACM International Conference on Architectural Support for Programming Languages and Operating Systems. For the second year, ASPLOS employs a model of three submission deadlines - spring, summer and fall - along with a major revision mechanism, which, as an alternative to rejection, gives the authors of some submissions the opportunity to fix a list of problems and then resubmit their work to the subsequent review cycle.We introduced several notable changes to ASPLOS this year. Briefly, these include significantly increasing the program committee size to over 220 members (more than twice the size of last year), foregoing synchronous PC meetings and instead making all decisions online, and overhauling the review assignment process. The overhaul includes comparing the textual contents of submissions to the contents of papers authored by the reviewers and using a metric that quantifies the goodness of the match to guide the assignment of reviewers to submissions. The overhaul additionally involves asking reviewers to predict the expertise of their future reviews for a subset of the submissions and using this input as well, among others, for the assignment process.Key statistics of the ASPLOS'24 spring cycle include: 173 submissions were finalized (nearly double last year's spring count), with 47 (27%) related to machine learning, 41 to storage/memory, 39 to accelerators/FPGAs/GPUs, and 27 to security; 87 (51%) submissions were promoted to the second review round; 28 (16.2%) papers were accepted, with 16, 13, and 9 awarded artifact evaluation badges of "available," "functional," and "reproduced," respectively; 27 (15.6%) submissions were allowed to submit major revisions, of which 22 were subsequently accepted during the summer cycle; 762 reviews were uploaded; and 2,868 comments were generated during online discussions.Another change we introduced this year is asking authors to specify their per-submission most-related broader areas of research, which revealed that 54%, 42%, and 25% of the submissions are associated with architecture, operating systems, and programming languages, respectively, with only 21% being interdisciplinary. The full details are available in the PDF of the front matter.},
location = {La Jolla, CA, USA}
}

@inproceedings{10.1145/123186.123411,
author = {Ward, P. C. and Armstrong, J. R.},
title = {Behavioral fault simulation in VHDL},
year = {1991},
isbn = {0897913639},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/123186.123411},
doi = {10.1145/123186.123411},
abstract = {This paper presents two tools which facilitate the fault simulation of behavioral models described using VHDL. The first tool is the Behavioral Fault Mapper (BFM). The BFM algorithm accepts a fault-free VHDL model and a fault list of N faults from which it produces N faulty models. The process of mapping the faults in the fault list onto copies of the original VHDL model is automated. The N faulty models are immediately suitable for fault simulation. The second tool presented is the Test Bench Generator (TBG). The TBG algorithm creates the VHDL TestBench and all other files necessary to complete a batch-mode fault simulation of the N faulty models.},
booktitle = {Proceedings of the 27th ACM/IEEE Design Automation Conference},
pages = {587–593},
numpages = {7},
location = {Orlando, Florida, USA},
series = {DAC '90}
}

@inproceedings{10.1145/3213846.3213859,
author = {Strandberg, Per Erik and Ostrand, Thomas J. and Weyuker, Elaine J. and Sundmark, Daniel and Afzal, Wasif},
title = {Automated test mapping and coverage for network topologies},
year = {2018},
isbn = {9781450356992},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3213846.3213859},
doi = {10.1145/3213846.3213859},
abstract = {Communication devices such as routers and switches play a critical role in the reliable functioning of embedded system networks. Dozens of such devices may be part of an embedded system network, and they need to be tested in conjunction with various computational elements on actual hardware, in many different configurations that are representative of actual operating networks. An individual physical network topology can be used as the basis for a test system that can execute many test cases, by identifying the part of the physical network topology that corresponds to the configuration required by each individual test case. Given a set of available test systems and a large number of test cases, the problem is to determine for each test case, which of the test systems are suitable for executing the test case, and to provide the mapping that associates the test case elements (the logical network topology) with the appropriate elements of the test system (the physical network topology).  We studied a real industrial environment where this problem was originally handled by a simple software procedure that was very slow in many cases, and also failed to provide thorough coverage of each network's elements. In this paper, we represent both the test systems and the test cases as graphs, and develop a new prototype algorithm that a) determines whether or not a test case can be mapped to a subgraph of the test system, b) rapidly finds mappings that do exist, and c) exercises diverse sets of network nodes when multiple mappings exist for the test case. The prototype has been implemented and applied to over 10,000 combinations of test cases and test systems, and reduced the computation time by a factor of more than 80 from the original procedure. In addition, relative to a meaningful measure of network topology coverage, the mappings achieved an increased level of thoroughness in exercising the elements of each test system.},
booktitle = {Proceedings of the 27th ACM SIGSOFT International Symposium on Software Testing and Analysis},
pages = {73–83},
numpages = {11},
keywords = {testing, test coverage, subgraph isomorphism, network topology},
location = {Amsterdam, Netherlands},
series = {ISSTA 2018}
}

@proceedings{10.5555/3606013,
title = {ICSE '23: Proceedings of the 45th International Conference on Software Engineering: Companion Proceedings},
year = {2023},
isbn = {9798350322637},
publisher = {IEEE Press},
abstract = {ICSE is the leading and by far the largest conference in Software Engineering, attracting researchers, practitioners and students from around the world. ICSE2023 is co-located with 10 conferences and symposia this year, many long-established and prestigious venues in their own right.},
location = {Melbourne, Victoria, Australia}
}

@proceedings{10.1145/3508397,
title = {MEDES '22: Proceedings of the 14th International Conference on Management of Digital EcoSystems},
year = {2022},
isbn = {9781450392198},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
abstract = {During the past years, the International Conference on ManagEment of Digital EcoSystems (MEDES) has become one of the most important international scientific events bringing together researchers, developers, and practitioners to discuss latest research issues and experiences in developing advanced solutions that will help to design, deploy, exploit and tune emerging ecosystems.},
location = {Venice, Italy}
}

@inproceedings{10.1145/2652524.2652587,
author = {Rodrigues, Elder M. and Saad, Rodrigo S. and Oliveira, Flavio M. and Costa, Leandro T. and Bernardino, Maicon and Zorzo, Avelino F.},
title = {Evaluating capture and replay and model-based performance testing tools: an empirical comparison},
year = {2014},
isbn = {9781450327749},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2652524.2652587},
doi = {10.1145/2652524.2652587},
abstract = {[Context] A variety of testing tools have been developed to support and automate software performance testing activities. These tools may use different techniques, such as Model-Based Testing (MBT) or Capture and Replay (CR). [Goal] For software companies, it is important to evaluate such tools w.r.t. the effort required for creating test artifacts using them; despite its importance, there are few empirical studies comparing performance testing tools, specially tools developed with different approaches. [Method] We are conducting experimental studies to provide evidence about the required effort to use CR-based tools and MBT tools. In this paper, we present our first results, evaluating the effort (time spent) when using LoadRunner and Visual Studio CR-based tools, and the PLeTsPerf MBT tool to create performance test scripts and scenarios to test Web applications, in the context of a collaboration project between Software Engineering Research Center at PUCRS and a technological laboratory of a global IT company. [Results] Our results indicate that, for simple testing tasks, the effort of using a CR-based tool was lower than using an MBT tool, but as the testing complexity increases tasks, the advantage of using MBT grows significantly. [Conclusions] To conclude, we discuss the lessons we learned from the design, operation, and analysis of our empirical experiment.},
booktitle = {Proceedings of the 8th ACM/IEEE International Symposium on Empirical Software Engineering and Measurement},
articleno = {9},
numpages = {8},
keywords = {testing tools, performance testing, experiment},
location = {Torino, Italy},
series = {ESEM '14}
}

@inproceedings{10.1145/3314221.3314601,
author = {Dasgupta, Sandeep and Park, Daejun and Kasampalis, Theodoros and Adve, Vikram S. and Ro\c{s}u, Grigore},
title = {A complete formal semantics of x86-64 user-level instruction set architecture},
year = {2019},
isbn = {9781450367127},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3314221.3314601},
doi = {10.1145/3314221.3314601},
abstract = {We present the most complete and thoroughly tested formal semantics of x86-64 to date. Our semantics faithfully formalizes all the non-deprecated, sequential user-level instructions of the x86-64 Haswell instruction set architecture. This totals 3155 instruction variants, corresponding to 774 mnemonics. The semantics is fully executable and has been tested against more than 7,000 instruction-level test cases and the GCC torture test suite. This extensive testing paid off, revealing bugs in both the x86-64 reference manual and other existing semantics. We also illustrate potential applications of our semantics in different formal analyses, and discuss how it can be useful for processor verification.},
booktitle = {Proceedings of the 40th ACM SIGPLAN Conference on Programming Language Design and Implementation},
pages = {1133–1148},
numpages = {16},
keywords = {x86-64, ISA specification, Formal Semantics},
location = {Phoenix, AZ, USA},
series = {PLDI 2019}
}

@inproceedings{10.1145/3064899.3064907,
author = {Peijnenburg, Falco and Hage, Jurriaan and Serrano, Alejandro},
title = {Type Directives and Type Graphs in Elm},
year = {2016},
isbn = {9781450347679},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3064899.3064907},
doi = {10.1145/3064899.3064907},
abstract = {We introduce type graphs into Elm in order to improve type error messages for infinite types, and integrate type qualifiers (for type classes a la Haskell) and Elm's row polymorphism into type graphs. We also discuss how specialized type rules and siblings can be used to achieve domain-specific type error diagnosis in the context of Elm.},
booktitle = {Proceedings of the 28th Symposium on the Implementation and Application of Functional Programming Languages},
articleno = {2},
numpages = {12},
keywords = {type graphs, type error diagnosis, type classes, embedded domain specific languages, Elm},
location = {Leuven, Belgium},
series = {IFL 2016}
}

@proceedings{10.1145/3650212,
title = {ISSTA 2024: Proceedings of the 33rd ACM SIGSOFT International Symposium on Software Testing and Analysis},
year = {2024},
isbn = {9798400706127},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
abstract = {Welcome to the 33rd edition of the International Symposium on Software Testing and Analysis, ISSTA 2024, held on September 16--20, 2024 in Vienna, Austria. ISSTA 2024 is co-located with ECOOP and MPLR 2024. ISSTA brings together academics, industrial researchers, and practitioners from all over the world working on testing and analyzing software systems.},
location = {Vienna, Austria}
}

@proceedings{10.1145/3663529,
title = {FSE 2024: Companion Proceedings of the 32nd ACM International Conference on the Foundations of Software Engineering},
year = {2024},
isbn = {9798400706585},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
abstract = {We are pleased to welcome all delegates to FSE 2024, the ACM International Conference on the Foundations of Software Engineering (FSE) 2024. The conference now has a shorter name! FSE is an internationally renowned forum for researchers, practitioners, and educators to present and discuss the most recent innovations, trends, experiences, and challenges in the field of software engineering. FSE brings together experts from academia and industry to exchange the latest research results and trends as well as their practical application in all areas of software engineering.},
location = {Porto de Galinhas, Brazil}
}

@proceedings{10.1145/2983990,
title = {OOPSLA 2016: Proceedings of the 2016 ACM SIGPLAN International Conference on Object-Oriented Programming, Systems, Languages, and Applications},
year = {2016},
isbn = {9781450344449},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Amsterdam, Netherlands}
}

@proceedings{10.1145/3605098,
title = {SAC '24: Proceedings of the 39th ACM/SIGAPP Symposium on Applied Computing},
year = {2024},
isbn = {9798400702433},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
abstract = {On behalf of the Organizing Committee, I extend a warm welcome to you at the 39th Annual ACM Symposium on Applied Computing (SAC 2024), taking place in \'{A}vila, Spain, and hosted by the University of Salamanca. For more than three decades, this international forum has been dedicated to computer scientists, engineers, and practitioners, providing a platform for presenting their research findings and results in various areas of applied computing. The organizing committee sincerely appreciates your participation in this exciting international event, and we hope that the conference proves interesting and beneficial for all attendees.},
location = {Avila, Spain}
}

@inproceedings{10.1145/3007120.3007123,
author = {Dumont, Cyril and Mourlin, Fabrice and Nel, Laurent},
title = {A mobile distributed system for remote resource access},
year = {2016},
isbn = {9781450348065},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3007120.3007123},
doi = {10.1145/3007120.3007123},
abstract = {Mobile and distributed systems involve multiple mobile computers processing data and communicating the results to each other, such as in electronic commerce or online voting, where the users are geographically separated. Our contribution is on mobile distributed applications based on embedded platforms such as smartphones or tablets. We provide a definition of a protocol called MEXP which stands for Mobile Exchange eXperiment Protocol. It allows the exposure of local resources on a mobile device to other mobile computers of the distributed system. The kinds of resources are pictures and sounds which are recorded with a mobile device during lab activities. They require the use of a local Wi-Fi network for the security of the recorded data. The lab activities evolve over time and the observers have remote access to the pictures and sounds for validation and tagging. This work has resulted in the acceptance of our mobile distributed application by an academic training team in the Biology department.},
booktitle = {Proceedings of the 14th International Conference on Advances in Mobile Computing and Multi Media},
pages = {154–163},
numpages = {10},
keywords = {mobile REST services, distributed application, data collection, NFC exchange, Mobile architecture},
location = {Singapore, Singapore},
series = {MoMM '16}
}

@inproceedings{10.1145/1869643.1869648,
author = {Rideau, Francois-Ren\'{e} and Goldman, Robert P.},
title = {Evolving ASDF: more cooperation, less coordination},
year = {2010},
isbn = {9781450304702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1869643.1869648},
doi = {10.1145/1869643.1869648},
abstract = {We present ASDF2, the current state of the art in CL build systems. From a technical standpoint, ASDF2 improves upon ASDF by integrating previous common extensions, making configuration easy, and fixing bugs. However the overriding concern driving these changes was social rather than technical: ASDF plays a central role in the CL community and we wanted to reduce the coordination costs that it imposed upon CL programmers. We outline ASDF's history and architecture, explain the link between the social issues we faced and the software features we added, and explore the technical challenges involved and lessons learned, notably involving inplace code upgrade of ASDF itself, backward compatibility, portability, testing and other coding best practices.},
booktitle = {Proceedings of the 2010 International Conference on Lisp},
pages = {29–42},
numpages = {14},
keywords = {interaction design, dynamic code update., common lisp, code evolution, build infrastructure},
location = {Reno/Tahoe, Nevada, USA},
series = {ILC '10}
}

@inproceedings{10.1145/2593743.2593747,
author = {Malakuti, Somayeh and Wilke, Claas},
title = {Energy aspects: modularizing energy-aware applications},
year = {2014},
isbn = {9781450328449},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2593743.2593747},
doi = {10.1145/2593743.2593747},
abstract = {To effectively extend legacy applications with energy-awareness functionality, dedicated modularization mechanisms are required. This paper introduces the GreenDev framework, which integrates energy testing and event-based modularization for this matter. Energy testing facilitates identifying the energy-related interfaces of applications to the energy-awareness functionality, and event-based modularization facilitates modularizing this functionality from the base functionality of the applications. To maintain loose coupling among these, GreenDev offers a dedicated interface definition language, which enables defining the interfaces abstractly from the actual implementation of the applications. The applications are automatically augmented with these interfaces. We illustrate the applicability of GreenDev in implementing an energy-aware mobile emailing app.},
booktitle = {Proceedings of the 3rd International Workshop on Green and Sustainable Software},
pages = {23–30},
numpages = {8},
keywords = {energy testing, energy st-atechart, aspect-orientated programming, Event-based modularization},
location = {Hyderabad, India},
series = {GREENS 2014}
}

@proceedings{10.5555/3606010,
title = {ICSE '23: Proceedings of the 45th International Conference on Software Engineering},
year = {2023},
isbn = {9781665457019},
publisher = {IEEE Press},
abstract = {ICSE is the leading and by far the largest conference in Software Engineering, attracting researchers, practitioners and students from around the world. ICSE2023 is co-located with 10 conferences and symposia this year, many long-established and prestigious venues in their own right.},
location = {Melbourne, Victoria, Australia}
}

@proceedings{10.1145/3615318,
title = {EuroMPI '23: Proceedings of the 30th European MPI Users' Group Meeting},
year = {2023},
isbn = {9798400709135},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Bristol, United Kingdom}
}

@proceedings{10.1145/3540250,
title = {ESEC/FSE 2022: Proceedings of the 30th ACM Joint European Software Engineering Conference and Symposium on the Foundations of Software Engineering},
year = {2022},
isbn = {9781450394130},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
abstract = {On behalf of all members of the organizing committee, we are delighted to welcome everyone to the ACM Joint European Software Engineering Conference and Symposium on the Foundations of Software Engineering (ESEC/FSE) 2022. The event continues the long, distinguished ESEC/FSE tradition of presenting the most innovative research, and facilitating interactions between scientists and engineers who are passionate about advancing the theory and practice of software engineering.},
location = {Singapore, Singapore}
}

@proceedings{10.1145/3597926,
title = {ISSTA 2023: Proceedings of the 32nd ACM SIGSOFT International Symposium on Software Testing and Analysis},
year = {2023},
isbn = {9798400702211},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
abstract = {It is our great pleasure to welcome you to ISSTA 2023, the 32nd edition of the International Symposium on Software Testing and Analysis, to be held on July 18–20, 2023 in Seattle, USA. The symposium has become a premier scientific event in the expanding area of software testing and analysis, with a strong appeal to researchers from all continents.},
location = {Seattle, WA, USA}
}

@proceedings{10.1145/3605423,
title = {ICCTA '23: Proceedings of the 2023 9th International Conference on Computer Technology Applications},
year = {2023},
isbn = {9781450399579},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Vienna, Austria}
}

@proceedings{10.1145/3624062,
title = {SC-W '23: Proceedings of the SC '23 Workshops of the International Conference on High Performance Computing, Network, Storage, and Analysis},
year = {2023},
isbn = {9798400707858},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Denver, CO, USA}
}

@proceedings{10.1145/3592813,
title = {SBSI '23: Proceedings of the XIX Brazilian Symposium on Information Systems},
year = {2023},
isbn = {9798400707599},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Macei\'{o}, Brazil}
}

@proceedings{10.1145/3597503,
title = {ICSE '24: Proceedings of the IEEE/ACM 46th International Conference on Software Engineering},
year = {2024},
isbn = {9798400702174},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Lisbon, Portugal}
}

@proceedings{10.1145/3580252,
title = {CHASE '23: Proceedings of the 8th ACM/IEEE International Conference on Connected Health: Applications, Systems and Engineering Technologies},
year = {2023},
isbn = {9798400701023},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
abstract = {It is our great pleasure to welcome you to the eighth edition of the IEEE/ACM International Conference on Connected Health: Applications, Systems and Engineering Technologies (CHASE 2023). This is a leading international conference in the field of connected health, an interdisciplinary area with rich research problems and opportunities. CHASE aims to bring together researchers working in the smart and connected health area around the world to exchange ideas and foster collaborations. Its scope covers sensing, communications, and intelligent analytics in support of health-related applications, systems, and engineering technologies. The innovative works published at CHASE will revolutionize preventative health and personalized medicine, providing rich medical information never-before available to individuals while driving down healthcare costs.},
location = {Orlando, FL, USA}
}

@proceedings{10.1145/3677779,
title = {CMNM '24: Proceedings of the International Conference on Modeling, Natural Language Processing and Machine Learning},
year = {2024},
isbn = {9798400709760},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Xi'an, China}
}

@inproceedings{10.1145/1353482.1353484,
author = {Benz, Sebastian},
title = {AspectT: aspect-oriented test case instantiation},
year = {2008},
isbn = {9781605580449},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1353482.1353484},
doi = {10.1145/1353482.1353484},
abstract = {Test case instantiation is the transformation of abstract test cases into executable test scripts. Abstract test cases are either created during model based test case generation or are manually defined in a suitable modeling notation. The transformation varies depending on different testing concerns, such as test goal, test setup and test phase. Thus, for each testing concern a new transformation must be defined. This paper introduces AspectT, an aspect-oriented language for the instantiation of abstract test cases. We reduce the effort of test case instantiation by modularizing testing concerns in the form of aspects to enable their reuse in different testing contexts. The approach is implemented and integrated in an existing testing framework and has been successfully applied to test an electronic control unit of an automotive infotainment system at BMW Group.},
booktitle = {Proceedings of the 7th International Conference on Aspect-Oriented Software Development},
pages = {1–12},
numpages = {12},
keywords = {test case instantiation, test case generation, model-based testing, aspect-orientation},
location = {Brussels, Belgium},
series = {AOSD '08}
}

@proceedings{10.1145/3635059,
title = {PCI '23: Proceedings of the 27th Pan-Hellenic Conference on Progress in Computing and Informatics},
year = {2023},
isbn = {9798400716263},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Lamia, Greece}
}

@inproceedings{10.5555/1022685.1022944,
author = {Brini, Silvia and Benjelloun, Doha and Castanier, Fabien},
title = {A Flexible Virtual Platform for Computational and Communication Architecture Exploration of DMT VDSL Modems},
year = {2003},
isbn = {0769518702},
publisher = {IEEE Computer Society},
address = {USA},
abstract = {In this paper a high-level SoC architecture exploration of DMT (Discrete Multitone) VDSL transceivers (Very high speed Digital Subscriber Line) is presented. A flexible and complete virtual platform was developed for the purpose, exploiting the paradigm of "orthogonalization of concerns" (functionality independent from architecture) in the framework of Cadence VCC system level design tool. An accurate processor model, obtained through the back-annotation of profiling results on a target DSP core, allowed the exploration of different HW/SW partitioning and the study of the computational units required. A transaction-accurate VCC bus model was developed for the investigation of the on-chip bus architecture and its relevant parameters dimensioning.},
booktitle = {Proceedings of the Conference on Design, Automation and Test in Europe: Designers' Forum - Volume 2},
pages = {20164},
series = {DATE '03}
}

@inproceedings{10.5555/800054.802007,
author = {Boehm, Barry W. and Gray, Terence E. and Seewaldt, Thomas},
title = {Prototyping vs. specifying: A multi-project experiment},
year = {1984},
isbn = {0818605286},
publisher = {IEEE Press},
abstract = {In this experiment, seven software teams developed versions of the same small-size (2000-4000 source instruction) application software product. Four teams used the Specifying approach. Three teams used the Prototyping approach.The main results of the experiment were:Prototyping yielded products with roughly equivalent performance, but with about 40% less code and 45% less effort.The prototyped products rated somewhat lower on functionality and robustness, but higher on ease of use and ease of learning.Specifying produced more coherent designs and software that was easier to integrate.The paper presents the experimental data supporting these and a number of additional conclusions.},
booktitle = {Proceedings of the 7th International Conference on Software Engineering},
pages = {473–484},
numpages = {12},
location = {Orlando, Florida, USA},
series = {ICSE '84}
}

@proceedings{10.1145/2837614,
title = {POPL '16: Proceedings of the 43rd Annual ACM SIGPLAN-SIGACT Symposium on Principles of Programming Languages},
year = {2016},
isbn = {9781450335492},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {St. Petersburg, FL, USA}
}

@article{10.1145/351159.351173,
author = {Heering, Jan and Klint, Paul},
title = {Semantics of programming languages: a tool-oriented approach},
year = {2000},
issue_date = {March 2000},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {35},
number = {3},
issn = {0362-1340},
url = {https://doi.org/10.1145/351159.351173},
doi = {10.1145/351159.351173},
abstract = {By paying more attention to semantics-based tool generation, programming language semantics can significantly increase its impact. Ultimately, this may lead to "Language Design Assistants" incorporating substantial amounts of semantic knowledge.},
journal = {SIGPLAN Not.},
month = mar,
pages = {39–48},
numpages = {10}
}

@proceedings{10.5555/3643142,
title = {WSC '23: Proceedings of the Winter Simulation Conference},
year = {2023},
isbn = {9798350369663},
publisher = {IEEE Press},
location = {San Antonio, Texas, USA}
}

@proceedings{10.1145/2950290,
title = {FSE 2016: Proceedings of the 2016 24th ACM SIGSOFT International Symposium on Foundations of Software Engineering},
year = {2016},
isbn = {9781450342186},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Seattle, WA, USA}
}

@proceedings{10.1145/3622758,
title = {Onward! 2023: Proceedings of the 2023 ACM SIGPLAN International Symposium on New Ideas, New Paradigms, and Reflections on Programming and Software},
year = {2023},
isbn = {9798400703881},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
abstract = {Welcome to the 2023 ACM SIGPLAN International Symposium on New Ideas, New Paradigms, and Reflections on Programming and Software (Onward! 2023), the premier multidisciplinary conference focused on everything to do with programming and software, including processes, methods, languages, communities and applications. Onward! is more radical, more visionary, and more open than other conferences to ideas that are well-argued but not yet fully proven. We welcome different ways of thinking about, approaching, and reporting on programming language and software engineering research.    Onward! 2023 is co-located with SPLASH 2023, running from Sunday 22nd of October till Friday 27th of October, in Cascais, Portugal. We are delighted to have Felienne Hermans giving the Onward! keynote, on Wednesday 25th of October, on "Creating a learnable and inclusive programming language".    All papers and essays that lie here before you received at least three reviews, leading to a decision of accept, reject, or conditional accept. Authors of conditionally accepted papers were provided with explicit requirements for acceptance, and were carefully re-reviewed in the second phase. The essays track received six submissions, out of which four were accepted. The papers track accepted nine out of nineteen submissions.   We hope that the papers and essays in these proceedings will stimulate and challenge your thinking about programming and software engineering, and we are looking forward to many discussions at the conference.},
location = {Cascais, Portugal}
}

@proceedings{10.1145/3641554,
title = {SIGCSETS 2025: Proceedings of the 56th ACM Technical Symposium on Computer Science Education V. 1},
year = {2025},
isbn = {9798400705311},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
abstract = {Welcome to the 56th annual SIGCSE Technical Symposium on Computer Science Education (SIGCSE TS 2025)! For the first time since 1978, our symposium is being held in the "Steel City" of Pittsburgh, Pennsylvania, at the intersection of the Allegheny, Ohio, and Monongahela rivers. We are looking forward to four days of productive and informative presentations, vibrant and engaging discussions, and an overall wonderful experience with our SIGCSE community members. We are confident that our program of events provides meaningful and productive experiences for all.Our theme for this year is "Leading the Transformation". Our theme reflects the role of the computer science education community in adapting educational practice to new technologies and challenges. With advances in Artificial Intelligence (AI) transforming both academia and the workplace, the computer science education community has a unique opportunity to help shape the future use and application of computing. Our program this year is quite diverse and offers something for everyone, so please take time to peruse the schedule and choose the sessions which appeal to you. Pittsburgh is also an exciting city with lots to see and do, so you are encouraged to enjoy all the city has to offer.The format of the 2025 Technical Symposium is similar to 2024 in many ways. We will once again have a program that extends into Saturday afternoon, including papers and the Nifty Assignment session after lunch. We will also again have three Birds-of-a-Feather sessions, two on Thursday evening and one during lunch on Friday. For online attendees, we will continue to offer streaming of keynotes, the Nifty Assignment session, the First-Timers Lunch presentation, and a small set of paper, panel, and special sessions.This year we received almost 1200 submissions. Submission statistics for all of the Technical Symposium's tracks can be found in the table that follows. Papers were submitted to one of three tracks (Computing Education Research, Experience Reports and Tools, Position and Curricula Initiatives) with reviewing tailored to each track. Each paper submission was reviewed by at least three reviewers, with a substantial proportion of papers receiving four (or more) reviews, plus a meta review. We sincerely appreciate the work of the more than 800 reviewers and 112 Associate Program Chairs who contributed to the creation of this years' program. Their reviews helped us decide which submissions were accepted while also providing detailed feedback that allowed authors to further improve the final versions of their submissions.},
location = {Pittsburgh, PA, USA}
}

@proceedings{10.1109/3656336,
title = {ASPDAC '22: Proceedings of the 27th Asia and South Pacific Design Automation Conference},
year = {2022},
isbn = {9781665421355},
publisher = {IEEE Press},
abstract = {ASP-DAC is a high-quality and premium conference on Electronic Design Automation (EDA) like other sister conferences such as Design Automation Conference (DAC), Design, Automation &amp; Test in Europe (DATE), International Conference on Computer Aided Design (ICCAD), and Embedded Systems Week (ESWEEK). ASP-DAC started in 1995 and has continuously offered opportunities for researchers and designers in the world to learn about the advancements on design and automation of electronic systems.},
location = {Taipei, Taiwan}
}

@proceedings{10.1145/3629479,
title = {SBQS '23: Proceedings of the XXII Brazilian Symposium on Software Quality},
year = {2023},
isbn = {9798400707865},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Bras\'{\i}lia, Brazil}
}

@proceedings{10.1145/2676726,
title = {POPL '15: Proceedings of the 42nd Annual ACM SIGPLAN-SIGACT Symposium on Principles of Programming Languages},
year = {2015},
isbn = {9781450333009},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
abstract = {It is our great pleasure to welcome you to the 42nd ACM Symposium on Principles of Programming Languages, POPL 2015, held in Mumbai, India, at the beautiful Tata Institute for Fundamental Research. This year's program consists of 52 papers drawn from the 227 papers originally submitted at the July 2014 paper deadline. These papers cover a wide range of topics stretching from theoretical foundations concerning the lambda calculus, type theory and verification to applications in security, networking, and web programming. The program also features invited talks from Peter Buneman, Sumit Gulwani and Peter Lee.While at POPL'15 in Mumbai, we encourage you to take part in the following co-located events: ACM SIGPLAN Conference on Certified Programs and Proofs (CPP)International Workshop on Coq for Programming Languages (CoqPL)POPL Off the Beaten Track: New Frontiers for Programming Languages Research (OBT)ACM SIGPLAN Workshop on Partial Evaluation and Program Manipulation (PEPM)ACM SIGPLAN Programming Languages Mentoring Workshop (PLMW)International Conference on Verification, Model Checking and Abstract Interpretation (VMCAI)Programming Languages and Verification Technology for Networking (PLVNET)IMPECS-POPL Workshop on Emerging Research and Development Trends in Programming Languages (WEPL)Six tutorials.},
location = {Mumbai, India}
}

@proceedings{10.1145/2970276,
title = {ASE '16: Proceedings of the 31st IEEE/ACM International Conference on Automated Software Engineering},
year = {2016},
isbn = {9781450338455},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Singapore, Singapore}
}

@proceedings{10.1145/3620666,
title = {ASPLOS '24: Proceedings of the 29th ACM International Conference on Architectural Support for Programming Languages and Operating Systems, Volume 3},
year = {2024},
isbn = {9798400703867},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {3},
abstract = {Welcome to the third volume of ASPLOS'24: the 29th ACM International Conference on Architectural Support for Programming Languages and Operating Systems. This document is mostly dedicated to the 2024 fall cycle but also provides some statistics summarizing all three cycles.We introduced several notable changes to ASPLOS this year, most of which were discussed in our previous messages from program chairs in Volume 1 and 2, including: (1) significantly increasing the program committee size to over 220 members (more than twice the size of last year); (2) foregoing synchronous program committee (PC) meetings and instead making all decisions online; (3) overhauling the review assignment process; (4) developing an automated submission format violation identifier script that uncovers, e.g., disallowed vertical space manipulations that "squeeze" space; (5) introducing the new ASPLOS role of Program Vice Chairs to cope with the increased number of submissions and the added load caused by foregoing synchronous program committee; and (6) characterizing a systematic problem that ASPLOS is facing in reviewing quantum computing submissions, describing how we addressed it and highlighting how we believe that it should be handled in the future.Assuming readers have read our previous messages, here, we will only describe differences between the current cycle and the previous ones. These include: (1) Finally unifying submission and acceptance paper formatting instructions (forgoing the `jpaper' class) to rid authors of accepted papers from the need to reformat; (2) Describing the methodology we employed to select best papers, which we believe ensures quality and hope will persist; and (3) Reporting the ethical incidents we encountered and how we handled them. In the final, fourth volume, when the outcome of the ASPLOS'24 fall major revisions will become known, we plan to conduct a broader analysis of all the data we have gathered throughout the year.Following are some key statistics of the fall cycle: 340 submissions were finalized (43% more than last year's fall count and 17% less than our summer cycle) of which 111 are related to accelerators/FPGAs/GPUs, 105 to machine learning, 54 to security, 50 to datacenter/cloud and 50 to storage/memory; 183 (54%) submissions were promoted to the second review round; 39 (11.5%) papers were accepted (of which 19 were awarded artifact evaluation badges); 33 (9.7%) submissions were allowed to submit major revisions and are currently under review (these will be addressed in the fourth volume of ASPLOS'24 and will be presented in ASPLOS'25 if accepted); 1,368 reviews were uploaded; and 4,949 comments were generated during online discussions, of which 4,070 were dedicated to the submissions that made it to the second review round.This year, in the submission form, we asked authors to specify which of the three ASPLOS research areas are related to their submitted work. Analyzing this data revealed that 80%, 39%, and 29% of the submissions are categorized by their authors as related to architecture, operating systems, and programming languages, respectively, generating the highest difference we have observed across the cycles between architecture and the other two. About 46% of the fall submissions are "interdisciplinary," namely, were associated with two or more of the three areas.Overall, throughout all the ASPLOS'24 cycles, we received 922 submissions, constituting a 1.54x increase compared to last year. Our reviewers submitted a total of 3,634 reviews containing more than 2.6 million words, and we also generated 12,655 online comments consisting of nearly 1.2 million words. As planned, PC members submitted an average of 15.7 reviews and a median of 15, and external review committee (ERC) members submitted an average of 4.7 and a median of 5.We accepted 170 papers thus far, written by 1100 authors, leading to an 18.4% acceptance rate, with the aforementioned 33 major revisions still under review. Assuming that the revision acceptance rate will be similar to that of previous cycles, we estimate that ASPLOS'24 will accept nearly 200 (!) papers, namely, 21%–22% of the submissions.The ASPLOS'24 program consists of 193 papers: the 170 papers we accepted thus far and, in addition, 23 major revisions from the fall cycle of ASPLOS'23, which were re-reviewed and accepted. The full details are available in the PDF of the front matter.},
location = {La Jolla, CA, USA}
}

@inproceedings{10.1145/1409944.1409969,
author = {Liu, Xin and Sridharan, Ashwin and Machiraju, Sridhar and Seshadri, Mukund and Zang, Hui},
title = {Experiences in a 3G network: interplay between the wireless channel and applications},
year = {2008},
isbn = {9781605580968},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1409944.1409969},
doi = {10.1145/1409944.1409969},
abstract = {We present an experimental characterization of the physical and MAC layers in CDMA 1xEV-DO and their impact on transport layer performance. The 1xEV-DO network is currently the fastest mobile broadband cellular network, offering data rates of up to 3.1 Mbps for both stationary and mobile users. These rates are achieved by using novel capacity enhancement techniques at the lower layers. Specifically, 1xEV-DO incorporates rapid channel rate adaptation in response to signal conditions, and opportunistic scheduling to exploit channel fluctuations. Although shown to perform well in isolation, there is no comprehensive literature that examines the impact of these features on transport layer and application performance in real networks.We take the first step in addressing this issue through a large set of experiments conducted on a commercial 1xEV-DO network. Our evaluation includes both stationary and mobile scenarios wherein we transferred data using four popular transport protocols: TCPReno, TCP-Vegas, TCP-Westwood, and TCP-Cubic, and logged detailed measurements about wireless channel level characteristics as well as transport layer performance. We analyzed data from several days of experiments and inferred the properties of the physical, MAC and transport layers, as well as potential interactions between them. We find that the wireless channel data rate shows significant variability over long time scales on the order of hours, but retains high memory and predictability over small time scales on the order of milliseconds. We also find that loss-based TCP variants are largely unaffected by channel variations due to the presence of large buffers, and hence able to achieve in excess of 80% of the system capacity.},
booktitle = {Proceedings of the 14th ACM International Conference on Mobile Computing and Networking},
pages = {211–222},
numpages = {12},
keywords = {proportional fair (PF), mobility, measurement, cross-layer, cellular, TCP, SINR, DRC, CDMA, 3G, 1xEV-DO},
location = {San Francisco, California, USA},
series = {MobiCom '08}
}

@proceedings{10.1145/3651781,
title = {ICSCA '24: Proceedings of the 2024 13th International Conference on Software and Computer Applications},
year = {2024},
isbn = {9798400708329},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Bali Island, Indonesia}
}

@proceedings{10.1145/3674805,
title = {ESEM '24: Proceedings of the 18th ACM/IEEE International Symposium on Empirical Software Engineering and Measurement},
year = {2024},
isbn = {9798400710476},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Barcelona, Spain}
}

@proceedings{10.1145/3565387,
title = {CSAE '22: Proceedings of the 6th International Conference on Computer Science and Application Engineering},
year = {2022},
isbn = {9781450396004},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Virtual Event, China}
}

@proceedings{10.5555/3571885,
title = {SC '22: Proceedings of the International Conference on High Performance Computing, Networking, Storage and Analysis},
year = {2022},
isbn = {9784665454445},
publisher = {IEEE Press},
abstract = {This volume, containing the accepted technical papers and ACM Gordon Bell prize finalists, captures the best current research in all aspects of High Performance Computing (HPC). The SC22 Archive at the conference web site sc22.supercomputing.org complements this volume by collecting other high quality, peer-reviewed material including research posters, the visualization &amp; data analytics showcase, panels, birds of a feather, workshops, and tutorials.},
location = {Dallas, Texas}
}

@proceedings{10.1145/3608298,
title = {ICMHI '23: Proceedings of the 2023 7th International Conference on Medical and Health Informatics},
year = {2023},
isbn = {9798400700712},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Kyoto, Japan}
}

@proceedings{10.1145/3689031,
title = {EuroSys '25: Proceedings of the Twentieth European Conference on Computer Systems},
year = {2025},
isbn = {9798400711961},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
abstract = {We are delighted to welcome you to EuroSys 2025, the 20th edition of the European Conference on Computer Systems! We are excited to host EuroSys 2025 in the modern and dynamic city of Rotterdam, Netherlands. This year's EuroSys is very special as it is co-located (for the first time) with the 30th ACM International Conference on Architectural Support for Programming Languages and Operating Systems (ASPLOS 2025). We hope you will enjoy an excellent technical program, engaging discussions, and networking opportunities in this vibrant city known for its innovative architecture, bustling port, and rich cultural scene.},
location = {Rotterdam, Netherlands}
}

@proceedings{10.1145/3569951,
title = {PEARC '23: Practice and Experience in Advanced Research Computing 2023: Computing for the Common Good},
year = {2023},
isbn = {9781450399852},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Portland, OR, USA}
}

@proceedings{10.1145/3664476,
title = {ARES '24: Proceedings of the 19th International Conference on Availability, Reliability and Security},
year = {2024},
isbn = {9798400717185},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Vienna, Austria}
}

@article{10.1145/844128.844152,
author = {White, Brian and Lepreau, Jay and Stoller, Leigh and Ricci, Robert and Guruprasad, Shashi and Newbold, Mac and Hibler, Mike and Barb, Chad and Joglekar, Abhijeet},
title = {An integrated experimental environment for distributed systems and networks},
year = {2003},
issue_date = {Winter 2002},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {36},
number = {SI},
issn = {0163-5980},
url = {https://doi.org/10.1145/844128.844152},
doi = {10.1145/844128.844152},
abstract = {Three experimental environments traditionally support network and distributed systems research: network emulators, network simulators, and live networks. The continued use of multiple approaches highlights both the value and inadequacy of each. Netbed, a descendant of Emulab, provides an experimentation facility that integrates these approaches, allowing researchers to configure and access networks composed of emulated, simulated, and wide-area nodes and links. Netbed's primary goals are ease of use, control, and realism, achieved through consistent use of virtualization and abstraction.By providing operating system-like services, such as resource allocation and scheduling, and by virtualizing heterogeneous resources, Netbed acts as a virtual machine for network experimentation. This paper presents Netbed's overall design and implementation and demonstrates its ability to improve experimental automation and efficiency. These, in turn, lead to new methods of experimentation, including automated parameter-space studies within emulation and straightforward comparisons of simulated, emulated, and wide-area scenarios.},
journal = {SIGOPS Oper. Syst. Rev.},
month = dec,
pages = {255–270},
numpages = {16}
}

@proceedings{10.1145/3661167,
title = {EASE '24: Proceedings of the 28th International Conference on Evaluation and Assessment in Software Engineering},
year = {2024},
isbn = {9798400717017},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Salerno, Italy}
}

@proceedings{10.1145/3669940,
title = {ASPLOS '25: Proceedings of the 30th ACM International Conference on Architectural Support for Programming Languages and Operating Systems, Volume 1},
year = {2025},
isbn = {9798400706981},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
abstract = {We are delighted to introduce the first volume of the ASPLOS proceedings for 2025. The conference is in its third year of an experiment with a three-deadline structure: authors can submit to any of three separate review cycles handled by a single year-long program committee. This volume includes papers from the first two review cycles, which had submission deadlines in the spring and summer of 2024. We combined the two cycles because submission volumes in the spring cycle were disproportionately small.This volume contains 72 of the 74 papers accepted to ASPLOS 2025 to date. This includes papers accepted in the spring and summer cycles and those invited to submit a revision in the spring cycle that was ultimately accepted. Two of these 74 accepted papers are still undergoing artifact evaluation and will be published in a subsequent volume. The spring and summer review cycles saw a combined 586 submissions. These submissions were reviewed by a 208-person Program Committee augmented by 57 External Review Committee members. On occasion, we solicited a small number of external expert reviews. On the PC, 129 members self-reported they were in an academic role and 77 self-reported they were in an industrial role. On the ERC it was 43 and 13 respectively. The median PhD year of the combined committees was 2014. In addition to these committees, we engaged ten vice chairs, experienced and trusted reviewers who helped us monitor the review process for each paper.These committees reviewed all of the submissions that were not desk rejected (11 papers) or withdrawn (4 papers). In keeping with recent norms, the technical review happened in two phases. Each paper received three reviews in the first round, with, in most cases, two additional reviews in the second round for the 54% of submissions that advanced. To assign reviews, we used the Toronto Paper Matching System (TPMS) to provide a preliminary review assignment that matched reviewer expertise. We then manually inspected and adjusted these assignments as needed: for example, to correct errors in TPMS's topic modeling or adjust to late-discovered conflicts. In addition, each paper was assigned a non-conflicted chair and a non-conflicted vice chair to provide two extra sets of eyes to monitor and facilitate the process. Due to the size and distribution of the PC, which spanned 14 time zones, the PC did not meet synchronously. Instead, each paper was discussed by the reviewers via comments in the HotCRP system. Ultimately, the discussion for each paper reached one of three outcomes: rejection, conditional acceptance, or major revision. All conditionally accepted papers were shepherded. Major revision papers were invited to revise and resubmit their paper for a second round of review by a subset of the original reviewers. All authors of papers that advanced to the second round of review were given the opportunity to see and respond to their reviewer questions prior to the reviewer discussion.},
location = {Rotterdam, Netherlands}
}

@proceedings{10.1145/3658271,
title = {SBSI '24: Proceedings of the 20th Brazilian Symposium on Information Systems},
year = {2024},
isbn = {9798400709968},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Juiz de Fora, Brazil}
}

@proceedings{10.1145/3556223,
title = {ICCCM '22: Proceedings of the 10th International Conference on Computer and Communications Management},
year = {2022},
isbn = {9781450396349},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Okayama, Japan}
}

@proceedings{10.1145/3566097,
title = {ASPDAC '23: Proceedings of the 28th Asia and South Pacific Design Automation Conference},
year = {2023},
isbn = {9781450397834},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
abstract = {ASP-DAC is a high-quality and premium conference on Electronic Design Automation (EDA) like other sister conferences such as Design Automation Conference (DAC), Design, Automation &amp; Test in Europe (DATE), International Conference on Computer Aided Design (ICCAD), and Embedded SystemsWeek (ESWEEK). ASP-DAC started in 1995 and has continuously offered opportunities to learn about the advancements on LSI design and design automation fields, as well as to communicate with each other for researchers and designers around Asia and South Pacific regions.},
location = {Tokyo, Japan}
}

@proceedings{10.1145/3555228,
title = {SBES '22: Proceedings of the XXXVI Brazilian Symposium on Software Engineering},
year = {2022},
isbn = {9781450397353},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Virtual Event, Brazil}
}

@proceedings{10.1145/3584371,
title = {BCB '23: Proceedings of the 14th ACM International Conference on Bioinformatics, Computational Biology, and Health Informatics},
year = {2023},
isbn = {9798400701269},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
abstract = {ACM-BCB is the flagship conference of the ACM SIGBio, the ACM Special Interest Group in Bioinformatics, Computational Biology, and Biomedical Informatics. Continuing the annual tradition, the conference focuses on interdisciplinary research linking computer science, mathematics, statistics, biology, bioinformatics, biomedical informatics, and health informatics.},
location = {Houston, TX, USA}
}

@proceedings{10.1145/3641555,
title = {SIGCSETS 2025: Proceedings of the 56th ACM Technical Symposium on Computer Science Education V. 2},
year = {2025},
isbn = {9798400705328},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
abstract = {Welcome to the 56th annual SIGCSE Technical Symposium on Computer Science Education (SIGCSE TS 2025)! For the first time since 1978, our symposium is being held in the "Steel City" of Pittsburgh, Pennsylvania, at the intersection of the Allegheny, Ohio, and Monongahela rivers. We are looking forward to four days of productive and informative presentations, vibrant and engaging discussions, and an overall wonderful experience with our SIGCSE community members. We are confident that our program of events provides meaningful and productive experiences for all.Our theme for this year is "Leading the Transformation". Our theme reflects the role of the computer science education community in adapting educational practice to new technologies and challenges. With advances in Artificial Intelligence (AI) transforming both academia and the workplace, the computer science education community has a unique opportunity to help shape the future use and application of computing. Our program this year is quite diverse and offers something for everyone, so please take time to peruse the schedule and choose the sessions which appeal to you. Pittsburgh is also an exciting city with lots to see and do, so you are encouraged to enjoy all the city has to offer.The format of the 2025 Technical Symposium is similar to 2024 in many ways. We will once again have a program that extends into Saturday afternoon, including papers and the Nifty Assignment session after lunch. We will also again have three Birds-of-a-Feather sessions, two on Thursday evening and one during lunch on Friday. For online attendees, we will continue to offer streaming of keynotes, the Nifty Assignment session, the First-Timers Lunch presentation, and a small set of paper, panel, and special sessions.This year we received almost 1200 submissions. Submission statistics for all of the Technical Symposium's tracks can be found in the table that follows. Papers were submitted to one of three tracks (Computing Education Research, Experience Reports and Tools, Position and Curricula Initiatives) with reviewing tailored to each track. Each paper submission was reviewed by at least three reviewers, with a substantial proportion of papers receiving four (or more) reviews, plus a meta review. We sincerely appreciate the work of the more than 800 reviewers and 112 Associate Program Chairs who contributed to the creation of this years' program. Their reviews helped us decide which submissions were accepted while also providing detailed feedback that allowed authors to further improve the final versions of their submissions.},
location = {Pittsburgh, PA, USA}
}

@book{10.1145/3226595,
editor = {Brodie, Michael L.},
title = {Making Databases Work: the Pragmatic Wisdom of Michael Stonebraker},
year = {2018},
isbn = {9781947487192},
publisher = {Association for Computing Machinery and Morgan &amp; Claypool},
volume = {22},
abstract = {At the ACM Awards banquet in June 2017, during the 50th anniversary celebration of the A.M. Turing Award, ACM announced the launch of the ACM A.M. Turing Book Series, a sub-series of ACM Books, to celebrate the winners of the A.M. Turing Award, computing's highest honor, the "Nobel Prize" for computing. This series aims to highlight the accomplishments of awardees, explaining their major contributions of lasting importance in computing."Making Databases Work: The Pragmatic Wisdom of Michael Stonebraker," the first book in the series, celebrates Mike's contributions and impact. What accomplishments warranted computing's highest honor? How did Stonebraker do it? Who is Mike Stonebraker---researcher, professor, CTO, lecturer, innovative product developer, serial entrepreneur, and decades-long leader, and research evangelist for the database community. This book describes Mike's many contributions and evaluates them in light of the Turing Award.The book describes, in 36 chapters, the unique nature, significance, and impact of Mike's achievements in advancing modern database systems over more than 40 years. The stories involve technical concepts, projects, people, prototype systems, failures, lucky accidents, crazy risks, startups, products, venture capital, and lots of applications that drove Mike Stonebraker's achievements and career. Even if you have no interest in databases at all, you'll gain insights into the birth and evolution of Turing Award-worthy achievements from the perspectives of 39 remarkable computer scientists and professionals.Today, data is considered the world's most valuable resource ("The Economist," May 6, 2017), whether it is in the tens of millions of databases used to manage the world's businesses and governments, in the billions of databases in our smartphones and watches, or residing elsewhere, as yet unmanaged, awaiting the elusive next generation of database systems. Every one of the millions or billions of databases includes features that are celebrated by the 2014 A.M. Turing Award and are described in this book.}
}

@proceedings{10.1145/3658644,
title = {CCS '24: Proceedings of the 2024 on ACM SIGSAC Conference on Computer and Communications Security},
year = {2024},
isbn = {9798400706363},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
abstract = {It is with great enthusiasm that we, on behalf of the Organizing Committee, invite you to join us for the 31st ACM SIGSAC Conference on Computer and Communications Security (CCS), a premier security and privacy conference where researchers, practitioners, and educators come together to present, learn, and debate research, innovation, and trends in the field of Computer and Communications Security and Privacy.This year, we are proud to introduce our conference theme to be "Inclusion, Mentorship, Community." These three pillars reflect our collective commitment to fostering a vibrant, supportive, and forwardthinking environment within the CCS community. Particularly, we host our inaugural Doctoral Symposium, which offers PhD students a unique platform to receive timely, constructive feedback on their dissertation research from leading experts in our community. Additionally, our first-ever Diversity, Equity, and Inclusion (DEI) Workshop is designed to cultivate a culture that embraces diversity and champions equity in our field. Moreover, understanding the importance of guidance and support, we have organized panels focusing on Student Mentoring, Faculty Mentoring, and Public Service. These panels are designed to facilitate mentorship connections, share valuable experiences, and encourage service that extends the impact of our work beyond academia. These new initiatives are also opportunities to strengthen the bonds within our CCS community.Regarding the main conference, this year's main conference is our largest ever, featuring 328 paper presentations that showcase the latest research and developments in our field. We are also honored to have two distinguished keynote speakers: Dr. Dan Boneh and Dr. Gene Tsudik, who will share their invaluable insights and perspectives on pressing topics in security and privacy. Additionally, 18 specialized workshops will take place on the pre-conference and post-conference days, providing platforms for focused discussions and collaborations on numerous specialized topics.},
location = {Salt Lake City, UT, USA}
}

@proceedings{10.1145/3555776,
title = {SAC '23: Proceedings of the 38th ACM/SIGAPP Symposium on Applied Computing},
year = {2023},
isbn = {9781450395175},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Tallinn, Estonia}
}

@proceedings{10.1145/3643991,
title = {MSR '24: Proceedings of the 21st International Conference on Mining Software Repositories},
year = {2024},
isbn = {9798400705878},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
abstract = {MSR is a thriving research community that organizes a yearly conference with a solid reputation amongst software engineering researchers.},
location = {Lisbon, Portugal}
}

@proceedings{10.1145/3706594,
title = {CF '25 Companion: Proceedings of the 22nd ACM International Conference on Computing Frontiers: Workshops and Special Sessions},
year = {2025},
isbn = {9798400713934},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
abstract = {This is the companion proceedings of the 22nd ACM International Conference on Computing Frontiers (Volume 2) collecting the papers from co-located workshops and invited papers from special sessions. For papers from the main track, as well as keynote abstract and poster abstracts, see Volume 1.},
location = {
}
}

@proceedings{10.1145/3611643,
title = {ESEC/FSE 2023: Proceedings of the 31st ACM Joint European Software Engineering Conference and Symposium on the Foundations of Software Engineering},
year = {2023},
isbn = {9798400703270},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
abstract = {We are pleased to welcome all delegates to ESEC/FSE 2023, the ACM Joint European Software Engineering Conference and Symposium on the Foundations of Software Engineering. ESEC/FSE is an internationally renowned forum for researchers, practitioners, and educators to present and discuss the most recent innovations, trends, experiences, and challenges in the field of software engineering. ESEC/FSE brings together experts from academia and industry to exchange the latest research results and trends as well as their practical application in all areas of software engineering.},
location = {San Francisco, CA, USA}
}

@proceedings{10.1145/3745034,
title = {IC-BIS '25: Proceedings of the 4th International Conference on Biomedical and Intelligent Systems},
year = {2025},
isbn = {9798400714399},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {
}
}

@proceedings{10.1145/3711896,
title = {KDD '25: Proceedings of the 31st ACM SIGKDD Conference on Knowledge Discovery and Data Mining V.2},
year = {2025},
isbn = {9798400714542},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
abstract = {The 2025 ACM SIGKDD International Conference on Knowledge Discovery and Data Mining will be held in Toronto, Canada from August 3 - 7, 2025. This year's conference continues its tradition of being the premier forum for presentation of research results and experience reports on leading issues in Data Mining as well as in Data Science and Machine Learning. The large attendance of the KDD conference, and the high impact of the KDD publications, give researchers and practitioners a unique opportunity to share novel perspectives.},
location = {Toronto ON, Canada}
}

@proceedings{10.1145/3724154,
title = {BDEIM '24: Proceedings of the 2024 5th International Conference on Big Data Economy and Information Management},
year = {2024},
isbn = {9798400711862},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {
}
}

@proceedings{10.1145/3544902,
title = {ESEM '22: Proceedings of the 16th ACM / IEEE International Symposium on Empirical Software Engineering and Measurement},
year = {2022},
isbn = {9781450394277},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Helsinki, Finland}
}

@article{10.1145/986913.986917,
author = {Sammet, Jean E.},
title = {Roster of programming languages for 1973},
year = {1974},
issue_date = {November 1974},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {9},
number = {11},
issn = {0362-1340},
url = {https://doi.org/10.1145/986913.986917},
doi = {10.1145/986913.986917},
journal = {SIGPLAN Not.},
month = nov,
pages = {18–31},
numpages = {14}
}

@proceedings{10.1145/3600006,
title = {SOSP '23: Proceedings of the 29th Symposium on Operating Systems Principles},
year = {2023},
isbn = {9798400702297},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
abstract = {Welcome to the Proceedings of the 29th ACM Symposium on Operating Systems Principles (SOSP 2023). This year's program includes 43 papers that reflect today's broad range of topics that comprise modern computer systems research. The program committee carefully reviewed submitted papers and worked closely with the authors of selected papers to produce the collection of high-quality, readable papers presented here. We hope that you enjoy the program!},
location = {Koblenz, Germany}
}

@inproceedings{10.1145/1478873.1478890,
author = {Allen, J. R. and Yau, S. S.},
title = {Real-time fault detection for small computers},
year = {1971},
isbn = {9781450379090},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1478873.1478890},
doi = {10.1145/1478873.1478890},
abstract = {Advancing technology and declining costs have led to a sharp increase in the number and variety of small computers in use. Because small computers are readily suited for many real-time applications, a great deal of work has been directed toward simplifying the interface between the computer and its peripherals. Hardware interrupting capability and a specially designed I/O bus are required for peripheral device interfacing in a real-time environment and such things as direct memory access, data channels, and multilevel hardware and software interrupt capability are common. These machines tend to be parallel, synchronous computers with a relatively simple architecture.},
booktitle = {Proceedings of the May 16-18, 1972, Spring Joint Computer Conference},
pages = {119–127},
numpages = {9},
location = {Atlantic City, New Jersey},
series = {AFIPS '72 (Spring)}
}

@proceedings{10.1145/3583133,
title = {GECCO '23 Companion: Proceedings of the Companion Conference on Genetic and Evolutionary Computation},
year = {2023},
isbn = {9798400701207},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
abstract = {GECCO is the largest peer-reviewed conference in the field of Evolutionary Computation, and the main conference of the Special Interest Group on Genetic and Evolutionary Computation (SIGEVO) of the Association for Computing Machinery (ACM).},
location = {Lisbon, Portugal}
}

@proceedings{10.1145/3600160,
title = {ARES '23: Proceedings of the 18th International Conference on Availability, Reliability and Security},
year = {2023},
isbn = {9798400707728},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Benevento, Italy}
}

@article{10.1145/62764.1062251,
author = {Asher, Lisa},
title = {DA STANDARDS ACTIVITIES: Summary: Standard Package Position Papers VHDL Model Standards Group},
year = {1988},
issue_date = {December 1, 1988},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {18},
number = {3–4},
issn = {0163-5743},
url = {https://doi.org/10.1145/62764.1062251},
doi = {10.1145/62764.1062251},
abstract = {The following are abridged versions of position papers being used by the IEEE/DASS in developing the IEEE VHDL standard. These were supplied by Jim Armstrong who is Chairman of the VHDL Model Subgroup. Complete versions of the papers and minutes of the IEEE VHDL Subgroup are archived at the IEEE Computer Society. For further information call Rick Cain at 202-371-0101. I believe that sometime in the fall of 89 Design and Test will publish a special issue on the VHDL standard based on the final resolutions of the DASS. Special thanks to J. W. Smith for help in obtaining this material.},
journal = {SIGDA Newsl.},
month = dec,
pages = {31},
numpages = {54}
}

@proceedings{10.1145/3627106,
title = {ACSAC '23: Proceedings of the 39th Annual Computer Security Applications Conference},
year = {2023},
isbn = {9798400708862},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Austin, TX, USA}
}

@proceedings{10.1145/3638529,
title = {GECCO '24: Proceedings of the Genetic and Evolutionary Computation Conference},
year = {2024},
isbn = {9798400704949},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
abstract = {GECCO is the largest peer-reviewed conference in the field of Evolutionary Computation, and the main conference of the Special Interest Group on Genetic and Evolutionary Computation (SIGEVO) of the Association for Computing Machinery (ACM).},
location = {Melbourne, VIC, Australia}
}

@proceedings{10.1145/3675888,
title = {IC3-2024: Proceedings of the 2024 Sixteenth International Conference on Contemporary Computing},
year = {2024},
isbn = {9798400709722},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Noida, India}
}

@proceedings{10.1145/3745133,
title = {DEIS '25: Proceedings of the 2025 International Conference on Digital Economy and Information Systems},
year = {2025},
isbn = {9798400714375},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {
}
}

@proceedings{10.1145/3659914,
title = {PASC '24: Proceedings of the Platform for Advanced Scientific Computing Conference},
year = {2024},
isbn = {9798400706394},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
abstract = {The PASC Conference series is an international and interdisciplinary platform for the exchange of knowledge in scientific computing and computational science with a strong focus on methods, tools, algorithms, workflows, application challenges, and novel techniques in the context of scientific usage of high-performance computing.},
location = {Zurich, Switzerland}
}

@proceedings{10.1145/3508352,
title = {ICCAD '22: Proceedings of the 41st IEEE/ACM International Conference on Computer-Aided Design},
year = {2022},
isbn = {9781450392174},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
abstract = {Jointly sponsored by ACM and IEEE, ICCAD is the premier forum to explore new challenges, present leading-edge innovative solutions, and identify emerging technologies in the Electronic Design Automation (EDA) research areas. ICCAD covers the full range of Computer-Aided Design (CAD) topics - from device and circuit-level up through system-level, as well as post-CMOS design.},
location = {San Diego, California}
}

@proceedings{10.1145/2517349,
title = {SOSP '13: Proceedings of the Twenty-Fourth ACM Symposium on Operating Systems Principles},
year = {2013},
isbn = {9781450323888},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
abstract = {Welcome to the Proceedings of the 24th ACM Symposium on Operating Systems Principles (SOSP 2013), held at the Nemacolin Woodlands Resort, Farmington, Pennsylvania, USA. This year's program includes 30 papers, and touches on a wide range of computer systems topics, from kernels to big data, from responsiveness to correctness, and from devices to data centers. The program committee made every effort to identify and include some of the most creative and thought-provoking ideas in computer systems today. Each accepted paper was shepherded by a program committee member to make sure the papers are as readable and complete as possible. We hope you will enjoy the program as much as we did in selecting it.},
location = {Farminton, Pennsylvania}
}

@proceedings{10.1145/3604237,
title = {ICAIF '23: Proceedings of the Fourth ACM International Conference on AI in Finance},
year = {2023},
isbn = {9798400702402},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Brooklyn, NY, USA}
}

@proceedings{10.1145/3411764,
title = {CHI '21: Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
year = {2021},
isbn = {9781450380966},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Yokohama, Japan}
}

@proceedings{10.1145/3610661,
title = {ICMI '23 Companion: Companion Publication of the 25th International Conference on Multimodal Interaction},
year = {2023},
isbn = {9798400703218},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Paris, France}
}

@proceedings{10.1145/3708036,
title = {ICCSMT '24: Proceedings of the 2024 5th International Conference on Computer Science and Management Technology},
year = {2024},
isbn = {9798400709999},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {
}
}

@proceedings{10.1145/3696500,
title = {ICBDDM '24: Proceedings of the 2024 International Conference on Big Data and Digital Management},
year = {2024},
isbn = {9798400710278},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Shanghai, China}
}

@proceedings{10.1145/3583131,
title = {GECCO '23: Proceedings of the Genetic and Evolutionary Computation Conference},
year = {2023},
isbn = {9798400701191},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
abstract = {GECCO is the largest peer-reviewed conference in the field of Evolutionary Computation, and the main conference of the Special Interest Group on Genetic and Evolutionary Computation (SIGEVO) of the Association for Computing Machinery (ACM).},
location = {Lisbon, Portugal}
}

@proceedings{10.1145/3636555,
title = {LAK '24: Proceedings of the 14th Learning Analytics and Knowledge Conference},
year = {2024},
isbn = {9798400716188},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Kyoto, Japan}
}

@proceedings{10.5555/3709347,
title = {AAMAS '25: Proceedings of the 24th International Conference on Autonomous Agents and Multiagent Systems},
year = {2025},
isbn = {9798400714269},
publisher = {International Foundation for Autonomous Agents and Multiagent Systems},
address = {Richland, SC},
abstract = {Welcome to AAMAS-2025, the 24th edition of the International Conference on Autonomous Agents and Multiagent Systems!AAMAS is the largest and most influential conference in the area of agents and multiagent systems, bringing together researchers and practitioners in all areas of agent technology and providing an internationally renowned high-profile forum for publishing and learning about the latest developments in the field. AAMAS is the flagship conference of the non-profit International Foundation for Autonomous Agents and Multiagent Systems (IFAAMAS).We are happy that the 2025 edition of AAMAS will be coming to Detroit, MI. Previous editions were held in Bologna (2002), Melbourne (2003), New York (2004), Utrecht (2005), Hakodate (2006), Honolulu (2007), Estoril (2008), Budapest (2009), Toronto (2010), Taipei (2011), Valencia (2012), Saint Paul (2013), Paris (2014), Istanbul (2015), Singapore (2016), S\~{a}o Paulo (2017), Stockholm (2018), Montr\'{e}al (2019), Auckland/online (2020), London/online (2021), Auckland/online (2022), London (2023), and Auckland (2024).The main track of the conference includes peer-reviewed technical papers describing significant and original research on all aspects of the theory and practice of autonomous agents and multiagent systems, divided into the following areas of interest:Learning and Adaptation (LEARN)Game Theory and Economic Paradigms (GTEP)Coordination, Organizations, Institutions, Norms, and Ethics (COINE)Search, Optimization, Planning, and Scheduling (SOPS)Representation, Perception, and Reasoning (RPR)Engineering and Analysis of Multiagent Systems (EMAS)Modeling and Simulation of Societies (SIM)Human-Agent Interaction (HAI)Robotics and Control (ROBOT)Innovative Applications (IA)As in previous years, we worked with a three-tier program committee, consisting of 29 area chairs, 147 senior program committee members, and over 600 regular program committee members. Their work was supported by a substantial number of auxiliary reviewers. When composing the committee, we followed the tradition of AAMAS of not having anyone serve in a senior programme committee or area chair role for more than two years in a row, and we were pleased to see that many senior colleagues accepted our invitation to serve as regular programme committee members.For the main track, we received a total of 1361 abstract submissions. Some didn't materialize while a number of others were desk-rejected (mostly due to anonymity violations and similar infringements of the rules laid down in the Call for Papers). The program committee then reviewed the remaining 1021 submissions. Almost all submissions received at least three reviews, as well as a meta-review summarizing the assessment of the program committee. Authors had the opportunity to respond to initial versions of their reviews during a rebuttal phase, and the rebuttal phase additional gave the authors and reviewers an opportunity to engage in further discussion.},
location = {Detroit, MI, USA}
}

@proceedings{10.1145/3613904,
title = {CHI '24: Proceedings of the 2024 CHI Conference on Human Factors in Computing Systems},
year = {2024},
isbn = {9798400703300},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Honolulu, HI, USA}
}

@proceedings{10.1145/3745238,
title = {DEAI '25: Proceedings of the 2nd Guangdong-Hong Kong-Macao Greater Bay Area International Conference on Digital Economy and Artificial Intelligence},
year = {2025},
isbn = {9798400712791},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {
}
}

@proceedings{10.1145/3664647,
title = {MM '24: Proceedings of the 32nd ACM International Conference on Multimedia},
year = {2024},
isbn = {9798400706868},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
abstract = {We are delighted to welcome you to Melbourne, Australia for ACM Multimedia 2024, the 32nd ACM International Conference on Multimedia. ACM Multimedia is the premier international conference series in the area of multimedia within the field of computer science. Since 1993, ACM Multimedia has been bringing together worldwide researchers and practitioners from academia and industry to present their innovative research and to discuss recent advancements in multimedia.For the first time since the end of the COVID-19 pandemic, this year's conference returns to the Asia-Pacific region and resumes as a full-fledged, inperson event. With no travel restrictions or significant visa challenges, we are excited to once again experience the warmth of face-to-face gatherings, where we can reconnect with colleagues and friends.The enthusiasm and support from the community have been incredible. ACM Multimedia 2024 received over 4,300 main conference submissions, accepting more than 1,100 papers (please refer to the TPC Chairs' message for details). In addition, 10 Grand Challenges were selected from 22 submissions, 18 workshops from 30 submissions, and 8 tutorials from 13 proposals. We've prepared an exciting five-day program: workshops, grand challenges, and tutorials will be held on the 1st and 5th days, with the main conference occupying the middle three days. All accepted papers will be accessible online prior to the conference, and we are working to ensure proceedings are available through the ACM Digital Library around the conference period.This year's conference features three distinguished academic keynote speeches, several prestigious SIGMM award talks, a panel discussion on Generative AI in Multimedia, a refreshed Brave New Idea (BNI) session, and our inaugural industry program.The opening keynote will be delivered by Prof. Pascale Fung from HKUST, a Fellow of AAAI, ACL, and IEEE. Her talk will explore the pressing topic of Agents in the Large Language Model (LLM) Era. Prof. Judy Kay from the University of Sydney, a renowned expert in HCI, user modeling, and ubiquitous computing, will give the second keynote on how to empower individuals to harness and control their multimodal data. The final academic keynote will be presented by Prof. Jiebo Luo from the University of Rochester, a Fellow of ACM, AAAI, IEEE, SPIE, and IAPR, as well as a member of Academia Europaea and the US National Academy of Inventors. He will discuss leveraging LLMs as social multimedia analysis engines.This year, we continue using OpenReview to ensure an open and transparent review process. Thanks to the exceptional efforts of the technical program committee, every paper received at least three reviews before the review announcement. The BNI track has also revamped its review process to align with the main conference, promoting visionary papers. Additionally, we are excited to introduce the industry program to ACM Multimedia for the first time, featuring industry keynote speeches, expert talks, and demonstrations (please refer to the industry chairs' message for further details).We are also committed to making the conference inclusive and accessible. To support students with financial constraints, we have awarded travel grants to at least 25 students from the ACM Multimedia 2024 budget, with an additional 20+ students receiving SIGMM travel grants. Over 20 local students have also been recruited as volunteers, benefiting from complimentary registration. Furthermore, we have arranged childcare facilities to accommodate attendees with young children. A welcome reception will take place on the 2nd day of the conference, followed by a gala dinner on the 3rd day, featuring exciting cultural performances.We hope you find this year's program engaging and thought-provoking and that it offers valuable opportunities to exchange ideas with fellow researchers and practitioners from around the globe. We also encourage you to take time to explore the beautiful city of Melbourne and its surrounding regions.},
location = {Melbourne VIC, Australia}
}

@proceedings{10.1145/3544548,
title = {CHI '23: Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Hamburg, Germany}
}

