Scopus
EXPORT DATE: 17 August 2025

@CONFERENCE{2016,
	title = {ACM International Conference Proceeding Series},
	year = {2016},
	journal = {ACM International Conference Proceeding Series},
	volume = {Part F128404},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85046053536&partnerID=40&md5=0474c10feb1b62d0561df8aa88aa843f},
	abstract = {The proceedings contain 18 papers. The topics discussed include: deeply reifying running code for constructing a domain-specific language; a distributed selectors runtime system for Java applications; efficient memory traces with full pointer information; extraction-based regression test selection; inference and checking of object immutability; integrating asynchronous task parallelism and data-centric atomicity; JCrypt: towards computation over encrypted data; multi-tier data synchronization based on an optimized concurrent linked-list; preexistence and concrete type analysis in the context of multiple inheritance; and prioritizing regression tests for desktop and web-applications based on the execution frequency of modified code.},
	type = {Conference review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Hallenberg201296,
	author = {Hallenberg, Niels and Carlsen, Philip Lykke},
	title = {Declarative automated test},
	year = {2012},
	journal = {2012 7th International Workshop on Automation of Software Test, AST 2012 - Proceedings},
	pages = {96 – 102},
	doi = {10.1109/IWAST.2012.6228998},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84864262119&doi=10.1109%2fIWAST.2012.6228998&partnerID=40&md5=670bdf6333dc0c334ffece1b49a7898c},
	abstract = {Automated tests at the business level can be expensive to develop and maintain. One common approach is to have a domain expert instruct a QA developer to implement what she would do manually in the application. Though there exist record-replay tools specifically developed for this, these tend to scale poorly for more complicated test scenarios. We present a different solution: An Embedded Domain Specific Language (EDSL) in F#, containing the means to model the user interface, and the various manipulations of it. We hope that this DSL will bridge the gap between the business domain and technical domain of applications to such a degree that domain experts may be able to construct automatic tests without depending on QA developers, and that these tests will prove more maintainable. © 2012 IEEE.},
	author_keywords = {Automated Testing; Domain Specific Language; F#; Functional Testing},
	keywords = {Automation; User interfaces; Automated testing; Business domain; Domain experts; Domain specific languages; Embedded domain specific languages; Functional testing; Software testing},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 2}
}

@ARTICLE{Hunecke2025200,
	author = {Hunecke, Bastian and Nguyen, Minh and Hochgeschwender, Nico and Wrede, Sebastian},
	title = {Specification and Execution of Robotic Acceptance Tests for Object Sorting},
	year = {2025},
	journal = {Springer Proceedings in Advanced Robotics},
	volume = {36 SPAR},
	pages = {200 – 205},
	doi = {10.1007/978-3-031-89471-8_31},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-105006528351&doi=10.1007%2f978-3-031-89471-8_31&partnerID=40&md5=813d2168ae1ff633d8aa686e198d79b2},
	abstract = {Ensuring reliable performance in tasks with high variability is an increasingly important task in the engineering process of robotics applications. This paper introduces an extended toolchain leveraging Behaviour-Driven Development to specify acceptance criteria and high-quality simulations to execute acceptance tests. We demonstrate the effectiveness of the testing approach in a dynamic sorting task with objects picked from a moving conveyor using a Franka Panda robot system. The contributions include an extended domain-specific language for specifying acceptance criteria and an implementation for automated testing of sorting scenarios using NVIDIA IsaacSim. We conclude with a discussion on the current state and future work on acceptance testing for robotics. © The Author(s), under exclusive license to Springer Nature Switzerland AG 2025.},
	author_keywords = {Acceptance testing; Robot manipulation; Robot system and software engineering},
	keywords = {Application programs; Automatic test pattern generation; Computer operating systems; Industrial robots; Intelligent robots; Robotic assembly; Software design; Software packages; Software testing; Acceptance criteria; Acceptance testing; Engineering process; Object sorting; Reliable performance; Robot manipulation; Robot system and software engineering; Robotics applications; Robots system; Systems and software; Acceptance tests},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Felderer2018,
	author = {Felderer, Michael and Jeschko, Fabian},
	title = {A process for evidence-based engineering of domain-specific languages},
	year = {2018},
	journal = {ACM International Conference Proceeding Series},
	volume = {Part F137700},
	doi = {10.1145/3210459.3210479},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85053713372&doi=10.1145%2f3210459.3210479&partnerID=40&md5=fd309de170e0c9f0c6d37fca46d29ed0},
	abstract = {Domain-specific languages (DSLs) are mainly designed ad-hoc and gut feeling resulting in languages that are often not well suited for their users and engineers. In this paper we develop a process for evidence-based language engineering to design domain-specific languages based on empirical evidence to support decision in language engineering. The developed process comprises an iterative execution of the phases DSL engineering, issue identification, data collection and evidence appraisal. We exemplify the concept by designing a DSL for Gherkin, a language test-driven acceptance testing in Xtext. The required evidence is derived by mining and analyzing all GitHub projects until July 1, 2017 that apply Gherkin. © 2018 Association for Computing Machinery.},
	author_keywords = {Domain-specific languages; DSL engineering; Empirical research; Evidence-based software engineering; Repository mining},
	keywords = {Acceptance tests; Digital subscriber lines; Problem oriented languages; Acceptance testing; Domain specific languages; Empirical research; Evidence Based Software Engineering; Issue identifications; Iterative executions; Language engineering; Repository mining; Software engineering},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 3}
}

@CONFERENCE{Cao2022819,
	author = {Cao, Jiamin and Zhou, Yu and Sun, Chen and He, Lin and Xi, Zhaowei and Liu, Ying},
	title = {Firebolt: Finding Bugs in Programmable Data Plane Generators},
	year = {2022},
	journal = {Proceedings of the 2022 USENIX Annual Technical Conference, ATC 2022},
	pages = {819 – 834},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85140980496&partnerID=40&md5=0e1a142e9ab3dc6dd15d8983826b6f76},
	abstract = {Programmable data planes (DP) enable flexible customization of packet processing logic with domain-specific languages such as P4. To relieve developers from lengthy codes and tedious hardware details, many researches propose DP program generators that take high-level intents as input and automatically convert intents into DP programs. Generators must be correct, otherwise they may produce buggy programs or DP logic that is inconsistent with intents. Nevertheless, existing verification tools are designed to verify individual DP programs, not generators. They either cannot achieve high bug coverage or cannot debug generators with high scalability. This paper presents Firebolt, a blackbox testing tool designed to dig out faults in DP program generators, including security vulnerabilities, intent violations, and generator crash. Firebolt achieves high bug coverage by using syntax-guided intent generation to construct a comprehensive, syntactically correct, and semantically valid intent set. To avoid intent explosion, Firebolt designs an intent space pruning approach that eliminates redundant intents while preserving representative ones. For high scalability, Firebolt automatically formalizes DP programs and intents for verification. We apply Firebolt to three popular open-source DP generators. Evaluation results demonstrate that Firebolt can detect 2× bugs with 0.1% to 0.01% human efforts compared to existing tools. © 2022 USENIX Annual Technical Conference, ATC 2022.All rights reserved.},
	keywords = {Black-box testing; Computer circuits; Problem oriented languages; Program debugging; Black boxes; Data planes; Data-plane; Domains specific languages; Flexible customization; High scalabilities; Packet processing; Security vulnerabilities; Testing tools; Verification tools; Scalability},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1}
}

@CONFERENCE{Anderson2022266,
	author = {Anderson, Jacob and Hekmatnejad, Mohammad and Fainekos, Georgios},
	title = {PyFoReL: A Domain-Specific Language for Formal Requirements in Temporal Logic},
	year = {2022},
	journal = {Proceedings of the IEEE International Conference on Requirements Engineering},
	volume = {2022-August},
	pages = {266 – 267},
	doi = {10.1109/RE54965.2022.00037},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85133885496&doi=10.1109%2fRE54965.2022.00037&partnerID=40&md5=2ed4dd0e4e02455d8e8704e4cba5915a},
	abstract = {Temporal Logic (TL) bridges the gap between natural language and formal reasoning in the field of complex systems verification. However, in order to leverage the expressivity entailed by TL, the syntax and semantics must first be understood - a large task in itself. This significant knowledge gap leads to several issues: (1) the likelihood of adopting a TL-based verification method is decreased, and (2) the chance of poorly written and inaccurate requirements is increased. In this ongoing work, we present the Pythonic Formal Requirements Language (PyFoReL) tool: a Domain-Specific Language inspired by the programming language Python to simplify the elicitation of TL-based requirements for engineers and non-experts.  © 2022 IEEE.},
	author_keywords = {domain-specific language; formal requirements; requirements-based testing; temporal logic},
	keywords = {Computer circuits; Problem oriented languages; Semantics; Domains specific languages; Formal reasoning; Formal requirement; Knowledge gaps; Language tools; Natural languages; Requirement languages; Requirement-based testing; System verifications; Verification method; Temporal logic},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 2}
}

@CONFERENCE{King2014409,
	author = {King, Tariq M. and Nunez, Gabriel and Santiago, Dionny and Cando, Adam and Mack, Cody},
	title = {Legend: An agile DSL toolset for web acceptance testing},
	year = {2014},
	journal = {2014 International Symposium on Software Testing and Analysis, ISSTA 2014 - Proceedings},
	pages = {409 – 412},
	doi = {10.1145/2610384.2628048},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84942796278&doi=10.1145%2f2610384.2628048&partnerID=40&md5=e1b8e6f6bcaf8bf9f6d7650b26038563},
	abstract = {Agile development emphasizes collaborations among customers, business analysts, domain experts, developers, and testers. However, the large scale and rapid pace of many agile projects presents challenges during testing activities. Large sets of test artifacts must be comprehensible and available to various stakeholders, traceable to requirements, and easily maintainable as the software evolves. In this paper we describe Legend, a toolset that leverages domain-specific language to streamline functional testing in agile projects. Some key features of the toolset include test template generation from user stories, model-based automation, test inventory synchronization, and centralized test tagging. Copyright 2014 ACM.},
	author_keywords = {Agile development; Behavior-driven development; Domain-specific languages; Software testing; Test automation},
	keywords = {Digital subscriber lines; Problem oriented languages; Software testing; Acceptance testing; Agile development; Behavior-driven development; Business analysts; Domain specific languages; Functional testing; Model-based OPC; Test Automation; Acceptance tests},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 6}
}

@CONFERENCE{Grandy20092720,
	author = {Grandy, Holger and Benz, Sebastian},
	title = {Specification based testing of automotive human machine interfaces},
	year = {2009},
	journal = {INFORMATIK 2009 - Im Focus das Leben, Beitrage der 39. Jahrestagung der Gesellschaft fur Informatik e.V. (GI)},
	pages = {2720 – 2727},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-80052163718&partnerID=40&md5=245cf5ec35319deeaaa2b16c5d104d47},
	abstract = {Model based testing promises systematic test coverage in a continuous testing process. However, in practice, model based testing struggles with informal specifications, different software variants and large applications. In this paper, we present a solution to overcome these hurdles in the area of automotive infotainment systems using domain specific languages in combination with model transformations. Our approach is to define specific languages on different abstraction levels. We start with a variant-spanning user interface specification that is structured and formal, but not yet sufficient for automated testing. We use model transformation to stepwise enrich and refine these models into more specific test models. The approach has been developed at BMW Car IT and is currently used in the development of new infotainment systems.},
	keywords = {Application programs; Mathematical models; User interfaces; Abstraction level; Automated testing; Automotive infotainment; Continuous testing; Domain specific languages; Human Machine Interface; Infotainment systems; Interface specification; Model based testing; Model transformation; Software variants; Specific languages; Specification Based Testing; Systematic test; Test models; Use-model; Specifications},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 8}
}

@ARTICLE{Zampetti2020,
	author = {Zampetti, Fiorella and Di Sorbo, Andrea and Visaggio, Corrado Aaron and Canfora, Gerardo and Di Penta, Massimiliano},
	title = {Demystifying the adoption of behavior-driven development in open source projects},
	year = {2020},
	journal = {Information and Software Technology},
	volume = {123},
	doi = {10.1016/j.infsof.2020.106311},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85082699535&doi=10.1016%2fj.infsof.2020.106311&partnerID=40&md5=41d86560dabcd366109c4f5faad46bde},
	abstract = {Context:Behavior-Driven Development (BDD) features the capability, through appropriate domain-specific languages, of specifying acceptance test cases and making them executable. The availability of frameworks such as Cucumber or RSpec makes the application of BDD possible in practice. However, it is unclear to what extent developers use such frameworks, and whether they use them for actually performing BDD, or, instead, for other purposes such as unit testing. Objective:In this paper, we conduct an empirical investigation about the use of BDD tools in open source, and how, when a BDD tool is in place, BDD specifications co-evolve with source code. Method:Our investigation includes three different phases: (i) a large-scale analysis to understand the extent to which BDD frameworks are used in 50,000 popular open-source projects written in five programming languages; (ii) a study on the co-evolution of scenarios, fixtures and production code in a sample of 20 Ruby projects, through the Granger's causality test, and (iii) a survey with 31 developers to understand how they use BDD frameworks. Results:Results of the study indicate that ≃ 27% of the sampled projects use BDD frameworks, with a prevalence in Ruby projects (68%). In about 37% of the cases, we found a co-evolution between scenarios/fixtures and production code. Specifically, changes to scenarios and fixtures often happen together or after changes to source code. Moreover, survey respondents indicate that, while they understand the intended purpose of BDD frameworks, most of them write tests while/after coding rather than strictly applying BDD. Conclusions:Even if the BDD frameworks usage is widespread among open source projects, in many cases they are used for different purposes such as unit testing activities. This mainly happens because developers felt BDD remains quite effort-prone, and its application goes beyond the simple adoption of a BDD framework. © 2020 Elsevier B.V.},
	author_keywords = {Acceptance testing; Behavior-driven development; Co-evolution; Empirical study},
	keywords = {Boolean functions; Fixtures (tooling); Open source software; Open systems; Problem oriented languages; Ruby; Surveys; Acceptance testing; Behavior-driven development; Co-evolution; Domain specific languages; Empirical investigation; Empirical studies; Large-scale analysis; Open source projects; Acceptance tests},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 13}
}

@CONFERENCE{Laue201789,
	author = {Laue, Ralf and Storch, Arian and Schnädelbach, Markus},
	title = {Regression testing for visual models},
	year = {2017},
	journal = {CEUR Workshop Proceedings},
	volume = {1848},
	pages = {89 – 95},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85020554157&partnerID=40&md5=249749690bff7d9250f95ea548ab19f6},
	abstract = {In this paper, we present a set of Eclipse plug-ins which adapts the idea of regression testing for the area of visual modelling in software engineering: Expected properties of models in languages such as UML, BPMN, etc. are stored together with the model (comparable with test cases added to software). With each change of the model, these properties can be checked. The solution should work with any visual modelling language included into Eclipse - both for standardised as for domain-specific languages. The advantage of our approach over current existing solutions is that the process of model checking is completely hidden to the modeller. In particular, it is not necessary for the modeller to learn a formalism for specifying expected properties. Copyright 2017 for this paper by its authors.},
	keywords = {Computer programming languages; Information systems; Modeling languages; Problem oriented languages; Software engineering; Software testing; Systems engineering; Visual languages; Domain specific languages; Eclipse plug-ins; Over current; Regression testing; Test case; Visual model; Visual modelling; Model checking},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Martinez201413,
	author = {Martinez, Jorge and Thomas, Troy and King, Tariq M.},
	title = {Echo: A middleware architecture for domain-specific UI test automation},
	year = {2014},
	journal = {2014 Workshop on Joining AcadeMiA and Industry Contributions to Test Automation and Model-Based Testing, JAMAICA 2014 - Proceedings},
	pages = {13 – 15},
	doi = {10.1145/2631890.2631893},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84942409801&doi=10.1145%2f2631890.2631893&partnerID=40&md5=580120dfa5f66ea5514ea211d228169b},
	abstract = {Model-driven engineering (MDE) continues to raise the level of abstraction used in software development. Software testing researchers and practitioners have been adopting MDE principles, and applying them to software testing activities. Examples include the use of domain-specific languages for functional testing and test automation. In this paper we present the design of a layered middleware architecture to support domain-specific, functional UI test automation. Building on experiences gained implementing a Selenium- based framework for a large-scale agile project, we present design ideas that raise the abstraction level in UI test automation frameworks. Design considerations are discussed to provoke thoughts and ideas on automation frameworks. Copyright 2014 ACM.},
	author_keywords = {Domain-specific languages; Middleware; Software architecture; Software testing; Test automation; User interfaces},
	keywords = {Abstracting; Automation; Joining; Middleware; Model checking; Problem oriented languages; Software architecture; Software design; Testing; User interfaces; Design considerations; Domain specific languages; Functional testing; Level of abstraction; Middleware architecture; Model-driven Engineering; Test Automation; Test automation frameworks; Software testing},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 2}
}

@ARTICLE{Luna Robles2011297,
	author = {Luna Robles, Esteban and Rossi, Gustavo and Garrigós, Irene},
	title = {WebSpec: A visual language for specifying interaction and navigation requirements in web applications},
	year = {2011},
	journal = {Requirements Engineering},
	volume = {16},
	number = {4},
	pages = {297 – 321},
	doi = {10.1007/s00766-011-0124-1},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-80355133393&doi=10.1007%2fs00766-011-0124-1&partnerID=40&md5=f1f0f0c473c59f609af650d777b886c7},
	abstract = {Web application development is a complex and time-consuming process that involves different stakeholders (ranging from customers to developers); these applications have some unique characteristics like navigational access to information, sophisticated interaction features, etc. However, there have been few proposals to represent those requirements that are specific to Web applications. Consequently, validation of requirements (e. g., in acceptance tests) is usually informal and as a result troublesome. To overcome these problems, we present WebSpec, a domain-specific language for specifying the most relevant and characteristic requirements of Web applications: those involving interaction and navigation. We describe WebSpec diagrams, discussing their abstraction and expressive power. With a simple though realistic example, we show how we have used WebSpec in the context of an agile Web development approach discussing several issues such as automatic test generation, management of changes in requirements, and improving the understanding of the diagrams through application simulation. © 2011 Springer-Verlag London Limited.},
	author_keywords = {Code generation; Interaction; Simulation; Testing; Web requirements},
	keywords = {Navigation; Problem oriented languages; World Wide Web; Acceptance tests; Application simulation; Automatic test generation; Code Generation; Domain specific languages; Expressive power; Interaction; Interaction features; Management of change; Simulation; Time-consuming process; Visual language; WEB application; Web application development; Web development; Web requirements; User interfaces},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 22; All Open Access, Green Open Access}
}

@CONFERENCE{2017,
	title = {Proceedings - Asia-Pacific Software Engineering Conference, APSEC},
	year = {2017},
	journal = {Proceedings - Asia-Pacific Software Engineering Conference, APSEC},
	volume = {2017-December},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85172577489&partnerID=40&md5=5e7c983082528eeffeac50a9234bafe5},
	abstract = {The proceedings contain 93 papers. The topics discussed include: extracting traceability between predicates in event-B refinement; an improved approach to traceability recovery based on word embeddings; application of LSSVM and SMOTE on seven open source projects for predicting refactoring at class level; detecting full initialization points of objects to support code refactorings; a cloud-based trust evaluation scheme using a vehicular social network environment; Noff: a novel extendible parallel library for high-performance network traffic monitoring; a reusable framework for modeling and verifying in-vehicle networking systems in the presence of CAN and FlexRay; cost-effective regression testing using bloom filters in continuous integration development environments; correlation between the frequent use of gang-of-four design patterns and structural complexity; method level text summarization for java code using nano-patterns; flexible components for development of embedded systems with GPUs; Exniffer: learning to prioritize crashes by assessing the exploitability from memory dump; modeling and verifying identity authentication security of HDFS using CSP; a goal-driven framework in support of knowledge management; extracting insights from the topology of the JavaScript package ecosystem; improving bug localization with an enhanced convolutional neural network; mining handover process in open source development: an exploratory study; an analysis method of safety requirements for automotive software systems; and domain-specific language facilitates scheduling in model checking.},
	type = {Conference review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Boussaa2016202,
	author = {Boussaa, Mohamed and Barais, Olivier and Baudry, Benoit and Sunýe, Gerson},
	title = {Automatic non-functional testing of code generators families},
	year = {2016},
	journal = {GPCE 2016 - Proceedings of the 2016 ACM SIGPLAN International Conference on Generative Programming: Concepts and Experiences, co-located with SPLASH 2016},
	pages = {202 – 212},
	doi = {10.1145/2993236.2993256},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85006821065&doi=10.1145%2f2993236.2993256&partnerID=40&md5=23033cd767ef631f2e6581469ad5fe2e},
	abstract = {The intensive use of generative programming techniques provides an elegant engineering solution to deal with the heterogeneity of platforms and technological stacks. The use of domain-specific languages for example, leads to the creation of numerous code generators that automatically translate high-level system specifications into multi-Target executable code. Producing correct and efficient code generator is complex and error-prone. Although software designers provide generally high-level test suites to verify the functional outcome of generated code, it remains challenging and tedious to verify the behavior of produced code in terms of non-functional properties. This paper describes a practical approach based on a runtime monitoring infrastructure to automatically check the potential inefficient code generators. This infrastructure, based on system containers as execution platforms, allows code-generator developers to evaluate the generated code performance. We evaluate our approach by analyzing the performance of Haxe, a popular high-level programming language that involves a set of cross-platform code generators. Experimental results show that our approach is able to detect some performance inconsistencies that reveal real issues in Haxe code generators. ©2016 ACM.},
	author_keywords = {Code generator; Code quality; Non-functional properties; Testing},
	keywords = {Automatic programming; Computer programming languages; High level languages; Problem oriented languages; Software testing; Specifications; Testing; Code generators; Code quality; Domain specific languages; Engineering solutions; Execution platforms; Generative programming; High-level programming language; Non functional properties; Codes (symbols)},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 4; All Open Access, Green Open Access}
}

@ARTICLE{Makki2016178,
	author = {Makki, Majid and Van Landuyt, Dimitri and Joosen, Wouter},
	title = {Automated regression testing of BPMN 2.0 processes: A capture and replay framework for continuous delivery},
	year = {2016},
	journal = {ACM SIGPLAN Notices},
	volume = {52},
	number = {3},
	pages = {178 – 189},
	doi = {10.1145/2993236.2993257},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85084190357&doi=10.1145%2f2993236.2993257&partnerID=40&md5=bb4b3a3747c8e1d73b17801cc82923c9},
	abstract = {Regression testing is a form of software quality assurance (QA) that involves comparing the behavior of a newer version of a software artifact to its earlier correct behavior, and signaling the QA engineer when deviations are detected. Given the large potential in automated generation and execution of regression test cases for business process models in the context of running systems, powerful tools are required to make this practically feasible, more specifically to limit the potential impact on production systems, and to reduce the manual effort required from QA engineers. In this paper, we present a regression testing automation framework that implements the capture & replay paradigm in the context of BPMN 2.0, a domain-specific language for modeling and executing business processes. The framework employs parallelization techniques and efficient communication patterns to reduce the performance overhead of capturing. Based on inputs from the QA engineer, it manipulates the BPMN2 model before executing tests for isolating the latter from external dependencies (e.g. human actors or expensive web services) and for avoiding undesired side-effects. Finally, it performs a regression detection algorithm and reports the results to the QA engineer. We have implemented our framework on top of a BPMN2-compliant execution engine, namely jBPM, and performed functional validations and evaluations of its performance and fault-tolerance. The results, indicating 3.9% average capturing performance overhead, demonstrate that the implemented framework can be the foundation of a practical regression testing tool for BPMN 2.0, and a key enabler for continuous delivery of business process-driven applications and services. © 2016 ACM.},
	author_keywords = {BPMN 2.0; Business Process Execution; jBPM; Node Mocking; Performance Overhead; Regression Testing; Test Automation},
	keywords = {Automation; Computer software selection and evaluation; Engineers; Fault tolerance; Modeling languages; Problem oriented languages; Regression analysis; Software quality; Web services; Automated generation; Automated regression testing; Business process model; Detection algorithm; Domain specific languages; Efficient communications; Functional validation; Parallelization techniques; Software testing},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 3}
}

@ARTICLE{200844,
	title = {Trends in ISDN and DSL testers},
	year = {2008},
	journal = {EngineerIT},
	number = {APR.},
	pages = {44 – 46},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-43649107144&partnerID=40&md5=7414ec116271704223f4909561eb6655},
	abstract = {Germany is facing a massive change in the telecommunication interfaces that shows the planned unbundling of the broadband Internet accesses from the traditional telephone access will place even greater demands on the test equipment. Service technician needed a tester that could not only be used to run acceptance tests on ISDN but could also be used to replace a NTBA, splitter or modem. High-quality testers were also able to replace the customer's PC as well as to set up a point-to-point protocol (PPP) connection to analyze the quality of the Internet connection using upload and download tests. One of the Intec Argus ISDN and DSL handheld testers can serve as the remote end on the customer's subscriber access and exchange the standard voice readings. The Argus testers from Intec are positive proof that the currently diverse requirements connected with ISDN/DSL testing can be handled using a compact, battery-operated tester.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{2018,
	title = {10th International Conference on Software Quality Days, SWQD 2018},
	year = {2018},
	journal = {Lecture Notes in Business Information Processing},
	volume = {302},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85041098255&partnerID=40&md5=f83031c69cbcbb2f18637ce4e0cac983},
	abstract = {The proceedings contain 10 papers. The special focus in this conference is on Software Quality Days. The topics include: On evidence-based risk management in requirements engineering; requirement-based testing - Extracting logical test cases from requirement documents; expert sourcing to support the identification of model elements in system descriptions; are your requirements covered?; high quality at short time-to-market: Challenges towards this goal and guidelines for the realization; prioritizing corrective maintenance activities for android applications: An industrial case study on android crash reports; Evaluation of an integrated tool environment for experimentation in DSL engineering.},
	type = {Conference review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Poncelet2016143,
	author = {Poncelet, Clement and Jacquemard, Florent},
	title = {Model-based testing for building reliable realtime interactive music systems},
	year = {2016},
	journal = {Science of Computer Programming},
	volume = {132},
	pages = {143 – 172},
	doi = {10.1016/j.scico.2016.08.002},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84994087111&doi=10.1016%2fj.scico.2016.08.002&partnerID=40&md5=3932c1c8a1b4411d05d32d0fa7eec5e7},
	abstract = {The role of an Interactive Music System (IMS) is to accompany musicians during live performances, acting like a real musician. It must react in realtime to audio signals from musicians, according to a timed high-level requirement called mixed score, written in a domain specific language. Such goals imply strong requirements of temporal reliability and robustness to unforeseen errors in input, yet not much addressed by the computer music community. We present the application of Model-Based Testing techniques and tools to a state-of-the-art IMS, including in particular: offline and on-the-fly approaches for the generation of relevant input data for testing (including timing values), with coverage criteria, the computation of the corresponding expected output, according to the semantics of a given mixed score, the black-box execution of the test data on the System Under Test and the production of a verdict. Our method is based on formal models in a dedicated intermediate representation, compiled directly from mixed scores (high-level requirements), and either passed, to the model-checker Uppaal (after conversion to Timed Automata) in the offline approach, or executed by a virtual machine in the online approach. Our fully automatic framework has been applied to real mixed scores used in concerts and the results obtained have permitted to identify bugs in the target IMS. © 2016 Elsevier B.V.},
	author_keywords = {Interactive music systems; Model based testing; Timed automata},
	keywords = {Automata theory; Black-box testing; Computer music; Computer programming languages; Graphical user interfaces; High level languages; Problem oriented languages; Semantics; Testing; Coverage criteria; Domain specific languages; Interactive music systems; Intermediate representations; Model based testing; Off-line approaches; Temporal reliability; Timed Automata; Model checking},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 3; All Open Access, Bronze Open Access, Green Open Access}
}

@CONFERENCE{Duque-Torres2023606,
	author = {Duque-Torres, Alejandra and Pfahl, Dietmar},
	title = {Towards a Complete Metamorphic Testing Pipeline},
	year = {2023},
	journal = {Proceedings - 2023 IEEE International Conference on Software Maintenance and Evolution, ICSME 2023},
	pages = {606 – 610},
	doi = {10.1109/ICSME58846.2023.00081},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85181540604&doi=10.1109%2fICSME58846.2023.00081&partnerID=40&md5=26f65619c0edbe1eea26867d68936720},
	abstract = {Metamorphic Testing (MT) addresses the test oracle problem by examining the relationships between input-output pairs in consecutive executions of the System Under Test (SUT). These relations, known as Metamorphic Relations (MRs), specify the expected output changes resulting from specific input changes. However, achieving full automation in generating, selecting, and understanding MR violations poses challenges. Our research aims to develop methods and tools that assist testers in generating MRs, defining constraints, and providing explainability for MR outcomes. In the MR generation phase, we explore automated techniques that utilise a domain-specific language to generate and describe MRs. The MR constraint definition focuses on capturing the nuances of MR applicability by defining constraints. These constraints help identify the specific conditions under which MRs are expected to hold. The evaluation and validation involve conducting empirical studies to assess the effectiveness of the developed methods and validate their applicability in real-world regression testing scenarios. Through this research, we aim to advance the automation of MR generation, enhance the understanding of MR violations, and facilitate their effective application in regression testing. © 2023 IEEE.},
	author_keywords = {Automation; Metamorphic Relations; Metamorphic Testing; Regression Testing},
	keywords = {Problem oriented languages; Software testing; Automated techniques; Condition; Domains specific languages; Input-output; Metamorphic relations; Metamorphic testing; Oracle problem; Regression testing; Systems under tests; Test oracles; Automation},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1; All Open Access, Green Open Access}
}

@CONFERENCE{Juhnke201910,
	author = {Juhnke, Katharina and Tichy, Matthias},
	title = {A Tailored Domain Analysis Method for the Development of System-Specific Testing DSLs Enabling Their Smooth Introduction in Automotive Practice},
	year = {2019},
	journal = {Proceedings - 45th Euromicro Conference on Software Engineering and Advanced Applications, SEAA 2019},
	pages = {10 – 18},
	doi = {10.1109/SEAA.2019.00011},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85075988760&doi=10.1109%2fSEAA.2019.00011&partnerID=40&md5=3d843fd175af25bf7f5cad8e755d3945},
	abstract = {Automotive Test Case Specifications (TestSpecs) are a fundamental part of a structured test process in the automotive domain. For system and integration tests, acceptance and customer experience test cases are executed manually by human testers in a prototype vehicle. To ensure that these test cases are understood by humans, they are usually described in natural language, which often leads to ambiguities, misunderstandings, or incomplete test cases. In addition, the description of test cases vary significantly depending on the system to be tested and the respective test level. Test Designers want individual assistance in documenting their test cases with respect to system-specific characteristics, instead of using programming languages or standardized languages such as UML. Thus, Domain Specific Languages (DSLs) are a possible solution to satisfy this demand and to improve the quality of test cases, for example in terms of preciseness, uniformity, and completeness. The contribution of this paper is a systematic approach to support the development of system-specific automotive Testing DSLs that achieve high acceptance by test designers and testers. Therefore, we focus on the analysis phase in the DSL development process. We adapted domain analysis activities and defined a domain analysis method tailored to the analysis of automotive TestSpecs. We demonstrate the applicability of our method by means of five different automotive systems. Our evaluation shows that the derived system-specific Testing DSLs cover between 70% and 95% of the test steps contained in TestSpecs with only 11 to 35 conceptual templates. Moreover, a usability study with practitioners revealed a good usability of the Testing DSLs and the corresponding tool as well as that this eases the specification of test cases. © 2019 IEEE.},
	author_keywords = {automotive software testing; domain analysis; domain specific languages; natural language test cases},
	keywords = {Acceptance tests; Application programs; Digital subscriber lines; Natural language processing systems; Problem oriented languages; Specifications; Well testing; Automotive software; Automotive Systems; Automotive testing; Customer experience; Development process; Domain analysis; Domain specific languages; Test case; Software testing},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 3}
}

@CONFERENCE{Massey2002175,
	author = {Massey, Mary C. and Parrish, Brian E. and McMullen, William E. and Estes, Thomas J.},
	title = {Plastic ball grid arrays, a qualified packaging technology for high reliability space applications},
	year = {2002},
	journal = {Proceedings of SPIE - The International Society for Optical Engineering},
	volume = {4828},
	pages = {175 – 180},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-0036421992&partnerID=40&md5=a3770f2bf2f77e11db4aaa1b18e08e14},
	abstract = {TRW has qualified a new advanced digital packaging technology for critical space applications; Plastic Ball Grid Array (PBGA) assemblies. This achievement enables use of high I/O, state-of-the-art ASIC designs and promises improved digital subsystem performance at significantly reduced weight and cost. Plastic ball grid array packages accommodating die as large as 17 mm sq. with over 800 I/O are planned on future satellite programs surviving extensive component-level and product-level qualification testing. TRW's space-qualification of laminate-based (organic) area array packaging technology responds to the ever increasing demand for reliable, cost effective, high density interconnect (HDI) solutions while leveraging the commercial standard plastic encapsulated microcircuit (PEM). This paper describes the product line approach used to produce qualification test vehicles representative of proposed flight configurations. TRW's radiation hardened 32-bit processor ASIC was used as an electrically functional test vehicle. The initial research focused on package reliability without hermeticity (RWOH) and solder joint reliability. Test results from a controlled insertion of plastic ball grid array packages on flight-like dual sequential laminated (DSL) boards are presented, where thousands of solder joints are continuously monitored using an inexpensive and highly reliable on-board fault detection circuit. The data demonstrates how this technology can provide a superior integrated circuit (IC) packaging solution over traditional ceramic-based assemblies. Space programs will benefit from aggressive insertion of JEDEC standard PBGA packages to achieve higher performance designs with increased circuit densities, while reducing electronic product's size, weight, power, and cost.},
	author_keywords = {Dual sequential laminated (DSL); High density interconnect (HDI); Integrated circuit (IC); Plastic ball grid array (PBGA); Plastic encapsulated microcircuit (PEM); Radiation-hardened 32-bit processor (RH32); Reliability without hermeticity (RWOH)},
	keywords = {Electric discharges; Integrated circuits; Interconnection networks; Laminates; Printed circuit boards; Reliability; Satellites; Space applications; Plastic ball grid arrays (PBGA); Electronics packaging},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1}
}

@ARTICLE{Hoepfner2023,
	author = {Hoepfner, Gregor and Nachmann, Imke and Zerwas, Thilo and Berroth, Joerg K. and Kohl, Jens and Guist, Christian and Rumpe, Bernhard and Jacobs, Georg},
	title = {Towards a Holistic and Functional Model-Based Design Method for Mechatronic Cyber-Physical Systems},
	year = {2023},
	journal = {Journal of Computing and Information Science in Engineering},
	volume = {23},
	number = {5},
	doi = {10.1115/1.4056807},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85187009026&doi=10.1115%2f1.4056807&partnerID=40&md5=e0a99c41769c8f389f7cffa639c4d442},
	abstract = {Engineering cyber-physical systems (CPS) is complex and time-consuming due to the heterogeneity of the involved engineering domains and the high number of physical and logical interactions of their subsystems. Model-based systems engineering (MBSE) approaches tackle the complexity of developing CPS by formally and explicitly modeling subsystems and their interactions. Newer approaches also integrate domain-specific models and modeling languages to cover different aspects of CPS. However, MBSE approaches are currently not fully applicable for CPS development since they do not integrate formal models for physical and mechanical behavior to an extent that allows to seamlessly link mechanical models to the digital models and reuse them. In this paper, we discuss the challenges arising from the missing integration of physics into MBSE and introduce a model-based methodology capable of integrating physical functions and effects into an MBSE approach on a level where detailed physical effects are considered. Our approach offers a fully virtual, model-based development methodology covering the whole development process for the development of CPS. Evaluating this methodology on a real automotive use case demonstrates benefits regarding virtual development and functional testing of CPS. It shows potentials regarding automated development and continuous integration of the whole CPS including all domains. As an outlook of this paper, we discuss potential further research topics extending our development workflow. Copyright © 2023 by ASME.},
	author_keywords = {cyber-physical system design and operation; functional modeling; information management; knowledge engineering; model-based systems engineering},
	keywords = {Design; Embedded systems; Information management; Modeling languages; Cybe-physical system design and operation; Cybe-physical systems; Cyber-physical systems; Design and operations; Domain specific modeling languages; Domain-Specific Modelling Languages; Functional modelling; Holistic model; Model-based system engineerings; Physical effects; Cyber Physical System},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 8}
}

@ARTICLE{Vogel20004pp,
	author = {Vogel, Erich and Halbach, Robert and Sheppard, Ben},
	title = {Programmable DSP-based DSL chipsets streamline system testing},
	year = {2000},
	journal = {EE: Evaluation Engineering},
	volume = {39},
	number = {10},
	pages = {4 pp},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-0034301179&partnerID=40&md5=66059ddaf7bbaed1377e4f952f11448b},
	abstract = {The streamline testing of programmable digital signal processing (DSP)-based digital subscriber line (DSL) was discussed. The programmable DSP-based solutions were tested by performing signal analysis and generation functions in software. The programmable solution allowed manufacturing tests to be customized to individual system requirements. The manufacturing verification process for DSL modems was completed in three stages of in-circuit, parametric and functional testing.},
	keywords = {Costs; Digital signal processing; Integrated circuit testing; Microprogramming; Modems; Digital subscriber lines (DSL); In-circuit testing (ICT); Microprocessor chips},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{2017,
	title = {Proceedings - ACM/IEEE 20th International Conference on Model Driven Engineering Languages and Systems, MODELS 2017},
	year = {2017},
	journal = {Proceedings - ACM/IEEE 20th International Conference on Model Driven Engineering Languages and Systems, MODELS 2017},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85040587063&partnerID=40&md5=da93e88a05513c5241f09ab1013fdd30},
	abstract = {The proceedings contain 36 papers. The topics discussed include: SQL-PL4OCL: an automatic code generator from OCL to SQL procedural language; a fuzzy logic based approach for model-based regression test selection; partial evaluation of OCL expressions; reusable specification templates for defining dynamic semantics of DSLs; active domain-specific languages: making every mobile user a modeller; experiences with teaching MPS in industry: towards bringing domain specific languages closer to practitioners; software product lines with design choices: reasoning about variability and design uncertainty; transformations of software product lines: a generalizing framework based on category theory; revisiting visitors for modular extension of executable DSMLs; from secure business process modeling to design-level security verification; why is my component and connector views specification unsatisfiable?; tool support for live formal verification; model-driven development of safety architectures; synthesis and exploration of multi-level, multi-perspective architectures of automotive embedded systems (SoSYM abstract); the next evolution of MDE: a seamless integration of machine learning into domain modeling; raising time awareness in model-driven engineering: vision paper; co-evolution of meta-modeling syntax and informal semantics in domain-specific modeling environments - a case study of AUTOSAR; heuristic-based recommendation for metamodel - OCL coevolution; ecoreification: making arbitrary java code accessible to metamodel-based tools; user experience for model-driven engineering: challenges and future directions; DREAMS toolchain: model-driven engineering of mixed-criticality systems; and bringing DSE to life: exploring the design space of an industrial automotive use case.},
	type = {Conference review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Häser2018147,
	author = {Häser, Florian and Felderer, Michael and Breu, Ruth},
	title = {Evaluation of an integrated tool environment for experimentation in DSL engineering},
	year = {2018},
	journal = {Lecture Notes in Business Information Processing},
	volume = {302},
	pages = {147 – 168},
	doi = {10.1007/978-3-319-71440-0_9},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85041097449&doi=10.1007%2f978-3-319-71440-0_9&partnerID=40&md5=2b2cd5b82e6ef2bc0ba009922ab15d0d},
	abstract = {Domain specific languages (DSL) are a popular means for providing customized solutions to a certain problem domain. So far, however, language workbenches lack sufficient built-in features in providing decision support when it comes to language design and improvement. Controlled experiments can provide data-driven decision support for both, researchers and language engineers, for comparing different languages or language features. This paper provides an evaluation of an integrated end-to-end tool environment for performing controlled experiments in DSL engineering. The experimentation environment is presented by a running example from engineering domain specific languages for acceptance testing. The tool is built on and integrated into the Meta Programming System (MPS) language workbench. For each step of an experiment the language engineer is supported by suitable DSLs and tools all within the MPS platform. The evaluation, from the viewpoint of the experiments subject, is based on the technology acceptance model (TAM). Results reveal that the subjects found the DSL experimentation environment intuitive and easy to use. © Springer International Publishing AG 2018.},
	author_keywords = {Domain specific languages; DSL; Empirical software engineering; Experimentation; Language engineering; Meta Programming System; Model-based software engineering},
	keywords = {Acceptance tests; Computer programming languages; Computer software selection and evaluation; Decision support systems; DSL; Problem oriented languages; Software engineering; Domain specific languages; Empirical Software Engineering; Experimentation; Language engineering; Meta Programming; Model based software engineering; Digital subscriber lines},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 5}
}

@CONFERENCE{Kumar2015,
	author = {Kumar, Rajesh and Kumar, Vivek},
	title = {Process optimization for testing of domain specific languages in industrial automation},
	year = {2015},
	journal = {2015 World Congress on Information Technology and Computer Applications, WCITCA 2015},
	doi = {10.1109/WCITCA.2015.7367051},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84962473616&doi=10.1109%2fWCITCA.2015.7367051&partnerID=40&md5=47d0b26a48ce3ed250a04d194aa96212},
	abstract = {Software testing is essential part of software development. The goal of the testing process is not only to enhance the quality and robustness of the software but also verify the correctness and non functional requirements of the software under all working conditions. Large software has their large testing suites to verify the stability of legacy features. Testing processes have huge challenges to maintain effectiveness and efficiency of the legacy test cases. There are many different processes and techniques available all technique or processes have their advantages and limitations. A tailored testing process has been tried to utilize all technique together to improvise the benefits and efficiency of testing in the industrial automation domain. This paper tries to explain a customized approach of utilizing the available testing techniques in such a way that it enhances the effectiveness and efficiency of regression testing, thus improving the time to market of large product-line Industrial automation software. © 2015 IEEE.},
	author_keywords = {Industial automation; Regression testing; Software testing process; Test automation; Test effectiveness; Test suite optimization},
	keywords = {Automation; Computer programming languages; Computer software; Efficiency; Optimization; Problem oriented languages; Software design; Testing; Domain specific languages; Effectiveness and efficiencies; Efficiency of testing; Industrial automation; Non-functional requirements; Regression testing; Test Automation; Test effectiveness; Software testing},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Strasser20104687,
	author = {Strasser, T. and Peters, T. and Jägle, H. and Zrenner, E. and Wilke, R.},
	title = {An integrated domain specific language for post-processing and visualizing electrophysiological signals in Java},
	year = {2010},
	journal = {2010 Annual International Conference of the IEEE Engineering in Medicine and Biology Society, EMBC'10},
	pages = {4687 – 4690},
	doi = {10.1109/IEMBS.2010.5626417},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-78650837400&doi=10.1109%2fIEMBS.2010.5626417&partnerID=40&md5=7b2189cb0d2e385f46d1ec94c4ff7f22},
	abstract = {Electrophysiology of vision - especially the electroretinogram (ERG) - is used as a non-invasive way for functional testing of the visual system. The ERG is a combined electrical response generated by neural and non-neuronal cells in the retina in response to light stimulation. This response can be recorded and used for diagnosis of numerous disorders. For both clinical practice and clinical trials it is important to process those signals in an accurate and fast way and to provide the results as structured, consistent reports. Therefore, we developed a freely available and open-source framework in Java (http://www.eye.uni-tuebingen.de/projectlidsI4sigproc). The framework is focused on an easy integration with existing applications. By leveraging well-established software patterns like pipes-and-filters and fluent interfaces as well as by designing the application programming interfaces (API) as an integrated domain specific language (DSL) the overall framework provides a smooth learning curve. Additionally, it already contains several processing methods and visualization features and can be extended easily by implementing the provided interfaces. In this way, not only can new processing methods be added but the framework can also be adopted for other areas of signal processing. This article describes in detail the structure and implementation of the framework and demonstrate its application through the software package used in clinical practice and clinical trials at the University Eye Hospital Tuebingen one of the largest departments in the field of visual electrophysiology in Europe. © 2010 IEEE.},
	keywords = {Algorithms; Computer Graphics; Diagnosis, Computer-Assisted; Electroretinography; Humans; Programming Languages; Retinal Diseases; Software; User-Computer Interface; Application programming interfaces (API); Electrophysiology; Experiments; Neurology; Processing; Signal processing; Visualization; Clinical practices; Clinical trial; Domain specific languages; Electrical response; Electroretinograms; Functional testing; Learning curves; Light stimulation; Neuronal cell; Non-invasive way; Open source frameworks; Post processing; Processing method; Software patterns; Visual systems; algorithm; article; computer assisted diagnosis; computer graphics; computer interface; computer language; computer program; electroretinography; human; methodology; retina disease; Java programming language},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 4}
}

@CONFERENCE{Vanderbauwhede2010141,
	author = {Vanderbauwhede, W. and Margala, M. and Chalamalasetti, S.R. and Purohit, S.},
	title = {A C++-embedded domain-specific language for programming the MORA soft processor array},
	year = {2010},
	journal = {Proceedings of the International Conference on Application-Specific Systems, Architectures and Processors},
	pages = {141 – 148},
	doi = {10.1109/ASAP.2010.5540750},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-77955948453&doi=10.1109%2fASAP.2010.5540750&partnerID=40&md5=ac257e54a23c83c1dbcc8c531fe9b659},
	abstract = {MORA is a novel platform for high-level FPGA programming of streaming vector and matrix operations, aimed at multimedia applications. It consists of soft array of pipelined low-complexity SIMD processors-in-memory (PIM). We present a Domain-Specific Language (DSL) for high-level programming of the MORA soft processor array. The DSL is embedded in C++, providing designers with a familiar language framework and the ability to compile designs using a standard compiler for functional testing before generating the FPGA bitstream using the MORA toolchain. The paper discusses the MORA-C++ DSL and the compilation route into the assembly for the MORA machine and provides examples to illustrate the programming model and performance. © 2010 IEEE.},
	author_keywords = {Domain-Specific language; Multimedia processing; Reconfigurable processor; Soft processor array},
	keywords = {Ability testing; Computer debugging; Digital subscriber lines; Functional programming; Pipeline processing systems; Problem oriented languages; Program compilers; Program debugging; Domains specific languages; Embedded domain-specific languages; Matrix operations; Multimedia applications; Multimedia processing; Processor array; Reconfigurable processors; Soft processor array; Soft processors; Vector operations; C++ (programming language)},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 10; All Open Access, Green Open Access}
}

@CONFERENCE{Gu2012945,
	author = {Gu, YaJun and Qin, Ye and Wang, ZhiJun and Wei, David and Ho, Andrew and Chen, Stephen and Feng, Zhen and Kurwa, Murad},
	title = {Application of build-in self test in functional test of DSL},
	year = {2012},
	journal = {IPC APEX EXPO 2012},
	volume = {2},
	pages = {945 – 959},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84867781631&partnerID=40&md5=1c267502b42d08eec9906c8e3b63b2fb},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1}
}

@CONFERENCE{Devroey2015817,
	author = {Devroey, Xavier and Perrouin, Gilles and Schobbens, Pierre-Yves and Heymans, Patrick},
	title = {Poster: VIBeS, Transition System Mutation Made Easy},
	year = {2015},
	journal = {Proceedings - International Conference on Software Engineering},
	volume = {2},
	pages = {817 – 818},
	doi = {10.1109/ICSE.2015.263},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84951856946&doi=10.1109%2fICSE.2015.263&partnerID=40&md5=9d5916997a8ecba09d6f142637546d01},
	abstract = {Mutation testing is an established technique used to evaluate the quality of a set of test cases. As model-based testing took momentum, mutation techniques were lifted to the model level. However, as for code mutation analysis, assessing test cases on a large set of mutants can be costly. In this paper, we introduce the Variability-Intensive Behavioural teSting (VIBeS) framework. Relying on Featured Transition Systems (FTSs), we represent all possible mutants in a single model constrained by a feature model for mutant (in)activation. This allow to assess all mutants in a single test case execution. We present VIBeS implementation steps and the DSL we defined to ease model-based mutation analysis. © 2015 IEEE.},
	author_keywords = {Featured Transition Systems; Model-Based Mutation Testing; VIBeS},
	keywords = {Model checking; Software engineering; Software testing; Feature modeling; Implementation steps; Model based testing; Model-based OPC; Mutation analysis; Mutation testing; Transition system; VIBeS; Quality control},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 7}
}

@CONFERENCE{Makki2016178,
	author = {Makki, Majid and Van Landuyt, Dimitri and Joosen, Wouter},
	title = {Automated regression testing of BPMN 2.0 processes a capture and replay framework for continuous delivery},
	year = {2016},
	journal = {GPCE 2016 - Proceedings of the 2016 ACM SIGPLAN International Conference on Generative Programming: Concepts and Experiences, co-located with SPLASH 2016},
	pages = {178 – 189},
	doi = {10.1145/2993236.2993257},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85006698880&doi=10.1145%2f2993236.2993257&partnerID=40&md5=3c116cc2fd69d4e51e8545e01e06e3e4},
	abstract = {Regression testing is a form of software quality assurance (QA) that involves comparing the behavior of a newer version of a software artifact to its earlier correct behavior, and signaling the QA engineer when deviations are detected. Given the large potential in automated generation and execution of regression test cases for business process models in the context of running systems, powerful tools are required to make this practically feasible, more specifically to limit the potential impact on production systems, and to reduce the manual effort required from QA engineers. In this paper, we present a regression testing automation framework that implements the capture & replay paradigm in the context of BPMN 2.0, a domain-specific language for modeling and executing business processes. The framework employs parallelization techniques and efficient communication patterns to reduce the performance overhead of capturing. Based on inputs from the QA engineer, it manipulates the BPMN2 model before executing tests for isolating the latter from external dependencies (e.g. human actors or expensive web services) and for avoiding undesired sideeffects. Finally, it performs a regression detection algorithm and reports the results to the QA engineer. We have implemented our framework on top of a BPMN2-compliant execution engine, namely jBPM, and performed functional validations and evaluations of its performance and fault-Tolerance. The results, indicating 3:9% average capturing performance overhead, demonstrate that the implemented framework can be the foundation of a practical regression testing tool for BPMN 2.0, and a key enabler for continuous delivery of business process-driven applications and services. ©2016 ACM.},
	author_keywords = {BPMN 2.0; Business process execution; JBPM; Node mocking; Performance overhead; Regression testing; Test automation},
	keywords = {Automatic programming; Automation; Computer programming languages; Computer software selection and evaluation; Engineers; Fault tolerance; Modeling languages; Problem oriented languages; Quality assurance; Regression analysis; Web services; BPMN 2.0; Business process execution; JBPM; Node mocking; Performance overhead; Regression testing; Test Automation; Software testing},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 3}
}

@ARTICLE{Bache2014320,
	author = {Bache, Emily and Bache, Geoffrey},
	title = {Specification by example with gui tests - how could that work?},
	year = {2014},
	journal = {Lecture Notes in Business Information Processing},
	volume = {179 LNBIP},
	pages = {320 – 326},
	doi = {10.1007/978-3-319-06862-6_26},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84904569844&doi=10.1007%2f978-3-319-06862-6_26&partnerID=40&md5=31a1d19d98862c19765b2fc95d31a409},
	abstract = {Specification by Example is a collaborative method for developing software. It involves a workshop where people representing various roles and viewpoints discuss what is to be built, and come up with concrete example scenarios. These scenarios later form the basis for automated (functional) acceptance tests, and are sometimes called "Living Documentation", as they are written in a Domain Specific Language and can be read by non-programmers. GUI testing has traditionally used a record-replay paradigm that requires the user interface exists before the tests can be created, and hence have been considered incompatible with a Specification by Example approach. In this experience report we will discuss how we have overcome this apparent contradiction at Jeppesen, and relate an experience using the tool TextTest for GUI testing of Jeppesen's next-generation Crew Management System. © Springer International Publishing Switzerland 2014.},
	author_keywords = {ATDD; Capture-Replay Testing; GUI testing; Specification by Example},
	keywords = {Graphical user interfaces; Problem oriented languages; Software design; Specifications; ATDD; Capture-replay; Crew management systems; Domain specific languages; Experience report; GUI testing; Record-replay; Acceptance tests},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 5}
}

@CONFERENCE{2008,
	title = {Software Engineering 2008 - Fachtagung des GI-Fachbereichs Softwaretechnik},
	year = {2008},
	journal = {Lecture Notes in Informatics (LNI), Proceedings - Series of the Gesellschaft fur Informatik (GI)},
	volume = {P-121},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85135817088&partnerID=40&md5=92cd9eb678ac694dec744b22590a3fd2},
	abstract = {The proceedings contain 36 papers. The topics discussed include: connecting good theory to good practice: software documentation: a case study; assisting needs driven requirements engineering with the ARIS toolset; eliminating trust from application programs by way of software architecture; towards automatic construction of reusable prediction models for component-based performance engineering; towards effective management of software knowledge exploiting the semantic wiki paradigm; towards a peer-to-peer based global software development environment; combining structural and functional test case generation; Monaco: a DSL approach for programming automation systems; and workshop agile knowledge sharing for distributed software teams.},
	type = {Conference review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{2025,
	title = {13th International Conference on Model-Based Software and Systems Engineering, MODELSWARD 2025},
	year = {2025},
	journal = {International Conference on Model-Driven Engineering and Software Development},
	volume = {1},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-105001807758&partnerID=40&md5=b3fddfddddcc27fb8c095c3135f7e24a},
	abstract = {The proceedings contain 46 papers. The special focus in this conference is on Model-Based Software and Systems Engineering. The topics include: Efficient Modelling with Logic-Labelled Finite-State Machines of IEC 61499 Function Blocks: Simulation, Execution and Verification; Evaluating the Quality of Class Diagrams Created by a Generative AI: Findings, Guidelines and Automation Options; towards Synthesis-Based Engineering for Cyber-Physical Production Systems; Designing a Meta-Model for the Eclipse Qrisp eDSL for High-Level Quantum Programming; towards a Domain-Specific Modelling Environment for Reinforcement Learning; A Taxonomy of Change Types for Textual DSL Grammars; Towards the Model-Driven Development of Adaptive Cloud Applications by Leveraging UML-RT and Container Orchestration; automatic Evaluation and Partitioning of Algorithms for Heterogeneous Systems; HyperGraphOS: A Meta Operating System for Science and Engineering; energy Monitoring Systems Analysis and Development: A Case Study for Graph-Based Modelling; a Domain Specific Language to Design New Control Architectures for Smart Grids; an Automata-Based Method to Formalize Psychological Theories: The Case Study of Lazarus and Folkman’s Stress Theory; Enabling Incremental SysML Model Verification: Managing Variability and Complexity Through Tagging and Model Reduction; next-Generation Design Tools for Intelligent Transportation Systems; reMoDeL: A Pure Functional Object-Oriented Concept Language for Models, Metamodels and Model Transformation; on the Generation of Input Space Model for Model-Driven Requirements-Based Testing; Automated Generation of Standardised Digital Twins Based on MBSE Models; towards a Classification Framework for the Digital Twin Tools: A Taxonomy; digital Twin System of Systems: A Layered Architecture Proposal; hierarchical System of Digital Twins: A Holistic Architecture for Swarm System Analysis.},
	type = {Conference review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Al-Sibahi2016207,
	author = {Al-Sibahi, Ahmad Salim and Dimovski, Aleksandar S. and Wasowski, Andrzej},
	title = {Symbolic execution of high-level transformations},
	year = {2016},
	journal = {SLE 2016 - Proceedings of the 2016 ACM SIGPLAN International Conference on Software Language Engineering, co-located with SPLASH 2016},
	pages = {207 – 220},
	doi = {10.1145/2997364.2997382},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85006790383&doi=10.1145%2f2997364.2997382&partnerID=40&md5=b701466c119c446a346df19b6b2204dc},
	abstract = {Transformations form an important part of developing domain specific languages, where they are used to provide semantics for typing and evaluation. Yet, few solutions exist for verifying transformations written in expressive high-level transformation languages. We take a step towards that goal, by developing a general symbolic execution technique that handles programs written in these high-level transformation languages. We use logical constraints to describe structured symbolic values, including containment, acyclicity, simple unordered collections (sets) and to handle deep type-based querying of syntax hierarchies. We evaluate this symbolic execution technique on a collection of refactoring and model transformation programs, showing that the white-box test generation tool based on symbolic execution obtains better code coverage than a black box test generator for such programs in almost all tested cases.},
	author_keywords = {Automated white-box test generation; Model transformation; Program transformation; Symbolic execution},
	keywords = {Computer programming languages; Model checking; Problem oriented languages; Semantics; Software testing; Domain specific languages; High-level transformations; Logical constraints; Model transformation; Program transformations; Symbolic execution; Symbolic value; Test generations; High level languages},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 16}
}

@CONFERENCE{Shrivastava202456,
	author = {Shrivastava, Ajita and Mitra, Arka Pratap and Dungdung, Vinita and Singh, Deep},
	title = {Development of a Critical System Using a Domain Specific Language},
	year = {2024},
	journal = {2024 IEEE Space, Aerospace and Defence Conference, SPACE 2024},
	pages = {56 – 60},
	doi = {10.1109/SPACE63117.2024.10667978},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85205272471&doi=10.1109%2fSPACE63117.2024.10667978&partnerID=40&md5=ceaf7ac576380c2ca4d1727043ca68f4},
	abstract = {For enhanced software modularity and maintainability, while meeting the exceedingly complex system requirements, a Domain Specific Language (DSL) was developed for the safety related computer system- Emergency Core Cooling System Test Facility, in a nuclear power station. This conception facilitated accurate development of test sequences directly by domain experts possessing limited familiarity with computer programming aspects. This unique DSL-based programming approach and exhaustive closed-loop black box testing enabled accurate tuning of variabilities, speedier software development, and ease of future modification. Considering the stringent atomic energy regulatory requirements, this also duly saved on development effort and software qualification timeline. © 2024 IEEE.},
	author_keywords = {Domain Specific Language; Nuclear Power Plant; Software Development},
	keywords = {Black-box testing; Nuclear energy; Critical systems; Domains specific languages; Emergency Core Cooling System; Enhanced software; Power; Safety-Related; Software maintainability; Software modularity; System requirements; System test; Nuclear power plants},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Honfi2017119,
	author = {Honfi, Dávid and Molnár, Gábor and Micskei, Zoltán and Majzik, István},
	title = {Model-based regression testing of autonomous robots},
	year = {2017},
	journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
	volume = {10567 LNCS},
	pages = {119 – 135},
	doi = {10.1007/978-3-319-68015-6_8},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030667574&doi=10.1007%2f978-3-319-68015-6_8&partnerID=40&md5=c0ede83fdf5f839c64044a13044f7747},
	abstract = {Testing is a common technique to assess quality of systems. Regression testing comes into view, when changes are introduced to the system under test and re-running all tests is not practical. Numerous techniques have been introduced to select tests only relevant to a given set of changes. These are typically based on source code, however, model-based development projects use models as primary artifacts described in various domain-specific languages. Thus, regression test selection should be performed directly on these models. We present a method and a case study on how model-based regression testing can be achieved in the context of autonomous robots. The method uses information from several domain-specific languages for modeling the robot’s context and configuration. Our approach is implemented in a prototype tool, and its scalability is evaluated on models from the case study. © 2017, Springer International Publishing AG.},
	keywords = {Computer programming languages; Modeling languages; Problem oriented languages; Regression analysis; Software testing; Systems analysis; Domain specific languages; Model based development; Model-based OPC; Prototype tools; Regression test selection; Regression testing; Source codes; System under test; Robots},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 6}
}

@ARTICLE{Sinha2006242,
	author = {Sinha, Avik and Smidts, Carol},
	title = {HOTTest: A model-based test design technique for enhanced testing of domain-specific applications},
	year = {2006},
	journal = {ACM Transactions on Software Engineering and Methodology},
	volume = {15},
	number = {3},
	pages = {242 – 278},
	doi = {10.1145/1151695.1151697},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-33748528112&doi=10.1145%2f1151695.1151697&partnerID=40&md5=396688bb148f87f73f3face6aa31322c},
	abstract = {Model-based testing is an effective black-box test generation technique for applications. Existing model-based testing techniques, however, fail to capture implicit domain-specific properties, as they overtly rely on software artifacts such as design documents, requirement specifications, etc., for completeness of the test model. This article presents a technique, HOTTest, which uses a strongly typed domain-specific language to model the system under test. This allows extraction of type-related system invariants, which can be related to various domain-specific properties of the application. Thus, using HOTTest, it is possible to automatically extract and embed domain-specific requirements into the test models. In this article we describe HOTTest, its principles and methodology, and how it is possible to relate domain-specific properties to specific type constraints. HOTTest is described using the example of HaskellDB, which is a Haskell-based embedded domain-specific language for relational databases. We present an example application of the technique and compare the results to some other commonly used Model-based test automation techniques like ASML-based testing, UML-based testing, and EFSM-based testing. © 2006 ACM.},
	author_keywords = {Database-specific test case generation; Domain-specific languages; Domain-specific testing; Haskell; HaskellDB; Model-based testing; Test case generation; Test generation tools},
	keywords = {Automation; Computer programming languages; Database systems; Embedded systems; Mathematical models; Database-specific test case generation; Domain-specific languages; Domain-specific testing; HaskellDB; Haskells; Model-based testing; Test case generation; Test generation tools; Software engineering},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 12}
}

@CONFERENCE{Gafurov2018749,
	author = {Gafurov, Davrondzhon and Hurum, Arne Erik and Markman, Martin},
	title = {Achieving test automation with testers without coding skills: An industrial report},
	year = {2018},
	journal = {ASE 2018 - Proceedings of the 33rd ACM/IEEE International Conference on Automated Software Engineering},
	pages = {749 – 756},
	doi = {10.1145/3238147.3240463},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85056528902&doi=10.1145%2f3238147.3240463&partnerID=40&md5=07b833ad7afb59d7723cc0d1e0f62984},
	abstract = {We present a process driven test automation solution which enables delegating (part of) automation tasks from test automation engineer (expensive resource) to test analyst (non-developer, less expensive). In our approach, a test automation engineer implements test steps (or actions) which are executed automatically. Such automated test steps represent user actions in the system under test and specified by a natural language which is understandable by a non-technical person. Then, a test analyst with a domain knowledge organizes automated steps combined with test input to create an automated test case. It should be emphasized that the test analyst does not need to possess programming skills to create, modify or execute automated test cases. We refine benchmark test automation architecture to be better suitable for an effective separation and sharing of responsibilities between the test automation engineer (with coding skills) and test analyst (with a domain knowledge). In addition, we propose a metric to empirically estimate cooperation between test automation engineer and test analyst's works. The proposed automation solution has been defined based on our experience in the development and maintenance of Helsenorge, the national electronic health services in Norway which has had over one million of visits per month past year, and we still use it to automate the execution of regression tests. © 2018 Association for Computing Machinery.},
	author_keywords = {DSL for test automation; Helsenorge; Keyword-driven test automation; Process-driven test automation; Test automation},
	keywords = {Benchmarking; Engineers; Software engineering; Automation solutions; Domain knowledge; Electronic health; Helsenorge; Natural languages; Programming skills; System under test; Test Automation; Automation},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 8}
}

@ARTICLE{Khorram20251187,
	author = {Khorram, Faezeh and Bousse, Erwan and Mottu, Jean-Marie and Sunyé, Gerson and  Khelladi, Djamel Eddine and Gómez-Abajo, Pablo and  Cañizares, Pablo C. and Guerra, Esther and de Lara, Juan},
	title = {A language-parametric test amplification framework for executable domain-specific languages},
	year = {2025},
	journal = {Software and Systems Modeling},
	volume = {24},
	number = {4},
	pages = {1187 – 1212},
	doi = {10.1007/s10270-025-01283-4},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-105006819310&doi=10.1007%2fs10270-025-01283-4&partnerID=40&md5=eac295ffbd9e844fefa3613183715133},
	abstract = {Behavioral models are important assets that must be thoroughly verified early in the design process. This can be achieved with manually-written test cases that embed carefully hand-picked domain-specific input data. However, such test cases may not always reach the desired level of quality, such as high coverage or being able to localize faults efficiently. Test amplification is an interesting emergent approach to improve a test suite by automatically generating new test cases out of existing manually-written ones. Yet, while ad-hoc test amplification solutions have been proposed for a few programming languages, no solution currently exists for amplifying the test suites of behavioral models. In order to fill this gap, we propose an automated and generic test amplification approach for executable domain-specific languages (DSLs). Hence, given an executable DSL, a conforming behavioral model, and an existing test suite, our approach synthesizes new regression test cases in three steps: (i) generating new test inputs by applying a set of generic modifiers on the existing test inputs; (ii) running the model under test with new inputs and generating assertions from the execution traces; and (iii) selecting the new test cases that increase the initial test quality. We provide a textual DSL to control and configure the amplification process, along with tool support for the whole approach atop the Eclipse GEMOC Studio. For assessment, we report on empirical evaluations over two different executable DSLs, which show improved test quality in terms of both coverage and mutation score. © The Author(s), under exclusive licence to Springer-Verlag GmbH Germany, part of Springer Nature 2025.},
	author_keywords = {Executable DSL; Executable model; Mutation testing; Regression testing; Test amplification},
	keywords = {Computer control; Problem oriented languages; Statistical process control; Behavioral model; Domains specific languages; Executable domain-specific language; Executable modeling; Executables; Mutation testing; Regression testing; Test amplifications; Test case; Test inputs; Design for testability},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{20141,
	title = {6th International Symposium on Leveraging Applications of Formal Methods, Verification and Validation, ISoLA 2014},
	year = {2014},
	journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
	volume = {8802},
	pages = {1 – 546},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84920545548&partnerID=40&md5=960410e1fe04f939dd4471ff830fdb7f},
	abstract = {The proceedings contain 44 papers. The special focus in this conference is on Critical Systems, Rigorous Engineering of Autonomic Ensembles, Automata Learning, Formal Methods and Analysis, Model-Based Code Generators and Automata Learning in Practice. The topics include: Statistical abstraction boosts design and test efficiency of evolving critical systems; incremental syntactic-semantic reliability analysis of evolving structured workflows; domain-specific languages for enterprise systems; formalizing self-adaptive clouds with knowlang; towards performance-aware engineering of autonomic component ensembles; rigorous system design flow for autonomous systems; algorithms for inferring register automata; active learning of nondeterministic systems from an ioco perspective; fomal methods and analyses in software product line engineering; domain specific languages for managing feature models; deployment variability in delta-oriented models; coverage criteria for behavioural testing of software product lines; DSL implementation for model-based development of pumps; domain-specific code generator modeling; LNCS transactions on foundations for mastering change; formal methods for collective adaptive ensembles; current issues on model-based software quality assurance for mastering change and compositional model-based system design as a foundation for mastering change.},
	type = {Conference review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{2012,
	title = {Computer Applications for Software Engineering, Disaster Recovery, and Business Continuity - International Conferences, ASEA and DRBC 2012, Held in Conjunction with GST 2012, Proceedings},
	year = {2012},
	journal = {Communications in Computer and Information Science},
	volume = {340 CCIS},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84869847795&partnerID=40&md5=50ed69d3acd9f3c6e6b80204eec1482c},
	abstract = {The proceedings contain 62 papers. The topics discussed include: impact on realistic mobility model for aircraft ad hoc networks; technology network model using bipartite social network analysis; mobile application development using component features and inheritance; view, level and fragment: commonalities in 'Architecture 101' and software modelling; highly analysable, reusable, and realisable architectural designs with XCD; ARSL: a domain specific language for aircraft separation minima determination; regression testing of object-oriented software: a technique based on use cases and associated tool; development of an instant meeting Android application using Wi-Fi direct APIs; developer support for understanding preprocessor macro expansions; towards building method level maintainability models based on expert evaluations; and a study on the improved stability of inverter through history management of semiconductor elements for power supply.},
	type = {Conference review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Selim2015365,
	author = {Selim, Gehan M. K. and Wang, Shige and Cordy, James R. and Dingel, Juergen},
	title = {Model transformations for migrating legacy deployment models in the automotive industry},
	year = {2015},
	journal = {Software and Systems Modeling},
	volume = {14},
	number = {1},
	pages = {365 – 381},
	doi = {10.1007/s10270-013-0365-1},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84922338189&doi=10.1007%2fs10270-013-0365-1&partnerID=40&md5=cb7ae64fdf0c3556171f4b91381d82e1},
	abstract = {Many companies in the automotive industry have adopted model-driven development in their vehicle software development. As a major automotive company, General Motors (GM) has been using a custom-built, domain-specific modeling language, implemented as an internal proprietary metamodel, to meet the modeling needs in its control software development. Since AUTomotive Open System ARchitecture (AUTOSAR) has been developed as a standard to ease the process of integrating components provided by different suppliers and manufacturers, there has been a growing demand to migrate these GM-specific, legacy models to AUTOSAR models. Given that AUTOSAR defines its own metamodel for various system artifacts in automotive software development, we explore applying model transformations to address the challenges in migrating GM-specific, legacy models to their AUTOSAR equivalents. As a case study, we have built and validated a model transformation using the MDWorkbench tool, the Atlas Transformation Language, and the Metamodel Coverage Checker tool. This paper reports on the case study, makes observations based on our experience to assist in the development of similar types of transformations, and provides recommendations for further research. © 2013, Springer-Verlag Berlin Heidelberg.},
	author_keywords = {Automotive control software; AUTOSAR; Black-box testing; Model transformations; Model-driven development (MDD); Transformation languages and tools},
	keywords = {Automobile manufacture; Black-box testing; Modeling languages; Open systems; Software design; Specification languages; Automotive control softwares; AutoSAR; Model transformation; Model-driven development; Transformation languages; Automotive industry},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 11}
}

@CONFERENCE{Aichernig201952,
	author = {Aichernig, Bernhard K. and Maderbacher, Benedikt and Tiran, Stefan},
	title = {Programming behavioral test models for SMT solving in scala},
	year = {2019},
	journal = {Proceedings - 2019 IEEE 12th International Conference on Software Testing, Verification and Validation Workshops, ICSTW 2019},
	pages = {52 – 60},
	doi = {10.1109/ICSTW.2019.00032},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85068361945&doi=10.1109%2fICSTW.2019.00032&partnerID=40&md5=fe77d7bc2818e097d36e6b5b03208583},
	abstract = {We present a novel approach for modeling cyber-physical systems for analysis and test purposes. Instead of creating a new expressive specification language with sophisticated semantics and complex compilers, we rely on a lightweight version of Back's Action Systems, for which we provide a simple bounded model checker using the SMT solver Z3. In order to model industrial-sized embedded systems, we extend our simple specification language by using the powerful capa-bilities of the modern programming language Scala for creating Domain Specific Languages (DSL). This enables us to use the features of an expressive, object-oriented and functional generalpurpose language without the need to increase the complexity of the model checker. We demonstrate how to model a railway interlocking system with a configurable track layout and sketch the application to model-based testing. © 2019 IEEE.},
	author_keywords = {Domain specific language; Model-based testing; Modelling; Scala; Test case generation},
	keywords = {Behavioral research; Embedded systems; Interlocking signals; Modeling languages; Models; Object oriented programming; Problem oriented languages; Semantics; Software testing; Specification languages; Specifications; Bounded model checkers; Domain specific languages; General-purpose languages; Model based testing; Object oriented; Railway interlocking system; Scala; Test case generation; Model checking},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1}
}

@CONFERENCE{Gu2012233,
	author = {Gu, YaJun and Qin, Ye and Wang, ZhiJun and Wei, David and Ho, Andrew and Chen, Stephen and Feng, Zhen and Kurwa, Murad},
	title = {Application of build-in self test in functional test of DSL},
	year = {2012},
	journal = {IPC APEX EXPO 2012},
	volume = {1},
	pages = {233 – 234},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84867814409&partnerID=40&md5=a1035fbcd1b42d620c0432fb69d626af},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1}
}

@ARTICLE{Boussaa2016202,
	author = {Boussaa, Mohamed and Barais, Olivier and Baudry, Benoit and Sunyé, Gerson},
	title = {Automatic non-functional testing of code generators families},
	year = {2016},
	journal = {ACM SIGPLAN Notices},
	volume = {52},
	number = {3},
	pages = {202 – 212},
	doi = {10.1145/2993236.2993256},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85084172333&doi=10.1145%2f2993236.2993256&partnerID=40&md5=3976bedc803982e1108e7fd43d89fa58},
	abstract = {The intensive use of generative programming techniques provides an elegant engineering solution to deal with the heterogeneity of platforms and technological stacks. The use of domain-specific languages for example, leads to the creation of numerous code generators that automatically translate highlevel system specifications into multi-target executable code. Producing correct and efficient code generator is complex and error-prone. Although software designers provide generally high-level test suites to verify the functional outcome of generated code, it remains challenging and tedious to verify the behavior of produced code in terms of non-functional properties. This paper describes a practical approach based on a runtime monitoring infrastructure to automatically check the potential inefficient code generators. This infrastructure, based on system containers as execution platforms, allows code-generator developers to evaluate the generated code performance. We evaluate our approach by analyzing the performance of Haxe, a popular high-level programming language that involves a set of cross-platform code generators. Experimental results show that our approach is able to detect some performance inconsistencies that reveal real issues in Haxe code generators. © 2016 ACM.},
	author_keywords = {code generator; code quality; non-functional properties; testing},
	keywords = {Problem oriented languages; Specifications; Domain specific languages; Engineering solutions; Execution platforms; Generative programming; High-level programming language; High-level systems; Non functional properties; Runtime Monitoring; Software testing},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1; All Open Access, Green Open Access}
}

@ARTICLE{Sinha2006173,
	author = {Sinha, Avik and Smidts, Carol},
	title = {An experimental evaluation of a higher-ordered-typed-functional specification-based test-generation technique},
	year = {2006},
	journal = {Empirical Software Engineering},
	volume = {11},
	number = {2},
	pages = {173 – 202},
	doi = {10.1007/s10664-006-6401-9},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-33644906370&doi=10.1007%2fs10664-006-6401-9&partnerID=40&md5=a051111db1dd9103f58ef5ba4e52186b},
	abstract = {HOTTest is a model based test automation technique of software systems based on models of the system described using HaskellDB. HaskellDB is an embedded domain specific language derived from Haskell. HOTTest enforces a systematic abstraction process and exploits system invariants for automatically producing test cases for domain specific requirements. Use of functional languages for system modeling is a new concept and hence HOTTest is subject to concerns of usability, like any other new technique. Also, the syntax and the declarative style of Haskell based languages make them difficult to learn. Similar concerns can be raised for HOTTest as it shares the same syntax with Haskell. In this paper we describe an experiment designed to study the usability of HOTTest and to compare it with existing model based test design techniques. The results show that HOTTest is more usable than the traditional technique and demonstrate that the test suites produced by HOTTest are more effective and efficient than those generated using the traditional model based test design technique. © Springer Science + Business Media, Inc. 2006.},
	author_keywords = {Controlled experiment; EFSM software model; Empirical study; Functional specification language; Software test automation},
	keywords = {Automation; Computer hardware description languages; Computer software; Mathematical models; Controlled experiment; EFSM software model; Empirical study; Functional specification language; Software test automation; Software engineering},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 13}
}

@CONFERENCE{Häser2014156,
	author = {Häser, Florian and Felderer, Michael and Breu, Ruth},
	title = {Test process improvement with documentation driven integration testing},
	year = {2014},
	journal = {Proceedings - 2014 9th International Conference on the Quality of Information and Communications Technology, QUATIC 2014},
	pages = {156 – 161},
	doi = {10.1109/QUATIC.2014.29},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84921059614&doi=10.1109%2fQUATIC.2014.29&partnerID=40&md5=634d14b73fda52a267350bb24816c632},
	abstract = {Improving the maturity of the test process in an organization, especially but not limited to integration testing, involves obstacles and risks, such as the additional work overhead of the new process. In addition, integration testing descriptions are often too technical not addressing the language needs of the domain. In research cooperations with companies from the insurance and banking domain it turned out that test descriptions and reports are one of the most useful testing artifacts, while doing adhoc testing. This paper presents a bottom up testing approach, which first helps the integration tester in producing a semi-formal test description and report, up to be an enabler for automatic model-based testing in the very end. The presented approach is based on a textual domain specific language that is able to evolve over time. This is done by analyzing the test descriptions and reports automatically with machine learning techniques as well as manually by integration testers. Often recurring test steps or used components are integrated into the test language, making it specially tailored for a specific organization. For each test step implementations can be attached, preparing it for the next iteration. In this paper the methodology and architecture of our integration testing approach are presented together with the underlying language concepts. © 2014 IEEE.},
	author_keywords = {Model-Based Integration Testing; Regression Testing; Test Process Improvement},
	keywords = {Integration; Iterative methods; Learning systems; Model checking; Online systems; Problem oriented languages; Process engineering; Automatic modeling; Domain specific languages; Machine learning techniques; Model-based integrations; Regression testing; Research cooperation; Test process; Underlying language; Integration testing},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 3}
}

@CONFERENCE{Liu202047,
	author = {Liu, Huabin},
	title = {A Universal Automated Test Solution for Trunking Communication System},
	year = {2020},
	journal = {Proceedings - 2020 International Conference on Computer Engineering and Application, ICCEA 2020},
	pages = {47 – 51},
	doi = {10.1109/ICCEA50009.2020.00017},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85086401815&doi=10.1109%2fICCEA50009.2020.00017&partnerID=40&md5=7a6362d93e52cce8a7d7448e1caf3563},
	abstract = {In order to improve the portability of the automated test of the trunking communication system, this paper proposed a universal automated test solution for the trunking communication system. It's based on the general architecture design of the trunking communication system, providing a replaceable communication protocol codec module. With the DSL-defined test script language describing the test cases, and efficient scheduling schemes for the test task, the automated functional test and performance test of the trunking communication system are realized. Theoretical analysis and experimental results show that the minimum load test task scheduling scheme based on user operation load prediction has lower response time and lower load balancing effect compared with the traditional static task scheduling scheme. © 2020 IEEE.},
	author_keywords = {automated test; component; test task scheduling; trunking communication},
	keywords = {Automation; Balancing; Load testing; Multitasking; Network architecture; Scheduling algorithms; Automated test solutions; Efficient scheduling; General architectures; Load predictions; Performance tests; Static task scheduling; Test script languages; Trunking communication systems; Testing},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Othman202218,
	author = {Othman, Refat and Zein, Samer},
	title = {Test Case Auto-Generation for Web Applications: A Model-Based Approach},
	year = {2022},
	journal = {ISMSIT 2022 - 6th International Symposium on Multidisciplinary Studies and Innovative Technologies, Proceedings},
	pages = {18 – 25},
	doi = {10.1109/ISMSIT56059.2022.9932797},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85142807877&doi=10.1109%2fISMSIT56059.2022.9932797&partnerID=40&md5=de6ce1a6c8bf5d3afbcfb7c0687abdf3},
	abstract = {Web applications are prevalent and considered the mainstay of information systems for organizations. At the same time, web applications are getting more complex, costly for development, and testing. Employees, customers, and business partners rely on these information systems to accomplish their business processes and tasks. Accordingly, users of these web applications assume that these systems are error-free and reliable. Automation testing is imperative to assure regression testing, off-load repetitive tasks from test engineers, and keep the pace between test engineers and developers. Further, it can reveal defects to test engineers at early development stages when parts of the software are broken or changed. Automated tests save time because the case gives the ability to run test cases at night and free testers to perform other types of testing, such as exploratory tests. However, even when using a dedicated automation testing framework, building test cases can be a time-consuming task. In this paper, we provide a solution for generating test cases for web applications. We present a new model-based approach that automatically generates test cases for Selenium testing tool, utilizing Domain-Specific Visual Language (DSVL) and Domain-Specific Textual Language (DSTL). Proof of concept framework is implemented and evaluated to measure user satisfaction, efficiency, and effectiveness of our approach. Our framework, named MAJD, was evaluated through a case study, using 20 tester engineers and developers from the industry with different experience levels. The results show that our framework is efficient and usable.  © 2022 IEEE.},
	author_keywords = {Domain-Specific Languages; Model-based testing; Software Testing; test case generation},
	keywords = {Ability testing; Application programs; Automation; Engineers; Graphical user interfaces; Information systems; Information use; Model checking; Problem oriented languages; Visual languages; Automation testing; Domains specific languages; Model based approach; Model based testing; Software testings; Test case; Test case generation; Test engineers; WEB application; Web applications; Software testing},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1}
}

@ARTICLE{Crapo2013215,
	author = {Crapo, Andrew and Moitra, Abha},
	title = {TOWARD A UNIFIED ENGLISH-LIKE REPRESENTATION of SEMANTIC MODELS, DATA, and GRAPH PATTERNS for SUBJECT MATTER EXPERTS},
	year = {2013},
	journal = {International Journal of Semantic Computing},
	volume = {7},
	number = {3},
	pages = {215 – 236},
	doi = {10.1142/S1793351X13500025},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84979072313&doi=10.1142%2fS1793351X13500025&partnerID=40&md5=d3fa8959aa767deb824b345f36de8c0a},
	abstract = {The Semantic Application Design Language (SADL) combines advances in standardized declarative modeling languages based on formal logic with advances in domain-specific language (DSL) development environments to create a controlled-English language that translates directly into the Web Ontology Language (OWL), the SPARQL graph query language, and a compatible if/then rule language. Models in the SADL language can be authored, tested, and maintained in an Eclipse-based integrated development environment (IDE). This environment offers semantic highlighting, statement completion, expression templates, hyperlinking of concepts to their definition, model validation, automatic error correction, and other advanced authoring features to enhance the ease and productivity of the modeling environment. In addition, the SADL language offers the ability to build in validation tests and test suites that can be used for regression testing. Through common Eclipse functionality, the models can be easily placed under source code control, versioned, and managed throughout the life of the model. Differences between versions can be compared side-by-side. Finally, the SADL-IDE offers an explanation capability that is useful in understanding what was inferred by the reasoner/rule engine and why those conclusions were reached. Perhaps more importantly, explanation is available of why an expected inference failed to occur. The objective of the language and the IDE is to enable domain experts to play a more active and productive role in capturing their knowledge and making it available as computable artifacts useful for automation where appropriate and for decision support systems in applications that benefit from a collaborative human-computer approach. SADL is built entirely on open source code and most of SADL is itself released to open source. This paper explores the concepts behind the language and provides details and examples of the authoring and model lifecycle support facilities. © 2013 World Scientific Publishing Company.},
	author_keywords = {Controlled English; graph pattern; ontology; OWL; semantic model},
	keywords = {Ability testing; Artificial intelligence; Birds; Computability and decidability; Decision support systems; Error correction; Integrodifferential equations; Life cycle; Ontology; Open source software; Open systems; Problem oriented languages; Query languages; Semantics; Software testing; Controlled English; Development environment; Domain specific languages; Graph patterns; Integrated development environment; Semantic Model; Subject matter experts; Web ontology language; Modeling languages},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 45}
}

@CONFERENCE{Bergsmann202412,
	author = {Bergsmann, Severin and Schmidt, Alexander and Fischer, Stefan and Ramler, Rudolf},
	title = {First Experiments on Automated Execution of Gherkin Test Specifications with Collaborating LLM Agents},
	year = {2024},
	journal = {A-TEST 2024 - Proceedings of the 15th ACM International Workshop on Automating Test Case Design, Selection and Evaluation, Co-located with: SSTA 2024},
	pages = {12 – 15},
	doi = {10.1145/3678719.3685692},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85207104093&doi=10.1145%2f3678719.3685692&partnerID=40&md5=df97e205cfe4a673567794d4607cfccc},
	abstract = {Gherkin is a domain-specific language for describing test scenarios in natural language, which are the basis for automated acceptance testing. The emergence of Large Language Models (LLMs) has opened up new possibilities for processing such test specifications and for generating executable test code. This paper investigates the feasibility of employing LLMs to execute Gherkin test specifications utilizing the AutoGen multi-agent framework. Our findings show that our LLM agent system is able to automatically run the given test scenarios by autonomously exploring the system under test, generating executable test code on the fly, and evaluating execution results. We observed high success rates for executing simple as well as more complex test scenarios, but we also identified difficulties regarding failure scenarios and fault detection. © 2024 Copyright held by the owner/author(s).},
	author_keywords = {Domain Specific Language; LLMs; Test Automation},
	keywords = {Autonomous agents; Intelligent agents; Model checking; Specification languages; Domains specific languages; Executables; Language model; Large language model; Model agents; Natural languages; Test Automation; Test code; Test scenario; Test specifications; Acceptance tests},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1}
}

@CONFERENCE{Felicio2023537,
	author = {Felicio, Duarte and Simao, Jose and Datia, Nuno},
	title = {Rapitest: Continuous black-box testing of restful web apis},
	year = {2023},
	journal = {Procedia Computer Science},
	volume = {219},
	pages = {537 – 545},
	doi = {10.1016/j.procs.2023.01.322},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85164265482&doi=10.1016%2fj.procs.2023.01.322&partnerID=40&md5=f7e5e32d823426adfeadc822f69ede44},
	abstract = {When it comes to web services, RESTful web APIs have become the de facto standard since 2000. Those APIs expose back-end data, so it is crucial that they are robust, secure, and reliable to keep sensitive data protected. Although existing tools for automating APIs test case generation have shown significant potential, they are limited in their applicability since they focus solely on random inputs through fuzzing. Using only API specifications, it is impractical to describe personalized and specific test case workflows. This paper introduces RapiTest, an open-source continuous black-box testing application for RESTful web APIs. It takes advantage of the API specification to automatically generate tests, but also makes use of a new DSL named Test Specification Language (TSL), to create rich test cases. The RapiTest web application allows the setup of several predefined verifications, regarding security and correctness of the responses, while running the tests at regular intervals, such as every 24 hours. In this way, the API can be monitored continuously to ensure it is running correctly.  © 2023 The Authors. Published by Elsevier B.V.},
	author_keywords = {API; Black-box Testing; DSL; Reliability; REST; System Integration; Web Application},
	keywords = {Application programming interfaces (API); Integration testing; Reliability; Sensitive data; Specifications; Web services; API; API specifications; De facto standard; REST; System integration; Test case; Web apis; WEB application; Web applications; Webs services; Black-box testing},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 6; All Open Access, Gold Open Access}
}

@CONFERENCE{Poncelet20151759,
	author = {Poncelet, Clément and Jacquemard, Florent},
	title = {Model based testing of an interactive music system},
	year = {2015},
	journal = {Proceedings of the ACM Symposium on Applied Computing},
	volume = {13-17-April-2015},
	pages = {1759 – 1764},
	doi = {10.1145/2695664.2695804},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84955496249&doi=10.1145%2f2695664.2695804&partnerID=40&md5=a00d9e874cc02eefa7097d0df6d69b47},
	abstract = {The role of an interactive music system (IMS) is to accompany musicians during live performances, like a real musician. It reacts in realtime to audio signals from musicians, according to a timed specification called mixed score, written in a domain specific language. Such goals imply strong requirements of temporal reliability and robustness to unforeseen errors in input, yet not so much studied in the computer music community. We present the application of model-based testing techniques and tools to a state-of-the-art IMS, including the following tasks: generation of relevant input data for testing (including timing values) following coverage criteria, computation of the corresponding expected output, according to the semantics of a given mixed score, black-box execution of the test data and verdict. Our method is based on formal models compiled directly from mixed scores, and passed, after conversion to timed automata, to the model-checker Uppaal. This fully automatic approach has been applied to real mixed scores used in concerts and the results obtained have permitted to identify bugs in the target IMS. Copyright 2015 ACM.},
	author_keywords = {Computer music domain specific languages; Interactive music systems; Model based testing; Realtime systems; Timed automata},
	keywords = {Automata theory; Black-box testing; Computational linguistics; Computer music; Computer programming languages; Graphical user interfaces; Problem oriented languages; Real time systems; Semantics; Automatic approaches; Coverage criteria; Domain specific languages; Interactive music systems; Model based testing; State of the art; Temporal reliability; Timed Automata; Model checking},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 5; All Open Access, Green Open Access}
}

@ARTICLE{20161,
	title = {16th International Symposium on Trends in Functional Programming, TFP 2015},
	year = {2016},
	journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
	volume = {9547},
	pages = {1 – 156},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84978701156&partnerID=40&md5=630b3015b0a82b152ed973383152d937},
	abstract = {The proceedings contain 8 papers. The special focus in this conference is on Trends in Functional Programming. The topics include: lightweight higher-order rewriting in haskell; towards a theory of reach; functional testing of java programs; type class instances for type-level lambdas in haskell; on the role of slicing in functional data-flow programming; a shallow embedded type safe extendable DSL for the arduino and programmable signatures and termination proofs for recursive functions in FoCaLiZe.},
	type = {Conference review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{2012,
	title = {Modelling Foundations and Applications - 8th European Conference, ECMFA 2012, Proceedings},
	year = {2012},
	journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
	volume = {7349 LNCS},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84864064431&partnerID=40&md5=d47a39e66a5c67e0c272e4c3e5157203},
	abstract = {The proceedings contain 30 papers. The topics discussed include: executable UML: from multi-domain to multi-core; models meeting automotive design challenges; a commutative model composition operator to support software adaptation; comparative study of model-based and multi-domain system engineering approaches for industrial settings; strengthening SAT-based validation of UML/OCL models by representing collections as relations; model interchange testing: a process and a case study; an internal domain-specific language for constructing OPC UA queries and event filters; combining UML sequence and state machine diagrams for data-flow based integration testing; model transformations for migrating legacy models: an industrial case study; derived features for EMF by integrating advanced model queries; a lightweight approach for managing XML documents with MDE languages; and bridging the gap between requirements and aspect state machines to support non-functional testing: industrial case studies.},
	type = {Conference review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{2009,
	title = {Proceedings of EuroPLoP 2009 - 14th Annual European Conference on Pattern Languages of Programming},
	year = {2009},
	journal = {Proceedings of EuroPLoP 2009 - 14th Annual European Conference on Pattern Languages of Programming},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84865211969&partnerID=40&md5=3e4e738b74f93ed5406f7903066944c5},
	abstract = {The proceedings contain 32 papers. The topics discussed include: enterprise architecture management patterns for enterprise architecture visioning; roles in a software project; applied pattern for strategy management for technology entrepreneurship and innovation MSc program; performance of open source projects; the role of analysis patterns in systems analysis; applying architectural patterns for parallel programming: solving the one-dimensional heat equation; towards formalized adaptation patterns for adaptive interactive systems; a pattern driven approach against architectural knowledge vaporization; reusable architectural decisions for DSL design: foundational decisions in DSL projects; a pattern vocabulary for project distribution; business patterns for knowledge audit implementation; applying distributed development patterns; and a pattern language of black-box test design for reactive software systems.},
	type = {Conference review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Gu2025963,
	author = {Gu, Yin and Zhang, Kai and Liu, Qi and Yu, Runlong and Lin, Xin and Sun, Xinjie},
	title = {ProCC: Programmatic Reinforcement Learning for Efficient and Transparent TCP Congestion Control},
	year = {2025},
	journal = {WSDM 2025 - Proceedings of the 18th ACM International Conference on Web Search and Data Mining},
	pages = {963 – 972},
	doi = {10.1145/3701551.3703585},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-105001673714&doi=10.1145%2f3701551.3703585&partnerID=40&md5=6d343e8b42e91f3e41bb0dc2b881826b},
	abstract = {Transmission Control Protocol (TCP) congestion control is a fundamental mechanism in the Internet that maintains network stability and performance by adjusting the sending rate of connections. Recently, Deep Reinforcement Learning (DRL) methods have shown superior performance over traditional expert-designed solutions. However, the DRL policies are often represented by black-box neural networks, they lack interpretability, making verification challenging and requiring excessive floating-point computation. This work introduces a novel approach, Programmatic reinforcement learning for Congestion Control (ProCC), designed to discover a program as a control policy from scratch autonomously. Programs in ProCC include branching structures (e.g., if blocks and if-else blocks), conditions and actions. However, directly optimizing such program structures is challenging due to their discrete non-differentiable nature, and the program space grows exponentially as the depth increases. To address this issue, ProCC defines a Domain-Specific Language (DSL) and program transformation rules, enabling the construction of a program search graph where similar programs are closer in proximity. Subsequently, ProCC employs Monte Carlo Tree Search (MCTS) to efficiently explore the discrete space and obtain promising programs. Extensive experiments conducted in multiple simulated environments demonstrate that ProCC is adaptive and consistently performs well under varying network conditions. The learned program's performance surpasses that of state-of-the-art DRL agents, and more importantly, the generated policies are concise, transparent, and computationally efficient. © 2025 Copyright held by the owner/author(s).},
	author_keywords = {Programmatic Reinforcement Learning; TCP Congestion Control},
	keywords = {Autonomous agents; Black-box testing; Deep neural networks; Deep reinforcement learning; Digital subscriber lines; Problem oriented languages; Reinforcement learning; Trees (mathematics); Control protocols; Fundamental mechanisms; Network stability; Performance; Programmatic reinforcement learning; Programmatics; Reinforcement learnings; Transmission control; Transmission control protocol congestion control; Transparent transmission; Congestion control (communication)},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1}
}

@CONFERENCE{Häser2016,
	author = {Häser, Florian and Felderer, Michael and Breu, Ruth},
	title = {An integrated tool environment for experimentation in domain specific language engineering},
	year = {2016},
	journal = {ACM International Conference Proceeding Series},
	volume = {01-03-June-2016},
	doi = {10.1145/2915970.2916010},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84978496761&doi=10.1145%2f2915970.2916010&partnerID=40&md5=759eb12218bda8990778c15d174a8bb4},
	abstract = {Domain specific languages (DSLs) are widely used in practice and investigated in software engineering research. But so far, language workbenches do not provide sufficient builtin decision support for language design and improvement. Controlled experiments have the potential to provide appropriate, data-driven decision support for language engineers and researchers to compare different language features with evidence-based feedback. This paper provides an integrated end-to-end tool environment to perform controlled experiments in DSL engineering. The experiment environment is built on the basis and integrated into the language workbench Meta Programming System (MPS). The environment not only supports language design but also all steps of experimentation, i.e., planning, operation, analysis & interpretation, as well as presentation & package. The tool environment is presented by means of a running example experiment comparing the time taken to create system acceptance tests for web applications in two different DSLs. © 2016 ACM.},
	author_keywords = {Controlled experiment; Domain Specific Languages (DSLs); Empirical evaluation; Experimentation; Language engineering; Meta Programming System (MPS); Tool support},
	keywords = {Acceptance tests; Computer programming languages; Decision support systems; Graphical user interfaces; Problem oriented languages; Software engineering; Controlled experiment; Domain specific languages; Empirical evaluations; Experimentation; Language engineering; Meta Programming; Tool support; Computational linguistics},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 11}
}

@ARTICLE{López-Fernández2016104,
	author = {López-Fernández, Jesús J. and Guerra, Esther and de Lara, Juan},
	title = {Combining unit and specification-based testing for meta-model validation and verification},
	year = {2016},
	journal = {Information Systems},
	volume = {62},
	pages = {104 – 135},
	doi = {10.1016/j.is.2016.06.008},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84994525407&doi=10.1016%2fj.is.2016.06.008&partnerID=40&md5=7772fd714a0e7e19439e5c522439e791},
	abstract = {Meta-models play a cornerstone role in Model-Driven Engineering as they are used to define the abstract syntax of modelling languages, and so models and all sorts of model transformations depend on them. However, there are scarce tools and methods supporting their Validation and Verification (V&V), which are essential activities for the proper engineering of meta-models. In order to fill this gap, we propose two complementary meta-model V&V languages. The first one has similar philosophy to the xUnit framework, as it enables the definition of meta-model unit test suites comprising model fragments and assertions on their (in-)correctness. The second one is directed to express and verify expected properties of a meta-model, including domain and design properties, quality criteria and platform-specific requirements. As a proof of concept, we have developed tooling for both languages in the Eclipse platform, and illustrate its use within an example-driven approach for meta-model construction. The expressiveness of our languages is demonstrated by their application to build a library of meta-model quality issues, which has been evaluated over the ATL zoo of meta-models and some OMG specifications. The results show that integrated support for meta-model V&V (as the one we propose here) is urgently needed in meta-modelling environments. © 2016 Elsevier Ltd},
	author_keywords = {Domain-specific modelling languages; Meta-model quality; Meta-modelling; Model-driven engineering; Validation & verification},
	keywords = {Software testing; Specifications; Domain-Specific Modelling Languages; Integrated supports; Meta model; Meta-modelling; Model transformation; Model-driven Engineering; Specification Based Testing; Validation and verification; Modeling languages},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 13}
}

@ARTICLE{Häser201652,
	author = {Häser, Florian and Felderer, Michael and Breu, Ruth},
	title = {Is business domain language support beneficial for creating test case specifications: A controlled experiment},
	year = {2016},
	journal = {Information and Software Technology},
	volume = {79},
	pages = {52 – 62},
	doi = {10.1016/j.infsof.2016.07.001},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84990036753&doi=10.1016%2fj.infsof.2016.07.001&partnerID=40&md5=23042425f7a84d0ada295d7b9e0547d3},
	abstract = {Context: Behavior Driven Development (BDD), widely used in modern software development, enables easy creation of acceptance test case specifications and serves as a communication basis between business- and technical-oriented stakeholders. BDD is largely facilitated through simple domain specific languages (DSL) and usually restricted to technical test domain concepts. Integrating business domain concepts to implement a ubiquitous language for all members of the development team is an appealing test language improvement issue. But the integration of business domain concepts into BDD toolkits has so far not been investigated. Objective: The objective of the study presented in this paper is to examine whether supporting the ubiquitous language features inside a DSL, by extending a DSL with business domain concepts, is beneficial over using a DSL without those concepts. In the context of the study, benefit is measured in terms of perceived quality, creation time and length of the created test case specifications. In addition, we analyze if participants feel supported when using predefined business domain concepts. Method: We investigate the creation of test case specifications, similar to BDD, in a controlled student experiment performed with graduate students based on a novel platform for DSL experimentation. The experiment was carried out by two groups, each solving a similar comparable test case, one with the simple DSL, the other one with the DSL that includes business domain concepts. A crossover design was chosen for evaluating the perceived quality of the resulting specifications. Results: Our experiment indicates that a business domain aware language allows significant faster creation of documents without lowering the perceived quality. Subjects felt better supported by the DSL with business concepts. Conclusion: Based on our findings we propose that existing BDD toolkits could be further improved by integrating business domain concepts. © 2016 Elsevier B.V.},
	author_keywords = {Behavior driven development; Controlled experiment; Domain Specific Languages (DSL); Software testing; Student experiment},
	keywords = {Boolean functions; Computer programming languages; Problem oriented languages; Software design; Software testing; Specifications; Students; Testing; Behavior driven development; Controlled experiment; Development teams; Domain specific languages; Language features; Perceived quality; Student experiments; Test case specifications; Acceptance tests},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 21}
}

@ARTICLE{20161,
	title = {15th International Conference on Software Reuse, ICSR 2016},
	year = {2016},
	journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
	volume = {9679},
	pages = {1 – 411},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84977492303&partnerID=40&md5=347f932969ae9dfb1c178ad3143fa5af},
	abstract = {The proceedings contain 29 papers. The special focus in this conference is on Software Product Lines, Business Aspects of Software Reuse, Component-Based Reuse, Reuse-Based Software Engineering and Software Reuse Tools. The topics include: Applying incremental model slicing to product-line regression testing; automated composition of service mashups through software product line engineering; feature location in model-based software product lines through a genetic algorithm; carrying ideas from knowledge-based configuration to software product lines; a method to support the adoption of reuse technology in large software organizations; a practical use case modeling approach to specify crosscutting concerns; an approach for prioritizing software features based on node centrality in probability network; rage reusable game software components and their integration into serious game engines; reusable secure connectors for secure software architecture; concept-based engineering of situation-specific migration methods; leveraging feature location to extract the clone-and-own relationships of a family of software products; an architecture to improve software reuse; pragmatic software reuse in bioinformatics; feature location benchmark for software families using eclipse community releases; java extensions for design pattern instantiation; towards a semantic search engine for open source software; detecting similar programs via the weisfeiler-leman graph kernel; a semi automatic maintenance of OCL constraints; reverse-engineering reusable language modules from legacy domain-specific languages; a framework for enhancing the retrieval of UML diagrams; a tool for analyzing and extracting specification clones in DSLS and a tool to support decision making for component reuse through profiling with ontologies.},
	type = {Conference review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Prasetya2011,
	author = {Prasetya, I.S.W.B. and Amorim, J. and Vos, T.E.J. and Baars, A.},
	title = {Using Haskell to script combinatoric testing of web services},
	year = {2011},
	journal = {Proceedings of the 6th Iberian Conference on Information Systems and Technologies, CISTI 2011},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-80052440645&partnerID=40&md5=5cef5a3d5aadbdfa7acfc8a4db258387},
	abstract = {The Classification Tree Method (CTM) is a popular approach in functional testing as it allows the testers to systematically partition the input domain of an SUT, and specifies the combinations they want. We have implemented the approach as a small domain specific language (DSL) embedded in the functional language Haskell. Such an embedding leads to clean syntax and moreover we can natively access Haskell's full features. This paper will explain the approach, and how it is applied for testing Web Services. © 2011 AISTI.},
	author_keywords = {automated testing; combinatoric testing},
	keywords = {Combinatorial mathematics; Information systems; User interfaces; Automated testing; Classification tree method; combinatoric testing; Domain specific languages; Functional languages; Functional testing; Haskell; Web services},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1}
}

@CONFERENCE{Gatherer2024,
	author = {Gatherer, Alan and Sengupta, Chaitali and Sen, Sudipta and Reed, Jeffery H.},
	title = {Directed Testing of ORAN using a Partially Specified Declarative Digital Twin},
	year = {2024},
	journal = {IEEE Vehicular Technology Conference},
	doi = {10.1109/VTC2024-Fall63153.2024.10758052},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85213046590&doi=10.1109%2fVTC2024-Fall63153.2024.10758052&partnerID=40&md5=75b618e4ff6eedfdbb5e682dfaa58496},
	abstract = {Real Time performance testing can be divided into two distinct parts: system test and algorithm test. System test checks that the right functions operate on the right data within power, latency, and other constraints under all conditions. Major RAN OEMs, put as much effort into system test and debug as they do into algorithm test, to ensure a competitive product. An algorithm tester will provide little insight into real time and hardware-software (HW-SW) capacity as it is unaware of the system implementation. In this paper we present an innovative Digital Twin technology, which we call Declarative Digital Twin (DDT). A DDT can describe the system requirements of the RAN such that critical corner cases can be found via automation, that would normally be missed by conventional testing. This is possible even when the RAN requirements are only partially specified. We present a Domain Specific Language (DSL) for declarative description of the RAN and show results from an automated solver that demonstrate how potential HW-SW implementation related corner cases can be identified from the DDT of an ORAN DU. © 2024 IEEE.},
	author_keywords = {5G; 6G; Automation; DSL; Functional Testing; O-RAN; Open RAN; RAN construction; Software Defined Radio},
	keywords = {5G mobile communication systems; Computer debugging; Computer hardware description languages; Digital storage; Digital subscriber lines; Problem oriented languages; Program debugging; 5g; 6g; Domains specific languages; Functional testing; Hardware/software; O-RAN; Open RAN; RAN construction; Software-defined radios; System test; Software testing},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; All Open Access, Green Open Access}
}

@CONFERENCE{Zanin2020,
	author = {Zanin, Aline and Zorzo, Avelino Fracisco and Nunes, Henry Cabral},
	title = {Model-based testing in agile projects: An approach based on domain-specific languages},
	year = {2020},
	journal = {23rd Iberoamerican Conference on Software Engineering, CIbSE 2020},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85092302559&partnerID=40&md5=7dce86b1a8e65a1e3c4090373feca4da},
	abstract = {Model-Based Testing (MBT) can bring several benefits to software quality. However, generally, MBT is applied in traditional software development lifecycle models, with few studies exploring its application in agile software development context. Hence, usually, agile development teams (AT) do not benefit from the advantages that the MBT technique provides, for example, reuse of artifacts and traceability between requirements and test artifacts. Thus, this article presents an approach for applying MBT in agile software development teams. This approach is based on the use of a semi-natural language to write scenarios for the automatic generation of models and test scripts. To exemplify the application of this approach, we also present a Domain-Specific Language (DSL) called Aquila, in which new functional test related keywords are added to the Gherkin DSL. We also present, based on a literature review, the majors challenges and difficulties of applying MBT in AT. To validate the proposed approach a Focus Group study was used. © CIbSE 2020.},
	author_keywords = {Agile; DSL; MBT; Software Testing},
	keywords = {Application programs; Computer software selection and evaluation; Digital subscriber lines; Life cycle; Model checking; Natural language processing systems; Problem oriented languages; Software quality; Software testing; Agile development; Agile software development; Automatic Generation; Domain specific languages; Focus group studies; Literature reviews; Model based testing; Software development life cycle; Software design},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Woskowski201262,
	author = {Woskowski, Christoph},
	title = {Applying industrial-strength testing techniques to critical care medical equipment},
	year = {2012},
	journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
	volume = {7612 LNCS},
	pages = {62 – 73},
	doi = {10.1007/978-3-642-33678-2_6},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84867588659&doi=10.1007%2f978-3-642-33678-2_6&partnerID=40&md5=56dc43ec05802ce8928510e60a23002c},
	abstract = {Hardware and software development of embedded systems interdependently gear into each other. Even more so if the device under development is intended for use in critical care facilities such as intensive care units. Especially in this case, safety measures and risk mitigation techniques are implemented using both hardware and software components. Thus applying hardware and software testing approaches in combination is inevitable as well. The increasing utilization of test domain-specific languages (Test DSLs), code generators and keyword-driven interpreters tends to raise the level of abstraction in test development. This approach aims to enhance productivity by generating executable tests from a non-programming language created for describing test cases. A second goal is to increase coverage by generating tests for as many as possible combinations of input values (black box test) or for all reasonable paths of a program flow (white box test). In combination with hardware-supported signal generation and fault injection this can be a very powerful strategy for testing safety-critical embedded devices. This article introduces an example of this strategy - the usage of a keyword-driven testing technique in cooperation with additional test hardware - in the context of an embedded medical device development, all the while emphasizing the benefit of combining different approaches. It discusses the utilization of commercial off-the-shelf (COTS) testing hardware as well as the application of an in-house developed test box. It also highlights the integration of commercial software - for requirements engineering, test management and continuous integration - with a self-developed testing framework powered by its own keyword-based test DSL. © 2012 Springer-Verlag.},
	author_keywords = {domainspecific language; embedded system; keyword-driven; medical device; safety-critical; testing hardware},
	keywords = {Biomedical equipment; Computer hardware; Embedded systems; Hardware; Intensive care units; Problem oriented languages; Safety engineering; Security of data; Signal generators; Black box test; Code generators; Commercial software; Commercial-off-the-shelf; Critical care; Domain specific languages; Embedded device; Fault injection; Hardware and software; Hardware and software components; Input values; keyword-driven; Level of abstraction; Medical Devices; Program flow; Risk mitigation; Safety measures; Safety-critical; Signal generation; Test case; Test development; Test management; Testing framework; Testing technique; White box; Software testing},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 5}
}

@CONFERENCE{Khorram2022109,
	author = {Khorram, Faezeh and Bousse, Erwan and Mottu, Jean-Marie and Sunyé, Gerson and Gómez-Abajo, Pablo and Cañizares, Pablo C. and Guerra, Esther and De Lara, Juan},
	title = {Automatic test amplification for executable models},
	year = {2022},
	journal = {Proceedings - 25th ACM/IEEE International Conference on Model Driven Engineering Languages and Systems, MODELS 2022},
	pages = {109 – 120},
	doi = {10.1145/3550355.3552451},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85141851957&doi=10.1145%2f3550355.3552451&partnerID=40&md5=9b72aa3f49b9c76724c4b098d4b29466},
	abstract = {Behavioral models are important assets that must be thoroughly verified early in the design process. This can be achieved with manually-written test cases that embed carefully hand-picked domain-specific input data. However, such test cases may not always reach the desired level of quality, such as high coverage or being able to localize faults efficiently. Test amplification is an interesting emergent approach to improve a test suite by automatically generating new test cases out of existing manually-written ones. Yet, while ad-hoc test amplification solutions have been proposed for a few programming languages, no solution currently exists for amplifying the test cases of behavioral models. In this paper, we fill this gap with an automated and generic approach. Given an executable DSL, a conforming behavioral model, and an existing test suite, our approach generates new regression test cases in three steps: (i) generating new test inputs by applying a set of generic modifiers on the existing test inputs; (ii) running the model under test with new inputs and generating assertions from the execution traces; and (iii) selecting the new test cases that increase the mutation score. We provide tool support for the approach atop the Eclipse GEMOC Studio1 and show its applicability in an empirical study. In the experiment, we applied the approach to 71 test suites written for models conforming to two different DSLs, and for 67 of the 71 cases, it successfully improved the mutation score between 3.17% and 54.11% depending on the initial setup. © 2022 ACM.},
	author_keywords = {executable DSL; executable model; regression testing; test amplification},
	keywords = {Behavioral research; Digital subscriber lines; Behavioral model; Design-process; Executable DSL; Executable modeling; Executables; Mutation score; Regression testing; Test amplifications; Test case; Test inputs; Software testing},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 4; All Open Access, Green Open Access}
}

@CONFERENCE{Caniço2024,
	author = {Caniço, Afonso B. and Santos, André L.},
	title = {A Domain-Specific Language for Dynamic White-Box Evaluation of Java Assignments},
	year = {2024},
	journal = {OpenAccess Series in Informatics},
	volume = {122},
	doi = {10.4230/OASIcs.ICPEC.2024.2},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85205700285&doi=10.4230%2fOASIcs.ICPEC.2024.2&partnerID=40&md5=0670e0e20a6aa8d2569a4f3dc85c115e},
	abstract = {Programming exercises involving algorithms typically involve time and spatial constraints. Automated assessments for such implementations are often carried out in a black-box manner or through static analysis of the code, without considering the internal execution properties, which could lead to falsely positive evaluations of students' solutions. We present Witter, a domain-specific language for defining white-box test cases for the Java language. We evaluated programming assignment submissions from a Data Structures and Algorithms course against Witter's test cases to determine if our approach could offer additional insight regarding incomplete algorithmic behaviour requirements. We found that a significant amount of student solutions fail to meet the desired algorithmic behavior (approx. 21%), despite passing black-box tests. Hence, we conclude that white-box tests are useful to achieve a thorough automated evaluation of this kind of exercises. © Afonso B. Caniço and André L. Santos;},
	author_keywords = {programming education; student assessment; White-box assessment},
	keywords = {Black-box testing; Curricula; Program debugging; Students; Algorithmics; Domains specific languages; Programming education; Programming exercise; Spatial constraints; Student assessment; Test case; Time constraints; White box; White-box assessment; Java programming language},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Malchaire1998270,
	author = {Malchaire, J. and Rodriguez Diaz, L.S. and Piette, A. and Gonçalves Amaral, F. and De Schaetzen, D.},
	title = {Neurological and functional effects of short-term exposure to hand-arm vibration},
	year = {1998},
	journal = {International Archives of Occupational and Environmental Health},
	volume = {71},
	number = {4},
	pages = {270 – 276},
	doi = {10.1007/s004200050280},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-0031747645&doi=10.1007%2fs004200050280&partnerID=40&md5=fe914fe0f553b0bb4dff0dbfd14d9d93},
	abstract = {Objective: The aim of the present study was to quantify the sensory and functional effects resulting from a short duration (30 min) exposure to hand-arm vibration. Subjects and methods: Nine subjects went through nine laboratory experiments. For 32 min they grasped a handle vibrating at three different amplitudes (5, 20, and 80 ms-2) and at three frequencies (31.5, 125, and 500 Hz). Additionally, a reference experiment was conducted in which the handle did not vibrate. Three sensory tests [vibration perception threshold (VPT), pressure perception threshold (PPT), and distal sensory latency time (DSL)], two functional tests [Purdue pegboard (PPB) and maximal voluntary force (MVF)], and a questionnaire concerning the perceived paresthesia and numbness were completed before, during, and after exposure. Results: A 32-min period of exposure to vibration leads to a temporary threshold shift (TTS) of the VPT and to the development of paresthesia and numbness. The VPT appears to vary with the exposure duration according to a first-order model with a time constant about equal to 3 min. The TTS increases with the vibration acceleration amplitude and is greater for an exposure frequency of 125 Hz than for that of 31.5 or 500 Hz. It is also greater at the test frequency 125 Hz than at 31.5 Hz. The other tests do not demonstrate any significant variation. In particular, the PPB test does not demonstrate any loss of dexterity. Conclusion: After some 30 min of exposure to vibration the VPTs are increased and paresthesia and numbness develop. However, these do not appear to influence significantly the capacity or performance at work.},
	author_keywords = {Dexterity; Vibration perception threshold; Work performance},
	keywords = {Adult; Arm; Hand; Hand Strength; Humans; Male; Mechanoreceptors; Median Nerve; Motor Skills; Neurologic Examination; Occupational Exposure; Paresthesia; Reaction Time; Sensory Thresholds; Vibration; adult; arm; article; controlled study; function test; hand; human; human experiment; job performance; latent period; male; mechanoreceptor; model; normal human; paresthesia; perceptive threshold; questionnaire; sensory stimulation; vibration sense; work capacity},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 31}
}

@CONFERENCE{Talby2009154,
	author = {Talby, David},
	title = {The perceived value of authoring and automating acceptance tests using a model driven development toolset},
	year = {2009},
	journal = {Proceedings of the 2009 ICSE Workshop on Automation of Software Test, AST 2009},
	pages = {154 – 157},
	doi = {10.1109/IWAST.2009.5069055},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-70349673934&doi=10.1109%2fIWAST.2009.5069055&partnerID=40&md5=48d78d31c56c55d68b8be3f60af589cb},
	abstract = {One approach to applying keyword driven testing in a model-driven development environment is by defining a domain specific language for test cases. The toolset then provides test editors, versioning, validation, reporting and hyperlinks across models - in addition to enabling automated test execution. This case study evaluates the effectiveness of such a solution as perceived by two teams of professional testers, who used it to test several products over a two year period. The results suggest that in addition to the expected benefits of automation, the solution reduces the time and effort required to write tests, maintain tests and plan the test authoring and execution efforts - at the expense of requiring longer training and a higher bar for recruiting testers.},
	keywords = {Automation; Computer software; Hypertext systems; Acceptance tests; Automated test; Domain specific languages; Hyperlinks; Keyword driven; Model driven development; Perceived value; Test case; Toolsets; Versioning; Testing},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1}
}

@ARTICLE{Dragoi2024100,
	author = {Dragoi, Cezara and Nagendra, Srinidhi and Srivas, Mandayam},
	title = {A Domain Specific Language for Testing Distributed Protocol Implementations},
	year = {2024},
	journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
	volume = {14783 LNCS},
	pages = {100 – 117},
	doi = {10.1007/978-3-031-67321-4_6},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85202594655&doi=10.1007%2f978-3-031-67321-4_6&partnerID=40&md5=40b72b7fadf22869dba8ed810774e0f5},
	abstract = {Large-scale, fault-tolerant, distributed systems are the backbone for many critical software services. Since they must execute correctly in a possibly adversarial environment with arbitrary communication delays and failures, the underlying algorithms are intricate. In particular, achieving consistency and data retention relies on intricate consensus (state machine replication) protocols. Ensuring the reliability of implementations of such protocols remains a significant challenge because of the enormous number of exceptional conditions that may arise in production. We propose a methodology and a tool called Netrix for testing such implementations that aims to exploit programmer’s knowledge to improve coverage, enables robust bug reproduction, and can be used in regression testing across different versions of an implementation. As evaluation, we apply our tool to a popular proof of stake blockchain protocol, Tendermint, which relies on a Byzantine consensus algorithm, a benign consensus algorithm, Raft, and BFT-Smart. We were able to identify deviations of the implementation from the protocol specification and validate corrections on an updated implementation. Additionally, we were able to confirm the presence of known bugs in previous versions. © The Author(s), under exclusive license to Springer Nature Switzerland AG 2024.},
	keywords = {Adversarial environments; Arbitrary communication; Consensus algorithms; Critical software; Distributed protocols; Domains specific languages; Fault tolerant distributed systems; Large-scales; Protocol implementation; Software services; Software testing},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1}
}

@BOOK{Bhadani2019255,
	author = {Bhadani, Rahul and Bunting, Matt and Sprinkle, Jonathan},
	title = {Model-based engineering with application to autonomy},
	year = {2019},
	journal = {Complexity Challenges in Cyber Physical Systems: Using Modeling and Simulation (M&S) to Support Intelligence, Adaptation and Autonomy},
	pages = {255 – 285},
	doi = {10.1002/9781119552482.ch10},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85102234102&doi=10.1002%2f9781119552482.ch10&partnerID=40&md5=81c7ec4e755a04fa2b93798e642059ab},
	abstract = {In this chapter we focus on where models fit into the verification and validation design cycle of autonomous cyber-physical systems. These systems typically make decisions through myriad of sensing loops, have implementations in multiple languages, and may have their logic represented in several different kinds of formal models. The use of code generation, along with software-in-the-loop and hardware-in-the-loop simulation (discussed further in Section 10.4), permits system designers to apply various agile techniques for the validation and verification of systems as requirements are implemented, tested, and demonstrated. The work in this chapter explores such a design cycle with application to autonomous driving. Examples are given for the implementation of various components that describe vehicle dynamics, control models, system identification, sensor/data acquisition, etc., which can be functionally described in models, and explored in simulation before utilizing code generation to deploy final solutions. The integration of simulation tools during functional design, software-in-the-loop testing, and hardware-in-the-loop testing, permits regression evaluation of use case scenarios. In addition to functional testing, we also describe how high-level domain-specific models can be used to include verification-in-the-loop toolboxes as part of the design cycle. All the examples in this chapter are based on an autonomous Ford Escape, which has a Robotic Operating System (ROS) API for its control and the integration of autonomous components - however, the results are applicable to other event-based and time-triggered middleware platforms. The implementation models in use include Simulink, MATLAB, StateFlow, and other domain-specific languages that specify high-level behaviors. © 2020 John Wiley & Sons, Inc.},
	author_keywords = {Autonomous cyber-physical systems; Autonomous ground vehicle control; Integration testing; Model-based design techniques; Safety-critical systems; Self-driving cars},
	type = {Book chapter},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 2}
}

@CONFERENCE{Khan2024,
	author = {Khan, Shaheer and Lawler, Christopher and Nicholas, Austin and Ortiz, Luis and Mukherji, Shubhodeep and Nowicki, Robert and Redfield, Benjamin and Voskanian, Vicken and Mak, Carter and Ruderman, Evan and Mallamaci, Michael},
	title = {Psyche: Innovations in Development of Planning and Sequencing Systems},
	year = {2024},
	journal = {IEEE Aerospace Conference Proceedings},
	doi = {10.1109/AERO58975.2024.10521374},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85193833783&doi=10.1109%2fAERO58975.2024.10521374&partnerID=40&md5=d649b0b2f0e23fb33729df9f19b86c26},
	abstract = {NASA Jet Propulsion Laboratory's (JPL) mission Psyche will be the first of its kind in many ways: the first to explore a metal asteroid, the first to fly a Hall Effect Thruster (HET) in deep space, and the first to demonstrate Deep Space Optical Communication (DSOC). Challenges presented by firsts of these nature require powerful, yet agile ground and onboard systems to be addressed in a timely and effective manner. This paper examines the ways that innovations in Psyche's planning and sequencing systems address both common challenges faced by many missions and unique challenges arising from first ever-in-flight activities. Psyche will be the first mission to operate using JPL's new common core flight software Flight Core Product Line (FCPL) and make use of capabilities such as real-time telemetry reactivity, multi-level logic, and complex math operations which enable new levels of onboard autonomy. Augmentation of FCPL's new capabilities through a user-friendly abstraction layer in ground software, an effort undertaken in conjunction with NASA's Europa Clipper mission, enables even more complexity in reusable sequences, as well as streamlines and simplifies the ground operation and review process. The combination of increased onboard capability in the reusable sequences with Psyche's agile planning and scheduling ground software allows Psyche to quickly develop new solutions to complex problems and represents an advancement from the approach of previous missions. An example of one of these solutions that takes full advantage of ground and onboard capabilities is presented: a unique momentum management strategy that addresses the challenge of the "swirl torque"that arises from the use of HETs in space. In order to address the challenges of testing these advanced reusable sequences, Psyche developed a robust and comprehensive automated regression testing framework and an intelligent sequence branch analysis tool that enables quick and reliable reusable sequence re-testing against new Flight Rules and constraints that are identified, resulting in significant risk reduction and cost-saving over manual approaches taken by previous missions. Analysis of these tools will prove useful to future missions that develop blocks, reusable sequences, or other onboard behaviors. A multi-mission process to parse command dictionaries into a set of Python command classes allows Psyche's sequencers to develop sequences directly in Python, a significant improvement over the previous approach of sequencing in Domain Specific Languages (DSLs) This approach of developing Python command classes provides the ability to develop sequences in any Integrated Development Environment of their choice, and results in significant cost savings by avoiding the need to develop sequence editing graphical interfaces, as have been developed for missions in the past. Benefits, drawbacks, and work to go for each of these innovations are discussed and lessons from Psyche's development phase are provided. © 2024 IEEE.},
	keywords = {Abstracting; Agile manufacturing systems; Computer aided software engineering; Computer software reusability; Earth (planet); Model checking; NASA; Cost saving; Deep space; Deep space optical communication; Ground software; Ground systems; Hall effect thrusters; Jet Propulsion Laboratory; NASA jet propulsion; Planning systems; Sequencing systems; Python},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1}
}

@CONFERENCE{López-Fernández2015101,
	author = {López-Fernández, Jesús J. and Guerra, Esther and De Lara, Juan},
	title = {Example-based validation of domain-specific visual languages},
	year = {2015},
	journal = {SLE 2015 - Proceedings of the 2015 ACM SIGPLAN International Conference on Software Language Engineering},
	pages = {101 – 112},
	doi = {10.1145/2814251.2814256},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84962488489&doi=10.1145%2f2814251.2814256&partnerID=40&md5=36d3928527316d731eacc396e7b281f9},
	abstract = {The definition of Domain-Specific Languages (DSLs) is a recurrent activity in Model-Driven Engineering. However, their construction is many times an ad-hoc proceb, partly due to the lack of tools enabling a proper engineering of DSLs and promoting domain experts to play an active role. The focus of this paper is on the validation of meta-models for visual DSLs. For this purpose, we propose a language and tool support for describing properties that in-stances of meta-models should (or should not) meet. Then, our system uses a model finder to produce example models, enriched with a graphical concrete syntax, that confirm or refute the abumptions of the meta-model developer. Our language complements metaBest, a framework for the validation and verification of meta-models that includes two other languages for unit testing and specification-based test-ing of meta-models. A salient feature of our approach is that it fosters interaction with domain experts by the use, proceb-ing and creation of informal drawings constructed in editors liked yED or Dia. We abeb the usefulneb of the approach in the validation of a DSL for house blueprints, with the par-Ticipation of 26 4th year computer science students. © 2015 ACM.},
	author_keywords = {Domain-Specific Visual Lan-guages; Meta-model Validation and Verification; Meta-modelling},
	keywords = {Computational linguistics; Computer programming languages; Problem oriented languages; Computer science students; Domain specific; Domain specific languages; Domain-specific visual language; Meta model; Meta-modelling; Model-driven Engineering; Validation and verification; Visual languages},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 6; All Open Access, Green Open Access}
}

@ARTICLE{Edwards2019277,
	author = {Edwards, James S. and Carvalho, I.S. and Felton, R. and Hogben, C. and Karkinsky, D. and Lomas, P.J. and McCullen, P.A. and Rimini, F.G. and Stephen, A.V.},
	title = {Robust configuration of the JET Real-Time Protection Sequencer},
	year = {2019},
	journal = {Fusion Engineering and Design},
	volume = {146},
	pages = {277 – 280},
	doi = {10.1016/j.fusengdes.2018.12.045},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85061085576&doi=10.1016%2fj.fusengdes.2018.12.045&partnerID=40&md5=911fd54e3884355d6740b603ff3d2338},
	abstract = {The JET Real-Time Protection Sequencer (RTPS) co-ordinates responses for magnetic and kinetic actuators to protect the ITER-Like Wall from possible melting events and other undesirable scenarios. It allows programmable stop responses per pulse, based on alarms raised by other systems. The architecture combines a modular run-time application developed using MARTe (Multithreaded Application Real-Time executor) with the top-level JET supervisory and configuration software, Level-1. Operational experience since 2011 drove a requirement to refactor the system in 2017, moving the maximum degree of functionality from compiled code to configuration data, providing more flexibility, maintainability and verifiability of action(s) to be taken during a pulse. This paper discusses the features of the architecture that made this clean separation of rule-based logic and real-time signal processing possible and practical, including how functions and interfaces between MARTe and Level-1 are organised. It also explains management of configuration data to address development, testing, commissioning and operations, each with individual ownership, responsibility and lifecycles. The core technology enabling this is the Level-1 domain specific language, able to manipulate, validate and load into plant configuration parameter sets. The language also enables implementation of advanced user interfaces, providing operators with the tools to focus on essentials tasks for their area of responsibility. It exemplifies this with recent verification and validation of the refactored protection system: unit/low-level integration tests defined by core developers and integration/behavioural tests defined by JET's Plasma Operations Group, respectively, ensuring robust and consistent behaviour. We show how the wide scope and power of this language has enabled evolution of JET operations efficiently and correctly over decades of operational experience. © 2019},
	author_keywords = {Configuration; Domain-specific language; Machine protection; Operations; Real-time framework; Software validation},
	keywords = {Magnetic actuators; Problem oriented languages; Signal processing; User interfaces; Configuration; Domain specific languages; Operations; Real time; Software validation; Application programs},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 4}
}

@ARTICLE{Oliveira2022,
	author = {Oliveira, Domingos F. and Gomes, João P. and Pereira, Ricardo B. and Brito, Miguel A. and Machado, Ricardo J.},
	title = {Development of a Self-diagnostic System Integrated into a Cyber-Physical System},
	year = {2022},
	journal = {Computers},
	volume = {11},
	number = {9},
	doi = {10.3390/computers11090131},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85138826836&doi=10.3390%2fcomputers11090131&partnerID=40&md5=ea93f5f613b55f3ea9eff46373499a26},
	abstract = {CONTROLAR provides Bosch with an intelligent functional testing machine used to test the correct functioning of the car radios produced. During this process, the radios are submitted to several tests, raising the problem of how the machine detects errors in several radios consecutively, making it impossible to know if the device has a problem since it has no module to see if it works correctly. This article arises from the need to find a solution to solve this problem, which was to develop a self-diagnostic system that will ensure the reliability and integrity of the cyber-physical system, passing a detailed state of the art. The development of this system was based on the design of an architecture that combines the KDT methodology with a DSL to manage and configure the tests to integrate the self-diagnostic test system into a CPS. A total of 28 test cases were performed to cover all its functionalities. The results show that all test cases passed. Therefore, the system meets all the proposed objectives. © 2022 by the authors.},
	author_keywords = {cyber-physical systems; self-diagnosis; test automation; web application},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 2; All Open Access, Gold Open Access, Green Open Access}
}