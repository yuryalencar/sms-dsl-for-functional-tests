@inproceedings{20244017133876 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2025 Elsevier Inc.},
copyright = {Compendex},
title = {Development of a Critical System Using a Domain Specific Language},
journal = {2024 IEEE Space, Aerospace and Defence Conference, SPACE 2024},
author = {Shrivastava, Ajita and Mitra, Arka Pratap and Dungdung, Vinita and Singh, Deep},
year = {2024},
pages = {56 - 60},
address = {Bangalore, India},
abstract = {<div data-language="eng" data-ev-field="abstract">For enhanced software modularity and maintainability, while meeting the exceedingly complex system requirements, a Domain Specific Language (DSL) was developed for the safety related computer system- Emergency Core Cooling System Test Facility, in a nuclear power station. This conception facilitated accurate development of test sequences directly by domain experts possessing limited familiarity with computer programming aspects. This unique DSL-based programming approach and exhaustive closed-loop black box testing enabled accurate tuning of variabilities, speedier software development, and ease of future modification. Considering the stringent atomic energy regulatory requirements, this also duly saved on development effort and software qualification timeline.<br/></div> © 2024 IEEE.},
key = {Nuclear power plants},
keywords = {Black-box testing;Nuclear energy;},
note = {Critical systems;Domains specific languages;Emergency Core Cooling System;Enhanced software;Power;Safety-Related;Software maintainability;Software modularity;System requirements;System test;},
URL = {http://dx.doi.org/10.1109/SPACE63117.2024.10667978},
} 


@inproceedings{20244117166978 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2025 Elsevier Inc.},
copyright = {Compendex},
title = {A Domain-Specific Language for Dynamic White-Box Evaluation of Java Assignments},
journal = {OpenAccess Series in Informatics},
author = {Canico, Afonso B. and Santos, Andre L.},
volume = {122},
year = {2024},
issn = {21906807},
address = {Lisbon, Portugal},
abstract = {<div data-language="eng" data-ev-field="abstract">Programming exercises involving algorithms typically involve time and spatial constraints. Automated assessments for such implementations are often carried out in a black-box manner or through static analysis of the code, without considering the internal execution properties, which could lead to falsely positive evaluations of students' solutions. We present Witter, a domain-specific language for defining white-box test cases for the Java language. We evaluated programming assignment submissions from a Data Structures and Algorithms course against Witter's test cases to determine if our approach could offer additional insight regarding incomplete algorithmic behaviour requirements. We found that a significant amount of student solutions fail to meet the desired algorithmic behavior (approx. 21%), despite passing black-box tests. Hence, we conclude that white-box tests are useful to achieve a thorough automated evaluation of this kind of exercises.<br/></div> © Afonso B. Caniço and André L. Santos;},
key = {Java programming language},
keywords = {Black-box testing;Curricula;Program debugging;Students;},
note = {Algorithmics;Domains specific languages;Programming education;Programming exercise;Spatial constraints;Student assessment;Test case;Time constraints;White box;White-box assessment;},
URL = {http://dx.doi.org/10.4230/OASIcs.ICPEC.2024.2},
} 


@inproceedings{20243616973267 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2025 Elsevier Inc.},
copyright = {Compendex},
title = {A Domain Specific Language for Testing Distributed Protocol Implementations},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
author = {Dragoi, Cezara and Nagendra, Srinidhi and Srivas, Mandayam},
volume = {14783 LNCS},
year = {2024},
pages = {100 - 117},
issn = {03029743},
address = {Rabat, Morocco},
abstract = {<div data-language="eng" data-ev-field="abstract">Large-scale, fault-tolerant, distributed systems are the backbone for many critical software services. Since they must execute correctly in a possibly adversarial environment with arbitrary communication delays and failures, the underlying algorithms are intricate. In particular, achieving consistency and data retention relies on intricate consensus (state machine replication) protocols. Ensuring the reliability of implementations of such protocols remains a significant challenge because of the enormous number of exceptional conditions that may arise in production. We propose a methodology and a tool called Netrix for testing such implementations that aims to exploit programmer’s knowledge to improve coverage, enables robust bug reproduction, and can be used in regression testing across different versions of an implementation. As evaluation, we apply our tool to a popular proof of stake blockchain protocol, Tendermint, which relies on a Byzantine consensus algorithm, a benign consensus algorithm, Raft, and BFT-Smart. We were able to identify deviations of the implementation from the protocol specification and validate corrections on an updated implementation. Additionally, we were able to confirm the presence of known bugs in previous versions.<br/></div> © The Author(s), under exclusive license to Springer Nature Switzerland AG 2024.},
key = {Software testing},
note = {Adversarial environments;Arbitrary communication;Consensus algorithms;Critical software;Distributed protocols;Domains specific languages;Fault tolerant distributed systems;Large-scales;Protocol implementation;Software services;},
URL = {http://dx.doi.org/10.1007/978-3-031-67321-4_6},
} 


@unpublished{20230088008 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2025 Elsevier Inc.},
copyright = {Compendex},
title = {A Domain Specific Language for Testing Consensus Implementations},
journal = {arXiv},
author = {Dragoi, Cezara and Enea, Constantin and Nagendra, Srinidhi and Srivas, Mandayam},
year = {2023},
issn = {23318422},
abstract = {<div data-language="eng" data-ev-field="abstract">Large-scale, fault-tolerant, distributed systems are the backbone for many critical software services. Since they must execute correctly in a possibly adversarial environment with arbitrary communication delays and failures, the underlying algorithms are intricate. In particular, achieving consistency and data retention relies on intricate consensus (state machine replication) protocols. Ensuring the reliability of implementations of such protocols remains a significant challenge because of the enormous number of exceptional conditions that may arise in production. We propose a methodology and a tool called Netrix for testing such implementations that aims to exploit programmer’s knowledge to improve coverage, enables robust bug reproduction, and can be used in regression testing across different versions of an implementation. As evaluation, we apply our tool to a popular proof of stake blockchain protocol, Tendermint, which relies on a Byzantine consensus algorithm, a benign consensus algorithm, Raft, and BFT-Smart. We were able to identify 4 deviations of the Tendermint implementation from the protocol specification and check their absence on an updated implementation. Additionally, we were able to reproduce 4 previously known bugs in Raft.<br/></div> © 2023, CC BY.},
key = {Blockchain},
keywords = {Cell proliferation;Problem oriented languages;Software testing;},
note = {Adversarial environments;Arbitrary communication;Block-chain;Consensus algorithms;Critical software;Distributed systems;Domains specific languages;Fault tolerant distributed systems;Large-scales;Software services;},
URL = {http://dx.doi.org/10.48550/arXiv.2303.05893},
} 


@inproceedings{20232814377784 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2025 Elsevier Inc.},
copyright = {Compendex},
title = {Rapitest: Continuous black-box testing of restful web apis},
journal = {Procedia Computer Science},
author = {Felicio, Duarte and Simao, Jose and Datia, Nuno},
volume = {219},
year = {2023},
pages = {537 - 545},
issn = {18770509},
address = {Lisbon, Portugal},
abstract = {<div data-language="eng" data-ev-field="abstract">When it comes to web services, RESTful web APIs have become the de facto standard since 2000. Those APIs expose back-end data, so it is crucial that they are robust, secure, and reliable to keep sensitive data protected. Although existing tools for automating APIs test case generation have shown significant potential, they are limited in their applicability since they focus solely on random inputs through fuzzing. Using only API specifications, it is impractical to describe personalized and specific test case workflows. This paper introduces RapiTest, an open-source continuous black-box testing application for RESTful web APIs. It takes advantage of the API specification to automatically generate tests, but also makes use of a new DSL named Test Specification Language (TSL), to create rich test cases. The RapiTest web application allows the setup of several predefined verifications, regarding security and correctness of the responses, while running the tests at regular intervals, such as every 24 hours. In this way, the API can be monitored continuously to ensure it is running correctly.<br/></div> © 2023 The Authors. Published by Elsevier B.V.},
key = {Black-box testing},
keywords = {Application programming interfaces (API);Integration testing;Reliability;Sensitive data;Specifications;Web services;},
note = {API;API specifications;De facto standard;REST;System integration;Test case;Web apis;WEB application;Web applications;Webs services;},
URL = {http://dx.doi.org/10.1016/j.procs.2023.01.322},
} 


@inproceedings{20154001337207 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2025 Elsevier Inc.},
copyright = {Compendex},
title = {Legend: An agile DSL toolset for web acceptance testing},
journal = {2014 International Symposium on Software Testing and Analysis, ISSTA 2014 - Proceedings},
author = {King, Tariq M. and Nunez, Gabriel and Santiago, Dionny and Cando, Adam and Mack, Cody},
year = {2014},
pages = {409 - 412},
address = {San Jose, CA, United states},
abstract = {<div data-language="eng" data-ev-field="abstract">Agile development emphasizes collaborations among customers, business analysts, domain experts, developers, and testers. However, the large scale and rapid pace of many agile projects presents challenges during testing activities. Large sets of test artifacts must be comprehensible and available to various stakeholders, traceable to requirements, and easily maintainable as the software evolves. In this paper we describe Legend, a toolset that leverages domain-specific language to streamline functional testing in agile projects. Some key features of the toolset include test template generation from user stories, model-based automation, test inventory synchronization, and centralized test tagging.<br/></div> Copyright 2014 ACM.},
key = {Software testing},
keywords = {Problem oriented languages;Digital subscriber lines;Acceptance tests;Graphical user interfaces;},
note = {Acceptance testing;Agile development;Behavior-driven development;Business analysts;Domain specific languages;Functional testing;Model-based OPC;Test Automation;},
URL = {http://dx.doi.org/10.1145/2610384.2628048},
} 


@article{20252218522781 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2025 Elsevier Inc.},
copyright = {Compendex},
title = {A language-parametric test amplification framework for executable domain-specific languages},
journal = {Software and Systems Modeling},
author = {Khorram, Faezeh and Bousse, Erwan and Mottu, Jean-Marie and Sunye, Gerson and Khelladi, Djamel Eddine and Gomez-Abajo, Pablo and Canizares, Pablo C. and Guerra, Esther and de Lara, Juan},
volume = {24},
number = {4},
year = {2025},
pages = {1187 - 1212},
issn = {16191366},
abstract = {<div data-language="eng" data-ev-field="abstract">Behavioral models are important assets that must be thoroughly verified early in the design process. This can be achieved with manually-written test cases that embed carefully hand-picked domain-specific input data. However, such test cases may not always reach the desired level of quality, such as high coverage or being able to localize faults efficiently. Test amplification is an interesting emergent approach to improve a test suite by automatically generating new test cases out of existing manually-written ones. Yet, while ad-hoc test amplification solutions have been proposed for a few programming languages, no solution currently exists for amplifying the test suites of behavioral models. In order to fill this gap, we propose an automated and generic test amplification approach for executable domain-specific languages (DSLs). Hence, given an executable DSL, a conforming behavioral model, and an existing test suite, our approach synthesizes new regression test cases in three steps: (i) generating new test inputs by applying a set of generic modifiers on the existing test inputs; (ii) running the model under test with new inputs and generating assertions from the execution traces; and (iii) selecting the new test cases that increase the initial test quality. We provide a textual DSL to control and configure the amplification process, along with tool support for the whole approach atop the Eclipse GEMOC Studio. For assessment, we report on empirical evaluations over two different executable DSLs, which show improved test quality in terms of both coverage and mutation score.<br/></div> © The Author(s), under exclusive licence to Springer-Verlag GmbH Germany, part of Springer Nature 2025.},
key = {Design for testability},
keywords = {Computer control;Problem oriented languages;Statistical process control;},
note = {Behavioral model;Domains specific languages;Executable domain-specific language;Executable modeling;Executables;Mutation testing;Regression testing;Test amplifications;Test case;Test inputs;},
URL = {http://dx.doi.org/10.1007/s10270-025-01283-4},
} 


@inproceedings{20251418182557 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2025 Elsevier Inc.},
copyright = {Compendex},
title = {ProCC: Programmatic Reinforcement Learning for Efficient and Transparent TCP Congestion Control},
journal = {WSDM 2025 - Proceedings of the 18th ACM International Conference on Web Search and Data Mining},
author = {Gu, Yin and Zhang, Kai and Liu, Qi and Yu, Runlong and Lin, Xin and Sun, Xinjie},
year = {2025},
pages = {963 - 972},
address = {Hannover, Germany},
abstract = {<div data-language="eng" data-ev-field="abstract">Transmission Control Protocol (TCP) congestion control is a fundamental mechanism in the Internet that maintains network stability and performance by adjusting the sending rate of connections. Recently, Deep Reinforcement Learning (DRL) methods have shown superior performance over traditional expert-designed solutions. However, the DRL policies are often represented by black-box neural networks, they lack interpretability, making verification challenging and requiring excessive floating-point computation. This work introduces a novel approach, Programmatic reinforcement learning for Congestion Control (ProCC), designed to discover a program as a control policy from scratch autonomously. Programs in ProCC include branching structures (e.g., if blocks and if-else blocks), conditions and actions. However, directly optimizing such program structures is challenging due to their discrete non-differentiable nature, and the program space grows exponentially as the depth increases. To address this issue, ProCC defines a Domain-Specific Language (DSL) and program transformation rules, enabling the construction of a program search graph where similar programs are closer in proximity. Subsequently, ProCC employs Monte Carlo Tree Search (MCTS) to efficiently explore the discrete space and obtain promising programs. Extensive experiments conducted in multiple simulated environments demonstrate that ProCC is adaptive and consistently performs well under varying network conditions. The learned program's performance surpasses that of state-of-the-art DRL agents, and more importantly, the generated policies are concise, transparent, and computationally efficient.<br/></div> © 2025 Copyright held by the owner/author(s).},
key = {Congestion control (communication)},
keywords = {Autonomous agents;Black-box testing;Deep neural networks;Deep reinforcement learning;Digital subscriber lines;Problem oriented languages;Reinforcement learning;Trees (mathematics);},
note = {Control protocols;Fundamental mechanisms;Network stability;Performance;Programmatic reinforcement learning;Programmatics;Reinforcement learnings;Transmission control;Transmission control protocol congestion control;Transparent transmission;},
URL = {http://dx.doi.org/10.1145/3701551.3703585},
} 


@inproceedings{20110113552572 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2025 Elsevier Inc.},
copyright = {Compendex},
title = {An integrated domain specific language for post-processing and visualizing electrophysiological signals in Java},
journal = {2010 Annual International Conference of the IEEE Engineering in Medicine and Biology Society, EMBC'10},
author = {Strasser, T. and Peters, T. and Jagle, H. and Zrenner, E. and Wilke, R.},
year = {2010},
pages = {4687 - 4690},
abstract = {Electrophysiology of vision - especially the electroretinogram (ERG) - is used as a non-invasive way for functional testing of the visual system. The ERG is a combined electrical response generated by neural and non-neuronal cells in the retina in response to light stimulation. This response can be recorded and used for diagnosis of numerous disorders. For both clinical practice and clinical trials it is important to process those signals in an accurate and fast way and to provide the results as structured, consistent reports. Therefore, we developed a freely available and open-source framework in Java (http://www.eye.uni-tuebingen.de/projectlidsI4sigproc). The framework is focused on an easy integration with existing applications. By leveraging well-established software patterns like pipes-and-filters and fluent interfaces as well as by designing the application programming interfaces (API) as an integrated domain specific language (DSL) the overall framework provides a smooth learning curve. Additionally, it already contains several processing methods and visualization features and can be extended easily by implementing the provided interfaces. In this way, not only can new processing methods be added but the framework can also be adopted for other areas of signal processing. This article describes in detail the structure and implementation of the framework and demonstrate its application through the software package used in clinical practice and clinical trials at the University Eye Hospital Tuebingen one of the largest departments in the field of visual electrophysiology in Europe. © 2010 IEEE.<br/>},
key = {Application programming interfaces (API)},
keywords = {Application programs;Visual languages;Open source software;Signal processing;Java programming language;Electrophysiology;Neurology;Problem oriented languages;Processing;},
note = {Clinical practices;Domain specific languages;Electrical response;Electroretinograms;Functional testing;Open source frameworks;Processing method;Software patterns;},
URL = {http://dx.doi.org/10.1109/IEMBS.2010.5626417},
} 


@inproceedings{20103513188582 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2025 Elsevier Inc.},
copyright = {Compendex},
title = {A C++-embedded domain-specific language for programming the MORA soft processor array},
journal = {Proceedings of the International Conference on Application-Specific Systems, Architectures and Processors},
author = {Vanderbauwhede, W. and Margala, M. and Chalamalasetti, S.R. and Purohit, S.},
year = {2010},
pages = {141 - 148},
issn = {21600511},
address = {Rennes, France},
abstract = {<div data-language="eng" data-ev-field="abstract">MORA is a novel platform for high-level FPGA programming of streaming vector and matrix operations, aimed at multimedia applications. It consists of soft array of pipelined low-complexity SIMD processors-in-memory (PIM). We present a Domain-Specific Language (DSL) for high-level programming of the MORA soft processor array. The DSL is embedded in C++, providing designers with a familiar language framework and the ability to compile designs using a standard compiler for functional testing before generating the FPGA bitstream using the MORA toolchain. The paper discusses the MORA-C++ DSL and the compilation route into the assembly for the MORA machine and provides examples to illustrate the programming model and performance. © 2010 IEEE.<br/></div>},
key = {C++ (programming language)},
keywords = {Ability testing;Computer debugging;Digital subscriber lines;Functional programming;Pipeline processing systems;Problem oriented languages;Program compilers;Program debugging;},
note = {Domains specific languages;Embedded domain-specific languages;Matrix operations;Multimedia applications;Multimedia processing;Processor array;Reconfigurable processors;Soft processor array;Soft processors;Vector operations;},
URL = {http://dx.doi.org/10.1109/ASAP.2010.5540750},
} 


@inproceedings{20165203173126 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2025 Elsevier Inc.},
copyright = {Compendex},
title = {Automated regression testing of BPMN 2.0 processes a capture and replay framework for continuous delivery},
journal = {GPCE 2016 - Proceedings of the 2016 ACM SIGPLAN International Conference on Generative Programming: Concepts and Experiences, co-located with SPLASH 2016},
author = {Makki, Majid and Van Landuyt, Dimitri and Joosen, Wouter},
year = {2016},
pages = {178 - 189},
address = {Amsterdam, Netherlands},
abstract = {Regression testing is a form of software quality assurance (QA) that involves comparing the behavior of a newer version of a software artifact to its earlier correct behavior, and signaling the QA engineer when deviations are detected. Given the large potential in automated generation and execution of regression test cases for business process models in the context of running systems, powerful tools are required to make this practically feasible, more specifically to limit the potential impact on production systems, and to reduce the manual effort required from QA engineers. In this paper, we present a regression testing automation framework that implements the capture & replay paradigm in the context of BPMN 2.0, a domain-specific language for modeling and executing business processes. The framework employs parallelization techniques and efficient communication patterns to reduce the performance overhead of capturing. Based on inputs from the QA engineer, it manipulates the BPMN2 model before executing tests for isolating the latter from external dependencies (e.g. human actors or expensive web services) and for avoiding undesired sideeffects. Finally, it performs a regression detection algorithm and reports the results to the QA engineer. We have implemented our framework on top of a BPMN2-compliant execution engine, namely jBPM, and performed functional validations and evaluations of its performance and fault-Tolerance. The results, indicating 3:9% average capturing performance overhead, demonstrate that the implemented framework can be the foundation of a practical regression testing tool for BPMN 2.0, and a key enabler for continuous delivery of business process-driven applications and services.<br/> ©2016 ACM.},
key = {Regression analysis},
keywords = {Computer software selection and evaluation;Automation;Modeling languages;Web services;Fault tolerance;Software testing;Problem oriented languages;},
note = {BPMN 2.0;Business process execution;JBPM;Node mocking;Performance overhead;Regression testing;Test Automation;},
URL = {http://dx.doi.org/10.1145/2993236.2993257},
} 


@article{20201908616657 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2025 Elsevier Inc.},
copyright = {Compendex},
title = {Automated regression testing of BPMN 2.0 processes: A capture and replay framework for continuous delivery},
journal = {ACM SIGPLAN Notices},
author = {Makki, Majid and Van Landuyt, Dimitri and Joosen, Wouter},
volume = {52},
number = {3},
year = {2016},
pages = {178 - 189},
issn = {15232867},
abstract = {Regression testing is a form of software quality assurance (QA) that involves comparing the behavior of a newer version of a software artifact to its earlier correct behavior, and signaling the QA engineer when deviations are detected. Given the large potential in automated generation and execution of regression test cases for business process models in the context of running systems, powerful tools are required to make this practically feasible, more specifically to limit the potential impact on production systems, and to reduce the manual effort required from QA engineers. In this paper, we present a regression testing automation framework that implements the capture & replay paradigm in the context of BPMN 2.0, a domain-specific language for modeling and executing business processes. The framework employs parallelization techniques and efficient communication patterns to reduce the performance overhead of capturing. Based on inputs from the QA engineer, it manipulates the BPMN2 model before executing tests for isolating the latter from external dependencies (e.g. human actors or expensive web services) and for avoiding undesired side-effects. Finally, it performs a regression detection algorithm and reports the results to the QA engineer. We have implemented our framework on top of a BPMN2-compliant execution engine, namely jBPM, and performed functional validations and evaluations of its performance and fault-tolerance. The results, indicating 3.9% average capturing performance overhead, demonstrate that the implemented framework can be the foundation of a practical regression testing tool for BPMN 2.0, and a key enabler for continuous delivery of business process-driven applications and services.<br/> © 2016 ACM.},
key = {Regression analysis},
keywords = {Automation;Fault tolerance;Modeling languages;Software testing;Computer software selection and evaluation;Problem oriented languages;Engineers;Web services;},
note = {Automated generation;Automated regression testing;Business process model;Detection algorithm;Domain specific languages;Efficient communications;Functional validation;Parallelization techniques;},
URL = {http://dx.doi.org/10.1145/2993236.2993257},
} 


@inproceedings{20192807155857 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2025 Elsevier Inc.},
copyright = {Compendex},
title = {Programming behavioral test models for SMT solving in scala},
journal = {Proceedings - 2019 IEEE 12th International Conference on Software Testing, Verification and Validation Workshops, ICSTW 2019},
author = {Aichernig, Bernhard K. and Maderbacher, Benedikt and Tiran, Stefan},
year = {2019},
pages = {52 - 60},
address = {Xi'an, China},
abstract = {We present a novel approach for modeling cyber-physical systems for analysis and test purposes. Instead of creating a new expressive specification language with sophisticated semantics and complex compilers, we rely on a lightweight version of Back's Action Systems, for which we provide a simple bounded model checker using the SMT solver Z3. In order to model industrial-sized embedded systems, we extend our simple specification language by using the powerful capa-bilities of the modern programming language Scala for creating Domain Specific Languages (DSL). This enables us to use the features of an expressive, object-oriented and functional generalpurpose language without the need to increase the complexity of the model checker. We demonstrate how to model a railway interlocking system with a configurable track layout and sketch the application to model-based testing.<br/> © 2019 IEEE.},
key = {Specification languages},
keywords = {Problem oriented languages;Specifications;Computer aided software engineering;Model checking;Embedded systems;Object oriented programming;Semantics;Behavioral research;Modeling languages;},
note = {Bounded model checkers;Domain specific languages;General-purpose languages;Model based testing;Object oriented;Railway interlocking system;Scala;Test case generation;},
URL = {http://dx.doi.org/10.1109/ICSTW.2019.00032},
} 


@inproceedings{20252218513560 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2025 Elsevier Inc.},
copyright = {Compendex},
title = {Specification and Execution of Robotic Acceptance Tests for Object Sorting},
journal = {Springer Proceedings in Advanced Robotics},
author = {Hunecke, Bastian and Nguyen, Minh and Hochgeschwender, Nico and Wrede, Sebastian},
volume = {36 SPAR},
year = {2025},
pages = {200 - 205},
issn = {25111256},
address = {Stuttgart, Germany},
abstract = {<div data-language="eng" data-ev-field="abstract">Ensuring reliable performance in tasks with high variability is an increasingly important task in the engineering process of robotics applications. This paper introduces an extended toolchain leveraging Behaviour-Driven Development to specify acceptance criteria and high-quality simulations to execute acceptance tests. We demonstrate the effectiveness of the testing approach in a dynamic sorting task with objects picked from a moving conveyor using a Franka Panda robot system. The contributions include an extended domain-specific language for specifying acceptance criteria and an implementation for automated testing of sorting scenarios using NVIDIA IsaacSim. We conclude with a discussion on the current state and future work on acceptance testing for robotics.<br/></div> © The Author(s), under exclusive license to Springer Nature Switzerland AG 2025.},
key = {Acceptance tests},
keywords = {Application programs;Automatic test pattern generation;Computer operating systems;Industrial robots;Intelligent robots;Robotic assembly;Software design;Software packages;Software testing;},
note = {Acceptance criteria;Acceptance testing;Engineering process;Object sorting;Reliable performance;Robot manipulation;Robot system and software engineering;Robotics applications;Robots system;Systems and software;},
URL = {http://dx.doi.org/10.1007/978-3-031-89471-8_31},
} 


@inproceedings{20180504691895 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2025 Elsevier Inc.},
copyright = {Compendex},
title = {Evaluation of an integrated tool environment for experimentation in DSL engineering},
journal = {Lecture Notes in Business Information Processing},
author = {Haser, Florian and Felderer, Michael and Breu, Ruth},
volume = {302},
year = {2018},
pages = {147 - 168},
issn = {18651348},
address = {Vienna, Austria},
abstract = {Domain specific languages (DSL) are a popular means for providing customized solutions to a certain problem domain. So far, however, language workbenches lack sufficient built-in features in providing decision support when it comes to language design and improvement. Controlled experiments can provide data-driven decision support for both, researchers and language engineers, for comparing different languages or language features. This paper provides an evaluation of an integrated end-to-end tool environment for performing controlled experiments in DSL engineering. The experimentation environment is presented by a running example from engineering domain specific languages for acceptance testing. The tool is built on and integrated into the Meta Programming System (MPS) language workbench. For each step of an experiment the language engineer is supported by suitable DSLs and tools all within the MPS platform. The evaluation, from the viewpoint of the experiments subject, is based on the technology acceptance model (TAM). Results reveal that the subjects found the DSL experimentation environment intuitive and easy to use.<br/> © Springer International Publishing AG 2018.},
key = {Acceptance tests},
keywords = {Software engineering;Digital subscriber lines;Problem oriented languages;Decision support systems;},
note = {Domain specific languages;Empirical Software Engineering;Experimentation;Language engineering;Meta Programming;Model based software engineering;},
URL = {http://dx.doi.org/10.1007/978-3-319-71440-0_9},
} 


@inproceedings{20124415610620 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2025 Elsevier Inc.},
copyright = {Compendex},
title = {Application of build-in self test in functional test of DSL},
journal = {IPC APEX EXPO 2012},
author = {Gu, YaJun and Qin, Ye and Wang, ZhiJun and Wei, David and Ho, Andrew and Chen, Stephen and Feng, Zhen and Kurwa, Murad},
volume = {2},
year = {2012},
pages = {945 - 959},
address = {San Diego, CA, United states},
} 


@inproceedings{20124415610585 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2025 Elsevier Inc.},
copyright = {Compendex},
title = {Application of build-in self test in functional test of DSL},
journal = {IPC APEX EXPO 2012},
author = {Gu, YaJun and Qin, Ye and Wang, ZhiJun and Wei, David and Ho, Andrew and Chen, Stephen and Feng, Zhen and Kurwa, Murad},
volume = {1},
year = {2012},
pages = {233 - 234},
address = {San Diego, CA, United states},
} 


@article{20230513481876 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2025 Elsevier Inc.},
copyright = {Compendex},
title = {Testing Models of Reactive Systems},
journal = {ProQuest Dissertations and Theses Global},
author = {Ahmadi, Reza},
year = {2019},
abstract = {<div data-language="eng" data-ev-field="abstract">Testing models of modern Real-time Embedded (RTE) systems is not straightforward due to timing constraints, numerous if not infinite possible behaviors, and complex communications between components. Software testing tools and approaches that can generate test cases to test these systems are therefore important. Many of the existing automatic approaches support testing at the implementation level only. The existing model-level testing tools either treat the model as a black box (e.g., random testing approaches) or have limitations when it comes to generating complex test sequences (e.g., symbolic execution). This thesis presents different test case generation techniques for models developed in UML-RT, a UML profile and a domain specific language for modeling RTE systems. We present a novel approach and tool support for automatic unit testing of UML-RT models by conducting concolic testing, a hybrid testing technique based on concrete and symbolic execution. Our technique conducts automatic concolic testing in two phases. In the first phase, the model is isolated from its environment, transformed to a testable model and integrated into a test harness. In the second phase, the harness tests the model concolically and reports the test execution results.To make the test case generation efficient for UML-RT models, we present a novel slicing technique and its tool support. The slicer takes the input model and a criterion, and constructs a slice by taking into account the input criterion. The slice contains only those (behavioral and structural) elements of the original model that depend on the input criterion. Therefore, a slice is possibly a smaller model (compared to the original model) that can make the test case generation more efficient.We describe implementations of each of the techniques in the context of Papyrus-RT, an open source Model Driven Engineering (MDE) tool based on the modeling language UML-RT, and report the results of applying our techniques to a set of benchmark models to validate our approach. ProQuest Subject Headings: Computer science.<br/></div>  © Citation reproduced with permission of ProQuest LLC.},
key = {Model checking},
keywords = {Black-box testing;Embedded systems;Modeling languages;Open source software;Problem oriented languages;Program debugging;Real time systems;},
note = {Concolic testing;Debugging;Language;Real-time embedded systems;Software;Symbolic execution;Test case generation;Testing models;Testing tools;Tool support;},
} 


@unpublished{20240432639 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2025 Elsevier Inc.},
copyright = {Compendex},
title = {Directed Testing of ORAN using a Partially Specified Declarative Digital Twin},
journal = {arXiv},
author = {Gatherer, Alan and Sengupta, Chaitali and Sen, Sudipta and Reed, Jeffery H.},
year = {2024},
issn = {23318422},
abstract = {<div data-language="eng" data-ev-field="abstract">Real Time performance testing can be divided into two distinct parts: system test and algorithm test. System test checks that the right functions operate on the right data within power, latency, and other constraints under all conditions. Major RAN OEMs, put as much effort into system test and debug as they do into algorithm test, to ensure a competitive product. An algorithm tester will provide little insight into real time and hardware-software (HW-SW) capacity as it is unaware of the system implementation. In this paper we present an innovative Digital Twin technology, which we call Declarative Digital Twin (DDT). A DDT can describe the system requirements of the RAN such that critical corner cases can be found via automation, that would normally be missed by conventional testing. This is possible even when the RAN requirements are only partially specified. We present a Domain Specific Language (DSL) for declarative description of the RAN and show results from an automated solver that demonstrate how potential HW-SW implementation related corner cases can be identified from the DDT of an ORAN DU.<br/></div> © 2024, CC BY.},
key = {Software testing},
keywords = {5G mobile communication systems;Computer debugging;Computer hardware description languages;Digital subscriber lines;Problem oriented languages;Program debugging;Static random access storage;},
note = {5g;6g;Domains specific languages;Functional testing;Hardware/software;O-RAN;Open RAN;RAN construction;Software-defined radios;System test;},
URL = {http://dx.doi.org/10.48550/arXiv.2410.09310},
} 


@inproceedings{20245217599121 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2025 Elsevier Inc.},
copyright = {Compendex},
title = {Directed Testing of ORAN using a Partially Specified Declarative Digital Twin},
journal = {IEEE Vehicular Technology Conference},
author = {Gatherer, Alan and Sengupta, Chaitali and Sen, Sudipta and Reed, Jeffery H.},
year = {2024},
issn = {15502252},
address = {Washington, DC, United states},
abstract = {<div data-language="eng" data-ev-field="abstract">Real Time performance testing can be divided into two distinct parts: system test and algorithm test. System test checks that the right functions operate on the right data within power, latency, and other constraints under all conditions. Major RAN OEMs, put as much effort into system test and debug as they do into algorithm test, to ensure a competitive product. An algorithm tester will provide little insight into real time and hardware-software (HW-SW) capacity as it is unaware of the system implementation. In this paper we present an innovative Digital Twin technology, which we call Declarative Digital Twin (DDT). A DDT can describe the system requirements of the RAN such that critical corner cases can be found via automation, that would normally be missed by conventional testing. This is possible even when the RAN requirements are only partially specified. We present a Domain Specific Language (DSL) for declarative description of the RAN and show results from an automated solver that demonstrate how potential HW-SW implementation related corner cases can be identified from the DDT of an ORAN DU.<br/></div> © 2024 IEEE.},
key = {Software testing},
keywords = {5G mobile communication systems;Computer debugging;Computer hardware description languages;Digital storage;Digital subscriber lines;Problem oriented languages;Program debugging;},
note = {5g;6g;Domains specific languages;Functional testing;Hardware/software;O-RAN;Open RAN;RAN construction;Software-defined radios;System test;},
URL = {http://dx.doi.org/10.1109/VTC2024-Fall63153.2024.10758052},
} 


@inproceedings{20240215338023 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2025 Elsevier Inc.},
copyright = {Compendex},
title = {Towards a Complete Metamorphic Testing Pipeline},
journal = {Proceedings - 2023 IEEE International Conference on Software Maintenance and Evolution, ICSME 2023},
author = {Duque-Torres, Alejandra and Pfahl, Dietmar},
year = {2023},
pages = {606 - 610},
address = {Bogota, Colombia},
abstract = {<div data-language="eng" data-ev-field="abstract">Metamorphic Testing (MT) addresses the test oracle problem by examining the relationships between input-output pairs in consecutive executions of the System Under Test (SUT). These relations, known as Metamorphic Relations (MRs), specify the expected output changes resulting from specific input changes. However, achieving full automation in generating, selecting, and understanding MR violations poses challenges. Our research aims to develop methods and tools that assist testers in generating MRs, defining constraints, and providing explainability for MR outcomes. In the MR generation phase, we explore automated techniques that utilise a domain-specific language to generate and describe MRs. The MR constraint definition focuses on capturing the nuances of MR applicability by defining constraints. These constraints help identify the specific conditions under which MRs are expected to hold. The evaluation and validation involve conducting empirical studies to assess the effectiveness of the developed methods and validate their applicability in real-world regression testing scenarios. Through this research, we aim to advance the automation of MR generation, enhance the understanding of MR violations, and facilitate their effective application in regression testing.<br/></div> © 2023 IEEE.},
key = {Automation},
keywords = {Problem oriented languages;Software testing;},
note = {Automated techniques;Condition;Domains specific languages;Input-output;Metamorphic relations;Metamorphic testing;Oracle problem;Regression testing;Systems under tests;Test oracles;},
URL = {http://dx.doi.org/10.1109/ICSME58846.2023.00081},
} 


@inproceedings{20224613122914 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2025 Elsevier Inc.},
copyright = {Compendex},
title = {Automatic test amplification for executable models},
journal = {Proceedings - 25th ACM/IEEE International Conference on Model Driven Engineering Languages and Systems, MODELS 2022},
author = {Khorram, Faezeh and Bousse, Erwan and Mottu, Jean-Marie and Sunye, Gerson and Gomez-Abajo, Pablo and Canizares, Pablo C. and Guerra, Esther and De Lara, Juan},
year = {2022},
pages = {109 - 120},
address = {Montreal, Canada},
abstract = {<div data-language="eng" data-ev-field="abstract">Behavioral models are important assets that must be thoroughly verified early in the design process. This can be achieved with manually-written test cases that embed carefully hand-picked domain-specific input data. However, such test cases may not always reach the desired level of quality, such as high coverage or being able to localize faults efficiently. Test amplification is an interesting emergent approach to improve a test suite by automatically generating new test cases out of existing manually-written ones. Yet, while ad-hoc test amplification solutions have been proposed for a few programming languages, no solution currently exists for amplifying the test cases of behavioral models. In this paper, we fill this gap with an automated and generic approach. Given an executable DSL, a conforming behavioral model, and an existing test suite, our approach generates new regression test cases in three steps: (i) generating new test inputs by applying a set of generic modifiers on the existing test inputs; (ii) running the model under test with new inputs and generating assertions from the execution traces; and (iii) selecting the new test cases that increase the mutation score. We provide tool support for the approach atop the Eclipse GEMOC Studio1 and show its applicability in an empirical study. In the experiment, we applied the approach to 71 test suites written for models conforming to two different DSLs, and for 67 of the 71 cases, it successfully improved the mutation score between 3.17% and 54.11% depending on the initial setup.<br/></div> © 2022 ACM.},
key = {Software testing},
keywords = {Behavioral research;Digital subscriber lines;},
note = {Behavioral model;Design-process;Executable DSL;Executable modeling;Executables;Mutation score;Regression testing;Test amplifications;Test case;Test inputs;},
URL = {http://dx.doi.org/10.1145/3550355.3552451},
} 


@article{20241315809603 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2025 Elsevier Inc.},
copyright = {Compendex},
title = {Metamodel-Based Model Generation and Validation Techniques With Applications =},
journal = {ProQuest Dissertations and Theses Global},
author = {Szatmari, Zoltan},
year = {2016},
abstract = {<div data-language="eng" data-ev-field="abstract">Model driven development using domain-specific languages and the related testing and validation tasks are common in safety-critical system development. Designing a new domain-specific language and selecting the right tool set for model manipulation and validation is a challenging task, since this determines the capabilities and efficiency of the entire development process. This dissertation is concerned with domain-specific language design, tool set selection and frameworks for model manipulation and validation demonstrated in two specifoc, new application domains. Model driven development using domain-specific languages and the related testing and validation tasks are common in safety-critical system development. Designing a new domain-specific language and selecting the right tool set for model manipulation and validation is a challenging task, since this determines the capabilities and efficiency of the entire development process. This dissertation is concerned with domain-specific language design, tool set selection and frameworks for model manipulation and validation demonstrated in two specific, new application domains.The first part of the dissertation presents a domain-specific language design method, that aims to provide support to derive domain-specific languages from ontology-based specifications. The challenge was to derive a language that supports efficient model generation and validation. The main contribution of this part is the construction of the well-depened mapping between the ontology-based and domain-specific model representations. This mapping allows the domain engineers to use ontologies in the language design phase, while the domain-specific model validation and manipulation tools can be used in the modeling phase. Additionally, the selection of the tools for model manipulation and validation is supported by providing a benchmark and initial benchmark results.The second part of the dissertation focuses on a model-based test data generation method for black-box testing of autonomous agents. The input test data for this testing approach are models that represent the agent’s context, in which the behaviour of the agent can be recorded and compared to the expectations. The challenge was to provide a modeling method to capture the agent’s context and additional requirements. The main contribution of this research is the definition of the test data generation problem as a constraint satisfaction problem on domain-specidfic models. Based on the proposed representation an iterative test data generation framework was constructed and demonstrated in an industrial use case.The third part of the dissertation presents a framework for checking the standard compliance of development and V&V processes. The challenge was to provide a modeling method that allows capturing the requirements described in the standards for development and V&V processes. The main contribution of this part is an ontology-based modeling method that covers both the modeling of the standards and the development processes, and provides a validation method for checking the standard compliance of the process models. ProQuest Subject Headings: Engineering, Robotics, System science.<br/></div>  © Citation reproduced with permission of ProQuest LLC.},
key = {Iterative methods},
keywords = {Application programs;Autonomous agents;Black-box testing;Compliance control;Efficiency;Formal specification;Model checking;Ontology;Problem oriented languages;Regulatory compliance;Robotics;Security systems;Software design;XML;},
note = {Development process;Domains specific languages;Language design;Model method;Model validation;Ontology's;Software;System development;Test data generation;Toolsets;},
} 


@article{20242116142659 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2025 Elsevier Inc.},
copyright = {Compendex},
title = {Metamodel-Based Model Generation and Validation Techniques With Applications},
journal = {ProQuest Dissertations and Theses Global},
author = {Szatmari, Zoltan},
year = {2016},
abstract = {<div data-language="eng" data-ev-field="abstract">Model driven development using domain-specific languages and the related testing and validation tasks are common in safety-critical system development. Designing a new domain-specific language and selecting the right tool set for model manipulation and validation is a challenging task, since this determines the capabilities and efficiency of the entire development process. This dissertation is concerned with domain-specific language design, tool set selection and frameworks for model manipulation and validation demonstrated in two specifoc, new application domains. Model driven development using domain-specific languages and the related testing and validation tasks are common in safety-critical system development. Designing a new domain-specific language and selecting the right tool set for model manipulation and validation is a challenging task, since this determines the capabilities and efficiency of the entire development process. This dissertation is concerned with domain-specific language design, tool set selection and frameworks for model manipulation and validation demonstrated in two specific, new application domains.The first part of the dissertation presents a domain-specific language design method, that aims to provide support to derive domain-specific languages from ontology-based specifications. The challenge was to derive a language that supports efficient model generation and validation. The main contribution of this part is the construction of the well-depened mapping between the ontology-based and domain-specific model representations. This mapping allows the domain engineers to use ontologies in the language design phase, while the domain-specific model validation and manipulation tools can be used in the modeling phase. Additionally, the selection of the tools for model manipulation and validation is supported by providing a benchmark and initial benchmark results.The second part of the dissertation focuses on a model-based test data generation method for black-box testing of autonomous agents. The input test data for this testing approach are models that represent the agent’s context, in which the behaviour of the agent can be recorded and compared to the expectations. The challenge was to provide a modeling method to capture the agent’s context and additional requirements. The main contribution of this research is the definition of the test data generation problem as a constraint satisfaction problem on domain-specidfic models. Based on the proposed representation an iterative test data generation framework was constructed and demonstrated in an industrial use case.The third part of the dissertation presents a framework for checking the standard compliance of development and V&V processes. The challenge was to provide a modeling method that allows capturing the requirements described in the standards for development and V&V processes. The main contribution of this part is an ontology-based modeling method that covers both the modeling of the standards and the development processes, and provides a validation method for checking the standard compliance of the process models. ProQuest Subject Headings: Engineering, Robotics, System science.<br/></div>  © Citation reproduced with permission of ProQuest LLC.},
key = {Iterative methods},
keywords = {Abstracting;Application programs;Autonomous agents;Black-box testing;Compliance control;Efficiency;Formal specification;Model checking;Ontology;Problem oriented languages;Regulatory compliance;Security systems;Software design;XML;},
note = {Development process;Domains specific languages;Language design;Model method;Model validation;Ontology's;Software;System development;Test data generation;Toolsets;},
} 


@article{20241315806480 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2025 Elsevier Inc.},
copyright = {Compendex},
title = {Metamodel-Based Model Generation and Validation Techniques With Applications =},
journal = {ProQuest Dissertations and Theses Global},
author = {Szatmari, Zoltan},
year = {2016},
abstract = {<div data-language="eng" data-ev-field="abstract">Model driven development using domain-specific languages and the related testing and validation tasks are common in safety-critical system development. Designing a new domain-specific language and selecting the right tool set for model manipulation and validation is a challenging task, since this determines the capabilities and efficiency of the entire development process. This dissertation is concerned with domain-specific language design, tool set selection and frameworks for model manipulation and validation demonstrated in two specifoc, new application domains. Model driven development using domain-specific languages and the related testing and validation tasks are common in safety-critical system development. Designing a new domain-specific language and selecting the right tool set for model manipulation and validation is a challenging task, since this determines the capabilities and efficiency of the entire development process. This dissertation is concerned with domain-specific language design, tool set selection and frameworks for model manipulation and validation demonstrated in two specific, new application domains.The first part of the dissertation presents a domain-specific language design method, that aims to provide support to derive domain-specific languages from ontology-based specifications. The challenge was to derive a language that supports efficient model generation and validation. The main contribution of this part is the construction of the well-depened mapping between the ontology-based and domain-specific model representations. This mapping allows the domain engineers to use ontologies in the language design phase, while the domain-specific model validation and manipulation tools can be used in the modeling phase. Additionally, the selection of the tools for model manipulation and validation is supported by providing a benchmark and initial benchmark results.The second part of the dissertation focuses on a model-based test data generation method for black-box testing of autonomous agents. The input test data for this testing approach are models that represent the agent’s context, in which the behaviour of the agent can be recorded and compared to the expectations. The challenge was to provide a modeling method to capture the agent’s context and additional requirements. The main contribution of this research is the definition of the test data generation problem as a constraint satisfaction problem on domain-specidfic models. Based on the proposed representation an iterative test data generation framework was constructed and demonstrated in an industrial use case.The third part of the dissertation presents a framework for checking the standard compliance of development and V&V processes. The challenge was to provide a modeling method that allows capturing the requirements described in the standards for development and V&V processes. The main contribution of this part is an ontology-based modeling method that covers both the modeling of the standards and the development processes, and provides a validation method for checking the standard compliance of the process models. ProQuest Subject Headings: Engineering, Robotics, System science.<br/></div>  © Citation reproduced with permission of ProQuest LLC.},
key = {Iterative methods},
keywords = {Application programs;Autonomous agents;Black-box testing;Compliance control;Efficiency;Formal specification;Model checking;Ontology;Problem oriented languages;Regulatory compliance;Robotics;Security systems;Software design;XML;},
note = {Development process;Domains specific languages;Language design;Model method;Model validation;Ontology's;Software;System development;Test data generation;Toolsets;},
} 


@article{20241916043316 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2025 Elsevier Inc.},
copyright = {Compendex},
title = {Metamodel-Based Model Generation and Validation Techniques With Applications},
journal = {ProQuest Dissertations and Theses Global},
author = {Szatmari, Zoltan},
year = {2016},
abstract = {<div data-language="eng" data-ev-field="abstract">Model driven development using domain-specific languages and the related testing and validation tasks are common in safety-critical system development. Designing a new domain-specific language and selecting the right tool set for model manipulation and validation is a challenging task, since this determines the capabilities and efficiency of the entire development process. This dissertation is concerned with domain-specific language design, tool set selection and frameworks for model manipulation and validation demonstrated in two specifoc, new application domains. Model driven development using domain-specific languages and the related testing and validation tasks are common in safety-critical system development. Designing a new domain-specific language and selecting the right tool set for model manipulation and validation is a challenging task, since this determines the capabilities and efficiency of the entire development process. This dissertation is concerned with domain-specific language design, tool set selection and frameworks for model manipulation and validation demonstrated in two specific, new application domains.The first part of the dissertation presents a domain-specific language design method, that aims to provide support to derive domain-specific languages from ontology-based specifications. The challenge was to derive a language that supports efficient model generation and validation. The main contribution of this part is the construction of the well-depened mapping between the ontology-based and domain-specific model representations. This mapping allows the domain engineers to use ontologies in the language design phase, while the domain-specific model validation and manipulation tools can be used in the modeling phase. Additionally, the selection of the tools for model manipulation and validation is supported by providing a benchmark and initial benchmark results.The second part of the dissertation focuses on a model-based test data generation method for black-box testing of autonomous agents. The input test data for this testing approach are models that represent the agent’s context, in which the behaviour of the agent can be recorded and compared to the expectations. The challenge was to provide a modeling method to capture the agent’s context and additional requirements. The main contribution of this research is the definition of the test data generation problem as a constraint satisfaction problem on domain-specidfic models. Based on the proposed representation an iterative test data generation framework was constructed and demonstrated in an industrial use case.The third part of the dissertation presents a framework for checking the standard compliance of development and V&V processes. The challenge was to provide a modeling method that allows capturing the requirements described in the standards for development and V&V processes. The main contribution of this part is an ontology-based modeling method that covers both the modeling of the standards and the development processes, and provides a validation method for checking the standard compliance of the process models. ProQuest Subject Headings: Engineering, Robotics, System science.<br/></div>  © Citation reproduced with permission of ProQuest LLC.},
key = {Iterative methods},
keywords = {Abstracting;Application programs;Autonomous agents;Black-box testing;Compliance control;Efficiency;Formal specification;Model checking;Ontology;Problem oriented languages;Regulatory compliance;Security systems;Software design;XML;},
note = {Development process;Domains specific languages;Language design;Model method;Model validation;Ontology's;Software;System development;Test data generation;Toolsets;},
} 


@article{20164502986281 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2025 Elsevier Inc.},
copyright = {Compendex},
title = {Model-based testing for building reliable realtime interactive music systems},
journal = {Science of Computer Programming},
author = {Poncelet, Clement and Jacquemard, Florent},
volume = {132},
year = {2016},
pages = {143 - 172},
issn = {01676423},
abstract = {The role of an Interactive Music System (IMS) is to accompany musicians during live performances, acting like a real musician. It must react in realtime to audio signals from musicians, according to a timed high-level requirement called mixed score, written in a domain specific language. Such goals imply strong requirements of temporal reliability and robustness to unforeseen errors in input, yet not much addressed by the computer music community. We present the application of Model-Based Testing techniques and tools to a state-of-the-art IMS, including in particular: offline and on-the-fly approaches for the generation of relevant input data for testing (including timing values), with coverage criteria, the computation of the corresponding expected output, according to the semantics of a given mixed score, the black-box execution of the test data on the System Under Test and the production of a verdict. Our method is based on formal models in a dedicated intermediate representation, compiled directly from mixed scores (high-level requirements), and either passed, to the model-checker Uppaal (after conversion to Timed Automata) in the offline approach, or executed by a virtual machine in the online approach. Our fully automatic framework has been applied to real mixed scores used in concerts and the results obtained have permitted to identify bugs in the target IMS.<br/> © 2016 Elsevier B.V.},
key = {Semantics},
keywords = {Automata theory;Black-box testing;Audio acoustics;Problem oriented languages;Computer music;Model checking;},
note = {Coverage criteria;Domain specific languages;Interactive music systems;Intermediate representations;Model based testing;Off-line approaches;Temporal reliability;Timed Automata;},
URL = {http://dx.doi.org/10.1016/j.scico.2016.08.002},
} 


@article{20143600043933 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2025 Elsevier Inc.},
copyright = {Compendex},
title = {Model transformations for migrating legacy deployment models in the automotive industry},
journal = {Software and Systems Modeling},
author = {Selim, Gehan M. K. and Wang, Shige and Cordy, James R. and Dingel, Juergen},
volume = {14},
number = {1},
year = {2015},
pages = {365 - 381},
issn = {16191366},
abstract = {<div data-language="eng" data-ev-field="abstract">Many companies in the automotive industry have adopted model-driven development in their vehicle software development. As a major automotive company, General Motors (GM) has been using a custom-built, domain-specific modeling language, implemented as an internal proprietary metamodel, to meet the modeling needs in its control software development. Since AUTomotive Open System ARchitecture (AUTOSAR) has been developed as a standard to ease the process of integrating components provided by different suppliers and manufacturers, there has been a growing demand to migrate these GM-specific, legacy models to AUTOSAR models. Given that AUTOSAR defines its own metamodel for various system artifacts in automotive software development, we explore applying model transformations to address the challenges in migrating GM-specific, legacy models to their AUTOSAR equivalents. As a case study, we have built and validated a model transformation using the MDWorkbench tool, the Atlas Transformation Language, and the Metamodel Coverage Checker tool. This paper reports on the case study, makes observations based on our experience to assist in the development of similar types of transformations, and provides recommendations for further research.<br/></div> © 2013, Springer-Verlag Berlin Heidelberg.},
key = {Automotive industry},
keywords = {Specification languages;Open systems;Software design;Embedded systems;Open source software;Black-box testing;Modeling languages;},
note = {Automotive control softwares;AutoSAR;Model transformation;Model-driven development;Transformation languages;},
URL = {http://dx.doi.org/10.1007/s10270-013-0365-1},
} 


@inproceedings{20160501861464 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2025 Elsevier Inc.},
copyright = {Compendex},
title = {Model based testing of an interactive music system},
journal = {Proceedings of the ACM Symposium on Applied Computing},
author = {Poncelet, Clement and Jacquemard, Florent},
volume = {13-17-April-2015},
year = {2015},
pages = {1759 - 1764},
address = {Salamanca, Spain},
abstract = {The role of an interactive music system (IMS) is to accompany musicians during live performances, like a real musician. It reacts in realtime to audio signals from musicians, according to a timed specification called mixed score, written in a domain specific language. Such goals imply strong requirements of temporal reliability and robustness to unforeseen errors in input, yet not so much studied in the computer music community. We present the application of model-based testing techniques and tools to a state-of-the-art IMS, including the following tasks: generation of relevant input data for testing (including timing values) following coverage criteria, computation of the corresponding expected output, according to the semantics of a given mixed score, black-box execution of the test data and verdict. Our method is based on formal models compiled directly from mixed scores, and passed, after conversion to timed automata, to the model-checker Uppaal. This fully automatic approach has been applied to real mixed scores used in concerts and the results obtained have permitted to identify bugs in the target IMS.<br/> Copyright 2015 ACM.},
key = {Semantics},
keywords = {Problem oriented languages;Model checking;Automata theory;Computer music;Black-box testing;Graphical user interfaces;},
note = {Automatic approaches;Coverage criteria;Domain specific languages;Interactive music systems;Model based testing;State of the art;Temporal reliability;Timed Automata;},
URL = {http://dx.doi.org/10.1145/2695664.2695804},
} 


@inproceedings{20244317267500 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2025 Elsevier Inc.},
copyright = {Compendex},
title = {First Experiments on Automated Execution of Gherkin Test Specifications with Collaborating LLM Agents},
journal = {A-TEST 2024 - Proceedings of the 15th ACM International Workshop on Automating Test Case Design, Selection and Evaluation, Co-located with: SSTA 2024},
author = {Bergsmann, Severin and Schmidt, Alexander and Fischer, Stefan and Ramler, Rudolf},
year = {2024},
pages = {12 - 15},
address = {Vienna, Austria},
abstract = {<div data-language="eng" data-ev-field="abstract">Gherkin is a domain-specific language for describing test scenarios in natural language, which are the basis for automated acceptance testing. The emergence of Large Language Models (LLMs) has opened up new possibilities for processing such test specifications and for generating executable test code. This paper investigates the feasibility of employing LLMs to execute Gherkin test specifications utilizing the AutoGen multi-agent framework. Our findings show that our LLM agent system is able to automatically run the given test scenarios by autonomously exploring the system under test, generating executable test code on the fly, and evaluating execution results. We observed high success rates for executing simple as well as more complex test scenarios, but we also identified difficulties regarding failure scenarios and fault detection.<br/></div> © 2024 Copyright held by the owner/author(s).},
key = {Acceptance tests},
keywords = {Autonomous agents;Intelligent agents;Model checking;Specification languages;},
note = {Domains specific languages;Executables;Language model;Large language model;Model agents;Natural languages;Test Automation;Test code;Test scenario;Test specifications;},
URL = {http://dx.doi.org/10.1145/3678719.3685692},
} 


@inproceedings{20204209341603 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2025 Elsevier Inc.},
copyright = {Compendex},
title = {Model-based testing in agile projects: An approach based on domain-specific languages},
journal = {23rd Iberoamerican Conference on Software Engineering, CIbSE 2020},
author = {Zanin, Aline and Zorzo, Avelino Fracisco and Nunes, Henry Cabral},
year = {2020},
address = {Curitiba, Brazil},
abstract = {Model-Based Testing (MBT) can bring several benefits to software quality. However, generally, MBT is applied in traditional software development lifecycle models, with few studies exploring its application in agile software development context. Hence, usually, agile development teams (AT) do not benefit from the advantages that the MBT technique provides, for example, reuse of artifacts and traceability between requirements and test artifacts. Thus, this article presents an approach for applying MBT in agile software development teams. This approach is based on the use of a semi-natural language to write scenarios for the automatic generation of models and test scripts. To exemplify the application of this approach, we also present a Domain-Specific Language (DSL) called Aquila, in which new functional test related keywords are added to the Gherkin DSL. We also present, based on a literature review, the majors challenges and difficulties of applying MBT in AT. To validate the proposed approach a Focus Group study was used.<br/> © CIbSE 2020.},
key = {Software testing},
keywords = {Application programs;Model checking;Life cycle;Computer software selection and evaluation;Software design;Digital subscriber lines;Problem oriented languages;},
note = {Agile development;Agile software development;Automatic Generation;Domain specific languages;Focus group studies;Literature reviews;Model based testing;Software development life cycle;},
} 


@inproceedings{20183905860278 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2025 Elsevier Inc.},
copyright = {Compendex},
title = {A process for evidence-based engineering of domain-specific languages},
journal = {ACM International Conference Proceeding Series},
author = {Felderer, Michael and Jeschko, Fabian},
year = {2018},
pages = {SIGNAL; Software Innovation - },
address = {Christchurch, New zealand},
abstract = {Domain-specific languages (DSLs) are mainly designed ad-hoc and gut feeling resulting in languages that are often not well suited for their users and engineers. In this paper we develop a process for evidence-based language engineering to design domain-specific languages based on empirical evidence to support decision in language engineering. The developed process comprises an iterative execution of the phases DSL engineering, issue identification, data collection and evidence appraisal. We exemplify the concept by designing a DSL for Gherkin, a language test-driven acceptance testing in Xtext. The required evidence is derived by mining and analyzing all GitHub projects until July 1, 2017 that apply Gherkin.<br/> © 2018 Association for Computing Machinery.},
key = {Acceptance tests},
keywords = {Problem oriented languages;Software engineering;Digital subscriber lines;},
note = {Acceptance testing;Data collection;Domain specific languages;Empirical research;Evidence Based Software Engineering;Issue identifications;Language engineering;Repository mining;},
URL = {http://dx.doi.org/10.1145/3210459.3210479},
} 


@article{2006129767382 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2025 Elsevier Inc.},
copyright = {Compendex},
title = {An experimental evaluation of a higher-ordered-typed-functional specification-based test-generation technique},
journal = {Empirical Software Engineering},
author = {Sinha, Avik and Smidts, Carol},
volume = {11},
number = {2},
year = {2006},
pages = {173 - 202},
issn = {13823256},
abstract = {HOTTest is a model based test automation technique of software systems based on models of the system described using HaskellDB. HaskellDB is an embedded domain specific language derived from Haskell. HOTTest enforces a systematic abstraction process and exploits system invariants for automatically producing test cases for domain specific requirements. Use of functional languages for system modeling is a new concept and hence HOTTest is subject to concerns of usability, like any other new technique. Also, the syntax and the declarative style of Haskell based languages make them difficult to learn. Similar concerns can be raised for HOTTest as it shares the same syntax with Haskell. In this paper we describe an experiment designed to study the usability of HOTTest and to compare it with existing model based test design techniques. The results show that HOTTest is more usable than the traditional technique and demonstrate that the test suites produced by HOTTest are more effective and efficient than those generated using the traditional model based test design technique. © Springer Science + Business Media, Inc. 2006.},
key = {Software engineering},
keywords = {Automation;Computer hardware description languages;Computer software;Mathematical models;},
note = {Controlled experiment;EFSM software model;Empirical study;Functional specification language;Software test automation;},
URL = {http://dx.doi.org/10.1007/s10664-006-6401-9},
} 


@inproceedings{20113714315180 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2025 Elsevier Inc.},
copyright = {Compendex},
title = {Using Haskell to script combinatoric testing of web services},
journal = {Proceedings of the 6th Iberian Conference on Information Systems and Technologies, CISTI 2011},
author = {Prasetya, I.S.W.B. and Amorim, J. and Vos, T.E.J. and Baars, A.},
year = {2011},
abstract = {The Classification Tree Method (CTM) is a popular approach in functional testing as it allows the testers to systematically partition the input domain of an SUT, and specifies the combinations they want. We have implemented the approach as a small domain specific language (DSL) embedded in the functional language Haskell. Such an embedding leads to clean syntax and moreover we can natively access Haskell's full features. This paper will explain the approach, and how it is applied for testing Web Services. © 2011 AISTI.<br/>},
key = {Websites},
keywords = {Web services;Combinatorial mathematics;Problem oriented languages;},
note = {Automated testing;Classification tree method;Domain specific languages;Functional languages;Functional testing;Haskell;},
} 


@inproceedings{20150400440526 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2025 Elsevier Inc.},
copyright = {Compendex},
title = {Test process improvement with documentation driven integration testing},
journal = {Proceedings - 2014 9th International Conference on the Quality of Information and Communications Technology, QUATIC 2014},
author = {Haser, Florian and Felderer, Michael and Breu, Ruth},
year = {2014},
pages = {156 - 161},
address = {Guimaraes, Portugal},
abstract = {Improving the maturity of the test process in an organization, especially but not limited to integration testing, involves obstacles and risks, such as the additional work overhead of the new process. In addition, integration testing descriptions are often too technical not addressing the language needs of the domain. In research cooperations with companies from the insurance and banking domain it turned out that test descriptions and reports are one of the most useful testing artifacts, while doing adhoc testing. This paper presents a bottom up testing approach, which first helps the integration tester in producing a semi-formal test description and report, up to be an enabler for automatic model-based testing in the very end. The presented approach is based on a textual domain specific language that is able to evolve over time. This is done by analyzing the test descriptions and reports automatically with machine learning techniques as well as manually by integration testers. Often recurring test steps or used components are integrated into the test language, making it specially tailored for a specific organization. For each test step implementations can be attached, preparing it for the next iteration. In this paper the methodology and architecture of our integration testing approach are presented together with the underlying language concepts.<br/> © 2014 IEEE.},
key = {Integration testing},
keywords = {Process engineering;Iterative methods;Integration;Learning systems;Model checking;Problem oriented languages;},
note = {Automatic modeling;Domain specific languages;Machine learning techniques;Model-based integrations;Regression testing;Research cooperation;Test process;Underlying language;},
URL = {http://dx.doi.org/10.1109/QUATIC.2014.29},
} 


@inproceedings{20123115287320 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2025 Elsevier Inc.},
copyright = {Compendex},
title = {Declarative automated test},
journal = {2012 7th International Workshop on Automation of Software Test, AST 2012 - Proceedings},
author = {Hallenberg, Niels and Carlsen, Philip Lykke},
year = {2012},
pages = {96 - 102},
address = {Zurich, Switzerland},
abstract = {Automated tests at the business level can be expensive to develop and maintain. One common approach is to have a domain expert instruct a QA developer to implement what she would do manually in the application. Though there exist record-replay tools specifically developed for this, these tend to scale poorly for more complicated test scenarios. We present a different solution: An Embedded Domain Specific Language (EDSL) in F#, containing the means to model the user interface, and the various manipulations of it. We hope that this DSL will bridge the gap between the business domain and technical domain of applications to such a degree that domain experts may be able to construct automatic tests without depending on QA developers, and that these tests will prove more maintainable. © 2012 IEEE.<br/>},
key = {User interfaces},
keywords = {Software testing;Automation;Problem oriented languages;},
note = {Automated test;Automated testing;Business domain;Domain experts;Domain specific languages;Embedded domain specific languages;Functional testing;Record-replay;},
URL = {http://dx.doi.org/10.1109/IWAST.2012.6228998},
} 


@inproceedings{20172703897368 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2025 Elsevier Inc.},
copyright = {Compendex},
title = {ACM International Conference Proceeding Series},
journal = {ACM International Conference Proceeding Series},
volume = {Part F128404},
year = {2016},
pages = {City of Lugano; Hasler Foundation; Oracle Labs; Universita della Svizzera Italiana, Faculty of Informatics - },
address = {Lugano, Switzerland},
abstract = {The proceedings contain 18 papers. The topics discussed include: deeply reifying running code for constructing a domain-specific language; a distributed selectors runtime system for Java applications; efficient memory traces with full pointer information; extraction-based regression test selection; inference and checking of object immutability; integrating asynchronous task parallelism and data-centric atomicity; JCrypt: towards computation over encrypted data; multi-tier data synchronization based on an optimized concurrent linked-list; preexistence and concrete type analysis in the context of multiple inheritance; and prioritizing regression tests for desktop and web-applications based on the execution frequency of modified code.<br/>},
} 


@inproceedings{20181805112947 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2025 Elsevier Inc.},
copyright = {Compendex},
title = {Proceedings - Asia-Pacific Software Engineering Conference, APSEC},
journal = {Proceedings - Asia-Pacific Software Engineering Conference, APSEC},
volume = {2017-December},
year = {2017},
issn = {15301362},
address = {Nanjing, Jiangsu, China},
abstract = {The proceedings contain 93 papers. The topics discussed include: extracting traceability between predicates in event-B refinement; an improved approach to traceability recovery based on word embeddings; application of LSSVM and SMOTE on seven open source projects for predicting refactoring at class level; detecting full initialization points of objects to support code refactorings; a cloud-based trust evaluation scheme using a vehicular social network environment; Noff: a novel extendible parallel library for high-performance network traffic monitoring; a reusable framework for modeling and verifying in-vehicle networking systems in the presence of CAN and FlexRay; cost-effective regression testing using bloom filters in continuous integration development environments; correlation between the frequent use of gang-of-four design patterns and structural complexity; method level text summarization for java code using nano-patterns; flexible components for development of embedded systems with GPUs; Exniffer: learning to prioritize crashes by assessing the exploitability from memory dump; modeling and verifying identity authentication security of HDFS using CSP; a goal-driven framework in support of knowledge management; extracting insights from the topology of the JavaScript package ecosystem; improving bug localization with an enhanced convolutional neural network; mining handover process in open source development: an exploratory study; an analysis method of safety requirements for automotive software systems; and domain-specific language facilitates scheduling in model checking.<br/>},
} 


@article{2000505390853 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2025 Elsevier Inc.},
copyright = {Compendex},
title = {Programmable DSP-based DSL chipsets streamline system testing},
journal = {EE: Evaluation Engineering},
author = {Vogel, Erich and Halbach, Robert and Sheppard, Ben},
volume = {39},
number = {10},
year = {2000},
pages = {4 pp - 4 pp},
issn = {01490370},
abstract = {The streamline testing of programmable digital signal processing (DSP)-based digital subscriber line (DSL) was discussed. The programmable DSP-based solutions were tested by performing signal analysis and generation functions in software. The programmable solution allowed manufacturing tests to be customized to individual system requirements. The manufacturing verification process for DSL modems was completed in three stages of in-circuit, parametric and functional testing.},
key = {Microprocessor chips},
keywords = {Costs;Digital signal processing;Integrated circuit testing;Microprogramming;Modems;},
note = {Digital subscriber lines (DSL);In-circuit testing (ICT);},
} 


@inproceedings{20202508836574 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2025 Elsevier Inc.},
copyright = {Compendex},
title = {A Universal Automated Test Solution for Trunking Communication System},
journal = {Proceedings - 2020 International Conference on Computer Engineering and Application, ICCEA 2020},
author = {Liu, Huabin},
year = {2020},
pages = {47 - 51},
address = {Guangzhou, China},
abstract = {In order to improve the portability of the automated test of the trunking communication system, this paper proposed a universal automated test solution for the trunking communication system. It's based on the general architecture design of the trunking communication system, providing a replaceable communication protocol codec module. With the DSL-defined test script language describing the test cases, and efficient scheduling schemes for the test task, the automated functional test and performance test of the trunking communication system are realized. Theoretical analysis and experimental results show that the minimum load test task scheduling scheme based on user operation load prediction has lower response time and lower load balancing effect compared with the traditional static task scheduling scheme.<br/> © 2020 IEEE.},
key = {Network architecture},
keywords = {Load testing;Testing;Scheduling algorithms;Multitasking;Automation;},
note = {Automated test solutions;Efficient scheduling;General architectures;Load predictions;Performance tests;Static task scheduling;Test script languages;Trunking communication systems;},
URL = {http://dx.doi.org/10.1109/ICCEA50009.2020.00017},
} 


@article{20194207535580 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2025 Elsevier Inc.},
copyright = {Compendex},
title = {TOWARD A UNIFIED ENGLISH-LIKE REPRESENTATION of SEMANTIC MODELS, DATA, and GRAPH PATTERNS for SUBJECT MATTER EXPERTS},
journal = {International Journal of Semantic Computing},
author = {Crapo, Andrew and Moitra, Abha},
volume = {7},
number = {3},
year = {2013},
pages = {215 - 236},
issn = {1793351X},
abstract = {The Semantic Application Design Language (SADL) combines advances in standardized declarative modeling languages based on formal logic with advances in domain-specific language (DSL) development environments to create a controlled-English language that translates directly into the Web Ontology Language (OWL), the SPARQL graph query language, and a compatible if/then rule language. Models in the SADL language can be authored, tested, and maintained in an Eclipse-based integrated development environment (IDE). This environment offers semantic highlighting, statement completion, expression templates, hyperlinking of concepts to their definition, model validation, automatic error correction, and other advanced authoring features to enhance the ease and productivity of the modeling environment. In addition, the SADL language offers the ability to build in validation tests and test suites that can be used for regression testing. Through common Eclipse functionality, the models can be easily placed under source code control, versioned, and managed throughout the life of the model. Differences between versions can be compared side-by-side. Finally, the SADL-IDE offers an explanation capability that is useful in understanding what was inferred by the reasoner/rule engine and why those conclusions were reached. Perhaps more importantly, explanation is available of why an expected inference failed to occur. The objective of the language and the IDE is to enable domain experts to play a more active and productive role in capturing their knowledge and making it available as computable artifacts useful for automation where appropriate and for decision support systems in applications that benefit from a collaborative human-computer approach. SADL is built entirely on open source code and most of SADL is itself released to open source. This paper explores the concepts behind the language and provides details and examples of the authoring and model lifecycle support facilities.<br/> © 2013 World Scientific Publishing Company.},
key = {Semantics},
keywords = {Artificial intelligence;Markup languages;Error correction;Modeling languages;Ontology;Context free languages;Human computer interaction;Open source software;Open systems;Query languages;Birds;Decision support systems;Integrodifferential equations;Problem oriented languages;Visual languages;},
note = {Controlled English;Development environment;Domain specific languages;Graph patterns;Integrated development environment;Semantic Model;Subject matter experts;Web ontology language;},
URL = {http://dx.doi.org/10.1142/S1793351X13500025},
} 


@inproceedings{20124815732189 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2025 Elsevier Inc.},
copyright = {Compendex},
title = {Computer Applications for Software Engineering, Disaster Recovery, and Business Continuity - International Conferences, ASEA and DRBC 2012, Held in Conjunction with GST 2012, Proceedings},
journal = {Communications in Computer and Information Science},
volume = {340 CCIS},
year = {2012},
issn = {18650929},
address = {Jeju Island, Korea, Republic of},
abstract = {The proceedings contain 62 papers. The topics discussed include: impact on realistic mobility model for aircraft ad hoc networks; technology network model using bipartite social network analysis; mobile application development using component features and inheritance; view, level and fragment: commonalities in 'Architecture 101' and software modelling; highly analysable, reusable, and realisable architectural designs with XCD; ARSL: a domain specific language for aircraft separation minima determination; regression testing of object-oriented software: a technique based on use cases and associated tool; development of an instant meeting Android application using Wi-Fi direct APIs; developer support for understanding preprocessor macro expansions; towards building method level maintainability models based on expert evaluations; and a study on the improved stability of inverter through history management of semiconductor elements for power supply.},
} 


@inproceedings{20123015276547 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2025 Elsevier Inc.},
copyright = {Compendex},
title = {Modelling Foundations and Applications - 8th European Conference, ECMFA 2012, Proceedings},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
volume = {7349 LNCS},
year = {2012},
issn = {03029743},
address = {Kgs. Lyngby, Denmark},
abstract = {The proceedings contain 30 papers. The topics discussed include: executable UML: from multi-domain to multi-core; models meeting automotive design challenges; a commutative model composition operator to support software adaptation; comparative study of model-based and multi-domain system engineering approaches for industrial settings; strengthening SAT-based validation of UML/OCL models by representing collections as relations; model interchange testing: a process and a case study; an internal domain-specific language for constructing OPC UA queries and event filters; combining UML sequence and state machine diagrams for data-flow based integration testing; model transformations for migrating legacy models: an industrial case study; derived features for EMF by integrating advanced model queries; a lightweight approach for managing XML documents with MDE languages; and bridging the gap between requirements and aspect state machines to support non-functional testing: industrial case studies.},
} 


@article{20164102895331 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2025 Elsevier Inc.},
copyright = {Compendex},
title = {Is business domain language support beneficial for creating test case specifications: A controlled experiment},
journal = {Information and Software Technology},
author = {Haser, Florian and Felderer, Michael and Breu, Ruth},
volume = {79},
year = {2016},
pages = {52 - 62},
issn = {09505849},
abstract = {Context: Behavior Driven Development (BDD), widely used in modern software development, enables easy creation of acceptance test case specifications and serves as a communication basis between business- and technical-oriented stakeholders. BDD is largely facilitated through simple domain specific languages (DSL) and usually restricted to technical test domain concepts. Integrating business domain concepts to implement a ubiquitous language for all members of the development team is an appealing test language improvement issue. But the integration of business domain concepts into BDD toolkits has so far not been investigated. Objective: The objective of the study presented in this paper is to examine whether supporting the ubiquitous language features inside a DSL, by extending a DSL with business domain concepts, is beneficial over using a DSL without those concepts. In the context of the study, benefit is measured in terms of perceived quality, creation time and length of the created test case specifications. In addition, we analyze if participants feel supported when using predefined business domain concepts. Method: We investigate the creation of test case specifications, similar to BDD, in a controlled student experiment performed with graduate students based on a novel platform for DSL experimentation. The experiment was carried out by two groups, each solving a similar comparable test case, one with the simple DSL, the other one with the DSL that includes business domain concepts. A crossover design was chosen for evaluating the perceived quality of the resulting specifications. Results: Our experiment indicates that a business domain aware language allows significant faster creation of documents without lowering the perceived quality. Subjects felt better supported by the DSL with business concepts. Conclusion: Based on our findings we propose that existing BDD toolkits could be further improved by integrating business domain concepts.<br/> © 2016 Elsevier B.V.},
key = {Acceptance tests},
keywords = {Digital subscriber lines;Graphical user interfaces;Students;Problem oriented languages;Software design;Software testing;Specifications;},
note = {Behavior driven development;Controlled experiment;Development teams;Domain specific languages;Graduate students;Language features;Student experiments;Test case specifications;},
URL = {http://dx.doi.org/10.1016/j.infsof.2016.07.001},
} 


@inproceedings{20163002635787 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2025 Elsevier Inc.},
copyright = {Compendex},
title = {16th International Symposium on Trends in Functional Programming, TFP 2015},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
volume = {9547},
year = {2016},
pages = {1 - 156},
issn = {03029743},
address = {Sophia Antipolis, France},
abstract = {The proceedings contain 8 papers. The special focus in this conference is on Trends in Functional Programming. The topics include: lightweight higher-order rewriting in haskell; towards a theory of reach; functional testing of java programs; type class instances for type-level lambdas in haskell; on the role of slicing in functional data-flow programming; a shallow embedded type safe extendable DSL for the arduino and programmable signatures and termination proofs for recursive functions in FoCaLiZe.},
} 


@article{20063810118906 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2025 Elsevier Inc.},
copyright = {Compendex},
title = {HOTTest: A model-based test design technique for enhanced testing of domain-specific applications},
journal = {ACM Transactions on Software Engineering and Methodology},
author = {Sinha, Avik and Smidts, Carol},
volume = {15},
number = {3},
year = {2006},
pages = {242 - 278},
issn = {1049331X},
abstract = {Model-based testing is an effective black-box test generation technique for applications. Existing model-based testing techniques, however, fail to capture implicit domain-specific properties, as they overtly rely on software artifacts such as design documents, requirement specifications, etc., for completeness of the test model. This article presents a technique, HOTTest, which uses a strongly typed domain-specific language to model the system under test. This allows extraction of type-related system invariants, which can be related to various domain-specific properties of the application. Thus, using HOTTest, it is possible to automatically extract and embed domain-specific requirements into the test models. In this article we describe HOTTest, its principles and methodology, and how it is possible to relate domain-specific properties to specific type constraints. HOTTest is described using the example of HaskellDB, which is a Haskell-based embedded domain-specific language for relational databases. We present an example application of the technique and compare the results to some other commonly used Model-based test automation techniques like ASML-based testing, UML-based testing, and EFSM-based testing. © 2006 ACM.},
key = {Software engineering},
keywords = {Automation;Computer programming languages;Database systems;Embedded systems;Mathematical models;},
note = {Database-specific test case generation;Domain-specific languages;Domain-specific testing;HaskellDB;Haskells;Model-based testing;Test case generation;Test generation tools;},
URL = {http://dx.doi.org/10.1145/1151695.1151697},
} 


@inproceedings{20123515370190 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2025 Elsevier Inc.},
copyright = {Compendex},
title = {Proceedings of EuroPLoP 2009 - 14th Annual European Conference on Pattern Languages of Programming},
journal = {Proceedings of EuroPLoP 2009 - 14th Annual European Conference on Pattern Languages of Programming},
year = {2009},
address = {Irsee, Germany},
abstract = {The proceedings contain 32 papers. The topics discussed include: enterprise architecture management patterns for enterprise architecture visioning; roles in a software project; applied pattern for strategy management for technology entrepreneurship and innovation MSc program; performance of open source projects; the role of analysis patterns in systems analysis; applying architectural patterns for parallel programming: solving the one-dimensional heat equation; towards formalized adaptation patterns for adaptive interactive systems; a pattern driven approach against architectural knowledge vaporization; reusable architectural decisions for DSL design: foundational decisions in DSL projects; a pattern vocabulary for project distribution; business patterns for knowledge audit implementation; applying distributed development patterns; and a pattern language of black-box test design for reactive software systems.},
} 


@inproceedings{20124315599205 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2025 Elsevier Inc.},
copyright = {Compendex},
title = {Applying industrial-strength testing techniques to critical care medical equipment},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
author = {Woskowski, Christoph},
volume = {7612 LNCS},
year = {2012},
pages = {62 - 73},
issn = {03029743},
address = {Magdeburg, Germany},
abstract = {Hardware and software development of embedded systems interdependently gear into each other. Even more so if the device under development is intended for use in critical care facilities such as intensive care units. Especially in this case, safety measures and risk mitigation techniques are implemented using both hardware and software components. Thus applying hardware and software testing approaches in combination is inevitable as well. The increasing utilization of test domain-specific languages (Test DSLs), code generators and keyword-driven interpreters tends to raise the level of abstraction in test development. This approach aims to enhance productivity by generating executable tests from a non-programming language created for describing test cases. A second goal is to increase coverage by generating tests for as many as possible combinations of input values (black box test) or for all reasonable paths of a program flow (white box test). In combination with hardware-supported signal generation and fault injection this can be a very powerful strategy for testing safety-critical embedded devices. This article introduces an example of this strategy - the usage of a keyword-driven testing technique in cooperation with additional test hardware - in the context of an embedded medical device development, all the while emphasizing the benefit of combining different approaches. It discusses the utilization of commercial off-the-shelf (COTS) testing hardware as well as the application of an in-house developed test box. It also highlights the integration of commercial software - for requirements engineering, test management and continuous integration - with a self-developed testing framework powered by its own keyword-based test DSL. © 2012 Springer-Verlag.<br/>},
key = {Risk assessment},
keywords = {Embedded systems;Integration testing;Safety engineering;Biomedical equipment;Problem oriented languages;Safety testing;Software design;},
note = {Continuous integrations;Domain specific languages;Hardware and software;Hardware and software components;Keyword driven;Medical device development;Medical Devices;Testing hardwares;},
URL = {http://dx.doi.org/10.1007/978-3-642-33678-2_6},
} 


@inproceedings{20161302149609 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2025 Elsevier Inc.},
copyright = {Compendex},
title = {Example-based validation of domain-specific visual languages},
journal = {SLE 2015 - Proceedings of the 2015 ACM SIGPLAN International Conference on Software Language Engineering},
author = {Lopez-Fernandez, Jesus J. and Guerra, Esther and De Lara, Juan},
year = {2015},
pages = {101 - 112},
address = {Pittsburgh, PA, United states},
abstract = {The definition of Domain-Specific Languages (DSLs) is a recurrent activity in Model-Driven Engineering. However, their construction is many times an ad-hoc proceb, partly due to the lack of tools enabling a proper engineering of DSLs and promoting domain experts to play an active role. The focus of this paper is on the validation of meta-models for visual DSLs. For this purpose, we propose a language and tool support for describing properties that in-stances of meta-models should (or should not) meet. Then, our system uses a model finder to produce example models, enriched with a graphical concrete syntax, that confirm or refute the abumptions of the meta-model developer. Our language complements metaBest, a framework for the validation and verification of meta-models that includes two other languages for unit testing and specification-based test-ing of meta-models. A salient feature of our approach is that it fosters interaction with domain experts by the use, proceb-ing and creation of informal drawings constructed in editors liked yED or Dia. We abeb the usefulneb of the approach in the validation of a DSL for house blueprints, with the par-Ticipation of 26 4th year computer science students.<br/> © 2015 ACM.},
key = {Blueprints},
keywords = {Digital subscriber lines;Problem oriented languages;Visual languages;Modeling languages;Local area networks;},
note = {Computer science students;Domain specific;Domain specific languages;Domain-specific visual language;Meta model;Meta-modelling;Model-driven Engineering;Validation and verification;},
URL = {http://dx.doi.org/10.1145/2814251.2814256},
} 


@inproceedings{20223312581697 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2025 Elsevier Inc.},
copyright = {Compendex},
title = {Software Engineering 2008 - Fachtagung des GI-Fachbereichs Softwaretechnik},
journal = {Lecture Notes in Informatics (LNI), Proceedings - Series of the Gesellschaft fur Informatik (GI)},
volume = {P-121},
year = {2008},
issn = {16175468},
address = {Munchen, Germany},
abstract = {<div data-language="eng" data-ev-field="abstract">The proceedings contain 36 papers. The topics discussed include: connecting good theory to good practice: software documentation: a case study; assisting needs driven requirements engineering with the ARIS toolset; eliminating trust from application programs by way of software architecture; towards automatic construction of reusable prediction models for component-based performance engineering; towards effective management of software knowledge exploiting the semantic wiki paradigm; towards a peer-to-peer based global software development environment; combining structural and functional test case generation; Monaco: a DSL approach for programming automation systems; and workshop agile knowledge sharing for distributed software teams.<br/></div>},
} 


@inproceedings{2002477229400 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2025 Elsevier Inc.},
copyright = {Compendex},
title = {Plastic ball grid arrays, a qualified packaging technology for high reliability space applications},
journal = {Proceedings of SPIE - The International Society for Optical Engineering},
author = {Massey, Mary C. and Parrish, Brian E. and McMullen, William E. and Estes, Thomas J.},
volume = {4828},
year = {2002},
pages = {175 - 180},
issn = {0277786X},
address = {Reno, NV, United states},
abstract = {TRW has qualified a new advanced digital packaging technology for critical space applications; Plastic Ball Grid Array (PBGA) assemblies. This achievement enables use of high I/O, state-of-the-art ASIC designs and promises improved digital subsystem performance at significantly reduced weight and cost. Plastic ball grid array packages accommodating die as large as 17 mm sq. with over 800 I/O are planned on future satellite programs surviving extensive component-level and product-level qualification testing. TRW's space-qualification of laminate-based (organic) area array packaging technology responds to the ever increasing demand for reliable, cost effective, high density interconnect (HDI) solutions while leveraging the commercial standard plastic encapsulated microcircuit (PEM). This paper describes the product line approach used to produce qualification test vehicles representative of proposed flight configurations. TRW's radiation hardened 32-bit processor ASIC was used as an electrically functional test vehicle. The initial research focused on package reliability without hermeticity (RWOH) and solder joint reliability. Test results from a controlled insertion of plastic ball grid array packages on flight-like dual sequential laminated (DSL) boards are presented, where thousands of solder joints are continuously monitored using an inexpensive and highly reliable on-board fault detection circuit. The data demonstrates how this technology can provide a superior integrated circuit (IC) packaging solution over traditional ceramic-based assemblies. Space programs will benefit from aggressive insertion of JEDEC standard PBGA packages to achieve higher performance designs with increased circuit densities, while reducing electronic product's size, weight, power, and cost.},
key = {Electronics packaging},
keywords = {Electric discharges;Integrated circuits;Interconnection networks;Laminates;Printed circuit boards;Reliability;Satellites;Space applications;},
note = {Plastic ball grid arrays (PBGA);},
} 



